* blackhat-SEO
** DONE [[http://blog.sina.com.cn/s/blog_c206a2c30101eks9.html][20种黑帽SEO作弊手法]]
     CLOSED: [2015-11-21 Sat 17:21]
     - State "DONE"       from "TODO"       [2015-11-21 Sat 17:21]
　　黑帽seo就是作弊的意思，黑帽seo主要是研究和利用搜索引擎算法漏洞,其手法不符合主流搜索引擎发行方针规定,采用搜索引擎禁止的方式优化网站，影响搜索引擎对网站排名的合理和公正性。黑帽seo行为通常就是一般所讲的“搜索引擎作弊行为”，通常的黑帽SEO是利用和放大搜索引擎的现在有的缺陷或漏洞而获取更多的用户访问流量。简单的说，黑帽seo优化就是使用作弊手段或有可疑手段在短时间内获取大量流量。同时随时可能因为搜索引擎算法的改变而面临惩罚。
 
　　做白帽就要花更多的时间和精力，而且并不能百分之百保证一定能做出一个成功的网站。但相对于来说白帽更加的安全，一旦成功，网站就可以维持排名和流量，成为一份高质量的资产。
 
　　黑帽的手法特点就是短平快,往往见效快，实施成本低。往往有很多seoer太过于急功近利,为了追求一时的排名,喜走捷径,剑走偏锋,而采用的作弊方法,搜索引擎肯定是痛恨黑帽的，因为黑帽降低了搜索结果相关性和用户体验，动了搜索引擎的饭碗，属于必须严厉打击的范围。一旦被惩罚，就要经过一个漫长的恢复过程。所以做黑帽被惩罚是正常的，甚至可以说，长远来看，是必然的。 
*** 黑帽SEO作弊手法一：关键字堆砌
　　关键字堆砌是黑帽seo方法中的一种，英文称Keyword Stuffing，通过在网页中大量重复关键词，提高关键词的密度，达到提高关键词排名的效果。,关键词堆砌是比较低级的一种手法,短时间内可以获得很不错的排名。这种手法已经是过去时了.搜索引擎判断这种作弊行为的算法已经相当成熟，所以，一旦网页上出现关键词堆砌现象，网站很容易被惩罚。
 
　　关键字堆砌是指在一个网页中非常密集地放置关键字。关键字堆砌的常见形式,如标题，Tag、关键词标签、说明标签、文章内容页高度重复关键词等。
 
　　1). 标题描述标签中堆砌关键词：
 
　　众所周知，标题是SEO中比较重要的一个部分，很多人将大量的关键地都堆砌在标题中，例如“SEO-seo培训-SEO服务-SEO优化-seo顾问-SEO教程-SEO排名”，这种写法算是堆砌的比较轻微的，有的人甚至会堆砌几十个类似的关键词，如果将这种文字都放入标题中，则就形成了对SEO这个词的堆砌。建议标题中相同关键词出现的次数最多不要超过3次。当然这个也不是必须的，需要了解百度分词，合理的去分布标题关键词。
 
　　2).网页中堆砌关键词：
 
　　关键词的密度直接影响了这个关键词在搜索引擎中的排名，关键词密度越高，则说明这个关键词在该网页中的重要性越大，所以SEO行业内有个名词叫做“关键词布局”，但是黑帽seo人员，只为了提高关键词的密度，而在网页中将关键词乱堆一气。在以前这一方法可能很有用，但是现在一味的在内容中堆砌关键词而没有合格的内容，可能会有那么一点效果，但是很快就会被搜索处理，并且现在的互联网追求的是与用户的互动，网站一味堆砌关键词，毫无看点肯定是不利于用户体验，伤害了用户。
 
　　3).ALT标签堆砌关键词
 
　　在ALT标签的关键字堆砌这个很简单，就是在alt标签中添加毫无关系的关键词或添加很多的关键词。　　
[[file:./tomsinsight-hack/关键词堆砌.jpg][关键词堆砌.jpg]]
*** 黑帽SEO作弊手法二：桥页
　　所谓桥页(doorway pages)，也叫：门页、跳页、过渡页，桥页通常是针对特定的关键字词组或短语，用软件自动生成大量低质量包含关键词的网页，然后从这些网页做自动转向到主页。目的是希望这些以不同关键词为目标的桥页在搜索引擎中得到好的排名。当用户点击搜索结果的时候，会自动转到主页。有的时候是在桥页上放上一个通往主页的链接，而不自动转向。桥页包括多个链接(往往是数百个)，对访问者用处极小或无用，不包含有价值的内容。桥页生成的文字往往是杂乱无章的，没有什么逻辑。如果是由人写出来的真正包含关键词的文章，就不是桥页了。
 
　　解释下如A页是桥页，B页是网站。如果访问A页那么弹出B页，搜索引擎会根据用户停留在A页的时间来判断A页是不是桥页。现在的搜索引擎越来越智能了。搜索引擎惩罚的话，从道理上将应该是惩罚A页。如果惩罚B页的话，那么会有无数的无辜网站会遭到恶意竞争对手的桥页“攻击”。
 
　　桥页是以前时常涌现的黑帽方法之一，当做优化的时候，桥页都会专门做一个页面，全体嵌入关键词，并且关键词全部加粗加超链接到首页，就是为了可以提高关键词呈现率，并且快捷的见到后果，这个方法比较快，但是搜索引擎也会对这样的网站进行查封。
[[file:./tomsinsight-hack/桥页.jpg][桥页.jpg]]
*** 黑帽SEO作弊手法三：隐藏链接(黑链) 
　　隐藏链接,通常也被称之为黑链，也叫暗链、隐链;指的是正常的链接通过一些方法，如：把链接放入js代码中，使用display:none等等，从而使用户在正常浏览网页的时候无法看到这个链接。
 
　　隐藏链接和隐藏文字(hidden text)相似，但是区别是把关键词放在链接里面，而这个链接也是用户所看不到的。
 
　　新手站长在跟其它网站交换链接的时候，可能会被蒙蔽，有的站长在给对方做友情链接的时候通过使用CSS来控制隐藏链接的方式也不少见，也有部份人通过提供免费的网站程序，博客风格，网站插件等方法把黑链植入到你的网站。
 
　　随着现在友情链接交易平台的盛行，不少无良的“黑客”或服务器管理人员，开始通过挂黑链的方式为自己谋利。黑链是通过技术手段扫描FTP和服务器的弱口令，网站漏洞，获取对方网站的管理权限，然后黑掉网站，在网页中添加指向自己网站的隐形锚文本连接挂进，从而快速提升网站排名。这手法一般在网站前台是无法看到的，只能通过查看源代码才能发现，一般是用CSS隐藏，也有用JS输出CSS。
 
　　我们知道百度排名算法中有一个很重要的因素就是基于超链接分析技术，当一个站点被越多的站点给链接的时候，那么这个站点的权重也会相对随之提升的，但是这并不包括隐藏链接这种手段所带来的链接数量，因为隐藏链接在搜索引擎看来是一种欺骗手段，所以必定会影响一个站点的权重正常传递。搜索引擎谷歌和百度早就提出，搜索引擎是不欢迎黑链的，隐藏链接是被搜索引擎严令禁止的，一旦发现，惩罚将会非常严重，轻则降低网页权重，严重甚至拔毛K站。所以新手站长在跟对方交换友情链接成功后，也要看下对方网站给您交换链接对应的HTML源代码是否正常。假如说你的网站当前做了隐藏链接，建议你把隐蔽链接去掉，以免搜索引擎发现k掉你的网站。
 
　　关于黑链详细情况，之前就写了一篇文章《[[my-anchor-hidden-links][全方位解读网站黑链]]》，大家可以看看。
*** 黑帽SEO作弊手法四：隐藏文字 
　　隐藏文字是在网页的HTML文件中放上含有关键词的文字，但这些字不能被用户所看到，只能被搜索引擎看到，这个很黑链很相似。
 
　　隐藏文字的方法可以有几种形式:比如颜色隐藏：通过将文字与背景设置为相同颜色，达到隐藏的效果;DIV隐藏链接;javascript隐藏链接;静态页面黑链代码;CSS隐藏链接代码(挂黑链常用此手段);小字号隐藏：将文字大小设置为1的细微文字或微型文字，并且放在不起眼的角落，用户很难察觉到，而搜索引擎却可以正常读取到。
 
　　隐藏关键词的目的就是为了增加页面关键词的密度,想提高网页的相关性,以达到优化的效果。有的时候，有的人还在这些地方放上与网站内容无关的，但是很热门的关键词，希望网页能在这些热门关键词下得到好的排名和流量。
 
　　隐藏文字说白了就是欺骗搜索引擎，现在的搜索引擎已经能轻易的识别这些技术，网站一但被搜索引擎发现隐藏堆砌关键字，轻则降权重，重则网站直接被K被屏蔽。
 
　　隐藏文字这也是常用的作弊方式，通常是某些黑客常用的方式，入侵某个网站后，为了不让管理员发现，便把文字的颜色和网页的seo关键字排名优化颜色设置成一致，用肉眼无法看出，只让搜素引擎看见而让浏览者看不见。
*** 黑帽SEO作弊手法五：隐藏页面
　　隐藏页面(cloaked page)也叫斗蓬法或障眼法，是专门针对搜索引擎在爬取网站页面时显示的经过特别优化的页面，指有的网页使用程序或脚本来检测来访问的是搜索引擎还是普通用户。通过在服务器上设置cloaked页面来读取和判断当前访问者是真实的访问者还是搜索引擎蜘蛛，然后根据服务器配置好的脚本有针对性的给予真实访问者和搜索引擎蜘蛛作出响应，给予对应的返回页面展示。如果是搜索引擎，网页就返回经过优化的网页版本。如果来访的是普通人，返回的是另外一个版本。
 
　　隐藏页面也是一种障眼法,为SEO作弊手段之一，这种手法意图蒙骗搜索引擎，来影响该网站的网页在搜索引擎中获取较好的排名，通常用户无法发现。因为一旦你的浏览器去看这个网页，无论是在页面上还是在HTML源文件中，你所得到的都已经是与搜索引擎看到的不同的版本。检测的方法是，看一下这个网页的快照。隐藏页面手法如被发现，该网站会永暂从搜索引擎名单中被剔除。  
*** 黑帽SEO作弊手法六：网页劫持 
　　网页劫持也就是我们经常所说的page jacking，是将别人的网站内容或者整个网站全面复制下来，偷梁换柱放在自己的网站上。欺骗性重定向，鬼域与其类似。
 
　　这种黑帽SEO手法对网页内容极其匮乏的站长是有吸引力的。但是，这个做法是相当冒险的，更是为人所不齿的。搜索引擎的专利技术能从多个因素上来判断这个被复制的网页或网站不是原创，而不予以收录。这种做法已经被google左侧排名优化搜索引擎从多个方面来判断重复网页是不是原创，所以这种网页劫持的方式用的也越来越少。　　 
*** 黑帽SEO作弊手法七：PR劫持
　  
PR劫持使用欺骗手段获得工具条上比较高的PR显示。方式是利用301和302定向的功能。从域名A做301或302转向到域名B，而域名A的PR值较高，域名B在PR更新后，也会显示域名A的PR值。最简单的就是先做301或302跳转到域名B，等PR更新过后，立刻取消转向，同时也获得了和A站相同的PR值。这个做假的PR显示值至少维持到下一次PR更新，一般有两三个月或更长的时间(最近GG更新有点慢)。这样可以获得比网站真实pr值高很多的pr数值。
[[file:./tomsinsight-hack/返回301或302作PR劫持.jpg][返回301或302作PR劫持.jpg]] 
　　那么如何检查是pr劫持呢？ 
　　方法一：
　　PR检测网站  http://checkpagerank.net

　　方法二：
　　看Google的网页快照，Google快照和你看到的网页不是同一个网站，(一般网站标题和logo都会显示出来)，就非常可疑了，网页快照里面的那个网站就是PR劫持的目标网站。该方法的缺陷：只要该网站劫持结束后更新到自己的网站，Google会重新收录新网站，那这个时候就看不出原来网站的痕迹，那就无法确认PR是否劫持，更无法知道劫持的哪个网站了。该方法只适用于劫持目标网站后转换到自己的网站不久。
 
　　方法三：
　　查看反向链接，再根据反向链接来判断真实的网站是哪个。登陆google，在搜索框中输入：link:it.xxxxx.com，搜索结果中的网站就是向该网站提供反向链接的，任意打开一个，在里面查找it.xxxxx.com的链接，没有发现。再随机找几个，依然没有发现，这就说明该站的PR是劫持的(多找几个网站可以增加这个判断结果的可信度)。
 
　　确定了该网站是PR劫持的之后，下面就查找该网站劫持的哪个网站的PR，可以这样做：看link出来的结果中哪个站的结果比较多，一般就是这个网站。因为link的结果中与被劫持PR的网站link是一样的，而被劫持PR的网站内页链接到主域名的比较多，所以一般结果比较多的那个站就是被劫持的网站。比如我们在刚才的结果中看到有大量的来自it.com.cn的内容，所以初步判断该网站是劫持的it.com.cn的PR。验证刚才的判断结果，方法很简单。用link:it.xxxxx.com和link:it.com.cn比较，如果是一样的，那就说明判断是正确的。在google中输入link:it.xxxxx.com，看查询结果;再输入link:it.com.cn，看查询结果。两者搜索结果完全一样，所以可以肯定的说，it.xxxxx.com是劫持的it.com.cn的PR。
 
*** 黑帽SEO作弊手法八：蜘蛛劫持 
　　蜘蛛劫持就是黑帽seoer通过各种非正常手段，劫持搜索引擎蜘蛛(如：百度蜘蛛)，其表现为：百度快照是一个页面，用户点击进入网站后看到的是另一个页面。通常是根据访客的user-agent的不同来进行此操作。
 
　　蜘蛛劫持的技术原理是通过黑客手段进入猎取站点，在其中一文件夹或者根目录上传一个文件(快照文件，给搜索引擎看的)来达到劫持猎取站点的蜘蛛，进入目标站点。大家都知道网站流量中很大一部分是来自于蜘蛛，蜘蛛劫持的目的就是劫持搜索引擎蜘蛛以及搜索引擎流量导入目标网站。
 
　　蜘蛛劫持问题的解决方法是第一时间检查自己的网站空间中是否存在木马文件，一般情况下都是这种[[my-anchor-global.asa][global.asa]] ，这个时候就要把这个文件名字重命名，这个时候这个木马程序就不会被别人控制了，因为这种木马文件我们是删处不掉的，只有空间商才有权限删除。木马文件重命名后在让空间商帮忙删除这个木马文件。
[[file:./tomsinsight-hack/glabal.asa木马用于劫持蜘蛛.jpg][glabal.asa木马用于劫持蜘蛛.jpg]] 
　　值得注意的是蜘蛛劫持和前面说的隐藏页面都是呈现给搜素引擎和用户是不一样的页面，但是本质是不一样的，隐藏页面的内容是同一个网站，只不过为了排名而呈现2种版本的页面，而蜘蛛劫持所展示的是2个网站，为的是盗取别人网站的流量。
 
　　还有一种和蜘蛛劫持类似的就是快照劫持，快照劫持就别人是在你不工作的时候进入你的网站的，一般是凌晨1点到5、6点这段时间(当然时间是不一定的)。他们通过各种手段进入你的网站后台，把网站的mate标签和title找成他们网站相关的内容，再等到蜘蛛抓取之后再把原来的信息再换回来，这样神不知鬼不觉，你也不会很轻易的发现什么。因此，第二天的快照就会变成劫持者的网站，这就导致了你的快照被劫持。有的时候别人是纯粹的快照劫持，没有劫持上面所说的搜索引擎蜘蛛。但是当发现快照不一致时我们也需要检查网站后台有没有global.asa 文件。
*** 黑帽SEO作弊手法九：垃圾链接
　　垃圾链接是指为达到快速的关键词排名目的，在各大论坛和博客发布和主题内容不相关的链接和自动生成(采集)网页中含有的链接，称为垃圾链接。这种方式相信大家以前都或多或少有干过，所有搜索引擎都把外链当作排名的主要因素之一，而从其他网站获得自然链接也不是那么轻松的事情，所以垃圾链接就运应而生了。
 
　　垃圾链接基本特征：
 
　　1、主要出现在论坛和博客的评论和留言中且无贡献值。
　　2、自动生成(主要指[[my-anchor-bbs-colloctor][采集页面]])的页面产生的链接。
　　3、页面内容和Title以及描述严重不符的网页输出链接。
　　4、自动评论和顶贴软件生成的链接(如：[[my-anchor-bbs-automately-post][论坛顶贴机]]和[[my-anchor-information-broadcast][博客群发群件软件]])。
 
　　垃圾链接不会马上被识别，而是事后审查并去除其权重，最终导致降权。垃圾链接在未识别之前会被计入关键词排名权重。现在搜索引擎对这种垃圾链接打击本身很严重，各类承载平台的审核力度也在加强。就算勉强暂时通过，以后被搜索引擎或网站管理人员发现处理之后会造成网站较大的外链波动，同时还可能带来很多的死链，所以我觉得对自己的网站而言，这种黑帽seo手法和堆砌关键词一样都是即没多大用又容易被发现的手法。不仅如此我们还要经常去查看自己网站外链，用外链工具删除别人的恶意投放外链。
*** 黑帽SEO作弊手法十：网站镜像
　　网站镜像，通过复制整个网站或部分网页内容并分配以不同域名和服务器，以此欺骗搜索引擎对同一站点或同一页面进行多次索引的行为，这既是为什么有的网站注明禁止未授权不得做网站镜像的原因了，两个网站的完全一样，相似度过高必然会导致自己的网站受到影响。
 
　　网站镜像可以起到分流作用：当一个网站的流量过高，服务器不能承受的时候，那么这时候就能起到给服务器减压分流的作用。同时如果不能对主站作正常访问(如某个服务器死掉或出了意外)，但仍能通过其它服务器正常浏览。但是这种手法容易被搜索引擎识别为作弊手法，导致自己的站点受到影响。来回的切换比较麻烦。一旦自己的网站被镜像，网站的品牌形象就会受损。千万别把所有的域名都指向一个站，或者绑定复制的网站，不要认为这样做能增加主站的权重和PR，大错特错，同样是作弊，搜索引擎为了避免关键词的地位被一家包揽，对镜像网站的处分是十分之狠，被搜索引擎识别后，不仅k掉你的网站，并且永恒封掉你的域名和服务器地址，在服务器所有的网站都会随着不幸。不过可以做一个镜像站后禁止搜索引擎访问就可以为主机服务器分流同时防止主机服务器出现问题打不开。
[[file:./tomsinsight-hack/网站镜像.gif][网站镜像.gif]]
*** 黑帽SEO作弊手法十一：诱饵替换
　　诱饵替换指的是作弊者先针对一些普通关键词制作页面获得排名后，页面再换成其他内容。一般分为两种情况，一是针对比较等闲的长尾关键词制作页面，获得排名但和点击后，把页面全部换成与热门关键词相关的商业价值更高的类容。第二种是针对普通用户正当的关键词制作内容，获得排名后再把页面换成非法、成人、赌博等内容。这类作弊大多用于一些短期暴利行业，从介绍就可以看出搜索引擎再次更新后任何排名将不复存在。
 
　　诱饵替换是SEO作弊的手段之一，诱饵替换利用了搜索引擎的记忆特性，我们经常在搜索引擎结果中看到这种现象，页面内容完全改变后，原来的页面排名并不会立即消失。甚至在搜索引擎重新捉取页面新内容后，也不会立即消失，而是维持一段时间。由于搜索引擎有这种记忆特性，再加上诱饵替换页面被重新抓取就需要一段时间，所以诱饵替换页面往往能在原来正当或比较容易的关键词搜索中保持一段时间的排名。有的人为了延长该页面排名存在的时间，甚至取得排名替换内容后直接用robots来禁止搜索引擎抓取。这种诱饵替换一旦发现就会被惩罚，不过一般做这些诱饵链接的人是有准备的，大不了在弄个页面就行了，反正做一个简单关键词上去很容易。而对我们而言尽管不能这样，但是可以有另一种方式，就是链接诱饵，不过这个诱饵可不属于黑帽子seo。具体地可以看《[[my-anchor-link-decoy][你知道链接诱饵吗?]]》一文。
 
*** 黑帽SEO作弊手法十二：内容采集
　　说到内容采集相信大家都是太熟悉了，基本所有seoer都“采集”过一些内容，木木seo也不例外，内容采集使用CMS程序自带或软件的采集功能，填充大量质量低劣的网站内容和垃圾信息。当然，大量采集网络中的重复内容，最终的结果各位Seoer心里都应该清楚。
 
　　常见的应用手法有：利用采集器软件和伪原创工具进行制造垃圾。
 
　　1. 采集器
 
　　一些采集器具有的内容采集和数据导入功能能将您采集的任何网页数据发布到远程服务器，业界对采集内容都是嗤之以鼻的，尽管通过采集的手段来更新网站内容是大多数站长所抵制的，但每时每刻依然有很多的站长利用各种手段进行内容采集。
 
　　通过采集程序来抓取别人网站的内容然后放到自己的网站上，这本身就是非常不正当获取内容的方式，因为这种方法的便捷性成为很多网站更新内容的手段和渠道，这可以看做是行业内部不正当竞争的一种方式。再者采集内容的质量难以人为掌控是采集受到抵制的另一个重要原因，现在的很多站长用程序来采集内容，而现有的技术还不能安全过滤文章中不利于网站发展的内容，比如不良画面语句。就算你都是从权威网站上采集内容，其他网站的内容很可能并不适合你网站内容的更新，网站本身的发展是存在差异特征的。现在搜索引擎的人性化水准逐步提高，作弊的手段极易遭来搜索引擎的不友好，轻则不收录重则K站，采集所造成的网站发展后果是完全得不偿失的。不论从哪个方面看，采集内容都不能使网站生存长久，是网站运营的不可取。

[[file:./tomsinsight-hack/采集器.gif][采集器.gif]]
　　2. 伪原创工具
 
　　所谓伪原创就是把一篇文章进行再加工，使其让搜索引擎认为是一篇原创文章，从而提高网站权重。
　　随着seo的发展出现了“伪原创”这个产物，被众多seoer痴迷不能自拔，到现在还有很多站长在操作站群，少则几百站点多则上千如此庞大的网站阵容如果用原创去更新简直就是无底洞，采集是最为简洁和方便的方法。
 
　　我们知道，搜索引擎是喜欢原创性的内容，对于重复的内容，它会认为没有收录的价值。如果网站上大量的内容都是转载的，搜索引擎就会觉得整个网站没有多大的价值，从而降低网站权重。网站排名自然也不会很高。
 
　　伪原创工具都是机械的、死板的，这些工具无外乎替换词语，比如同义词，甚至有替换成反义词的，这样就和原文的意思完全相反了，没有观点或者错误的观点，对网站长期发展百害无一利。
 
　　同时，这些伪原创工具还有一个“本事”就是打乱文章的段落、句式，使文章看起来前言不搭后语，说难听一点，这样的文章狗屁不通的，只给搜索引擎看。网站的最终目的是做给用户看的，一个网站大量的文章都读不懂，句子不通，你自己看到别人的网站这样子，也一定会马上单击屏幕右上角的红叉叉。
[[file:./tomsinsight-hack/伪原创工具.jpg][伪原创工具.jpg]]
　　当下搜索引擎对内容的重视，相信大家也是有目共睹，所以以前那种傻瓜式的采集已经越来越少的人用了，但是采集还是目前用得比较多的。采集来干什么?很简单，当然是获得大量的内容信息，然后自己整合出质量较高的伪原创，对于笔杆子不行的人，这方法可比在那干想好上千万倍。当然能坚持原创固然好，但是因为各种原因做不了也不要胡乱的填充垃圾内容。相关内容可以看《[[my-anchor-original-creation][你有你的原创，我有我的伪原创]]》。 
*** 黑帽SEO作弊手法十三：链接买卖
　　外部高质量单向链接对网站的推荐作用不用我多少大家都知道，这也是为什么大家总是到处找各种平台发放外链的原因之一，一个好的首页单向链接比那些平台中的链接要好太多太多，很多人通过链接交易平台进行链接买卖，也就是购买的高pr的外部链接或友情链接。这一种作弊手法现在也是很流行的。购买链接，虽然在其他网站买广告是很正常的一件事，但有的时候如果所购买的广告链接纯粹为了操纵搜索引擎排名并且一次性购买大量，也会被当做作弊手段。
 
　　虽然这样的连接搜索引擎虽然很少查，但是这样做的人自己心里很清楚。如果你的网站被认为是通过购买链接来作弊，也没办法去和搜索引擎争辩。因为搜索引擎的决定就是最后的决定。但是搜索引擎很难判断哪些链接是正常的哪些链接是购买的，这也是为什么你知道你的对手在买链接，而他的排名却一直比你高的原因。可以这样说现在很多排名在前面的网站都存在买链接的情况，只要到“正规”的地方买，并且合理的利用，我们根本不必当心什么。需要当心的只是那些做网站练级交易的网站，因为它们搜索引擎是可以发现的。 
[[file:./tomsinsight-hack/链接买卖.jpg][链接买卖.jpg]]
*** 黑帽SEO作弊手法十四：链接工厂(站群，链轮)
　　链接工厂，亦称大量链接机制，链接农场，链接养殖场;指由大量网页交叉链接而构成的一个网络系统。这些网页可能来自同一个域或多个不同的域，甚至可能来自不同的服务器。一个站点加入这样一个“链接工厂”后，一方面它可得到来自该系统中所有网页的链接，同时作为交换它需要“奉献”自己的链接，借此方法来提升链接得分，从而达到干预链接得分。其目的是通过搜索引擎获得大量流量，或者是将链接指向同一个网站，以提高搜索排名。站群通常由几个到几百个网站组成，个人站长想通过手工更新站群，那几乎是不可能的任务。所以一般都是通过站群软件来完成.
 
　　博客链轮，又称BLOG-LinkWheeler，在SEO中通常用来培养自己关键词在搜索引擎中的排名。当然，在庞大的外部导入链接的支撑下，我们可以利用站内的合理锚文本分布来进行恰当的优化。
[[file:./tomsinsight-hack/链轮.jpg][链轮.jpg]]
　　链接工厂简单的理解可以为一个相互链接的一群网站，不顾主题的相关，大家链接在一起，每个新加入的网站既可以得到之前的网站的链接，同时也要链接别人。而之前加入的网站就可以得到多一个链接。由于大量的网页相互交叉链接,而构成了一个链接的网络系统.比如说,现有100个网站,这些网站内容可能不相关,但是彼此互相链接,形成一个网状结构。
 
　　加入链接工厂,危害十分大.是对搜索引擎十分不友好的一种做法.加入链接工厂极有可能让你的站点陷入泥潭,到时候会被搜索引擎降权或者被K掉,google明确提出，不要加入链接工厂，而google的算法中有说到，链接作弊的网站，自己也算作弊了。
 
　　其实合理的做链轮搜索引擎是不能很好的发现的，但是说到底想把链轮做好是一个量大、繁琐的活，简单的说是又脏又累还伤神，没有团队支持很难做好。所以如果你就一个人，并且没那么多时间的话，大规模链轮还是别做了，简单的5、6个站直接的还是i尝试一下。关于链轮的详细介绍前面一篇文章《[[my-anchor-pictural-linkwheeler][图解seo链轮]]》已经写得很清楚了，这里就不再复。
*** 黑帽SEO作弊手法十五：群发软件
　　相信很多站长建站初期对网站的推广都是一筹莫展，想把站做好做大，但又耐不住性子，急于想一步登天，恨不得明天网站流量就超过1万，但是现实总是很残酷的。一开始急于收录，好容易收录了又开始着急没流量，想尽了一切办法也没又成功。最后想到了群发。
 
　　群发，指通过软件或其他方式对受众进行群体式广告发送，随着科技进步，群发不再是意义上的手机信息群发,短信群发。IT时代的到来，QQ群发，email群发,博客群发，阿里旺旺群发，贸易通群发,甚至网页群发都已普遍存在。现在很多群发人的目的不是为了seo优化，完全是为了把产品和企业信息展示给用户。当然这种强制性营销尽管受消费者反感，但不得不说带来的效果也是很大的。
 
　　群发软件主要作用为发布推广企业或个人信息。目前群发软件主要有：博客群发软件、邮件群发软件、QQ群发软件、企业QQ群发软件、阿里旺旺群发软件、阿里巴巴群发软件、引擎登陆群发软件、论坛群发软件、供求信息群发软件、留言板群发软件、短信群发软件、IP群发软件等等
**** 博客群发
　　博客群发通俗点说就是在各大门户网站批量创建博客，编写软文或者转载主站文章，而各个博客之间又互相友情链接，最终到达提升网站的知名度、增加外链、提高流量等目标。利用博客评论VS引用和博客引用通告群发可对在线的千万博客网站直接发送帖子，通过验证注册后直接发送带链接的图片或文字广告。内容字数限定1500字以下。
[[file:./tomsinsight-hack/博客群发.jpg][博客群发.jpg]]
**** 论坛群发软件
　　可对在线的千万论坛网站直接发送帖子，绕过验证直接发送带链接的图片或文字广告。内容字数限定800字以下。论坛群发软件迎合了论坛在线人数远大于邮件在线人数且交互及时等特点。比较新颖的一种网络推广方式，优点比较省时省力，阅读人数远大于邮件;缺点就是不长久，并且容易被封帖。但是只要平台访问量够大，发的帖子够多，就算存在时间短，带来的访问量也是可观的。
[[file:./tomsinsight-hack/论坛群发.png][论坛群发.png]]
**** 外链群发
　　利用脚本或软件工具在网络上各个平台进行大批量的外部链接群发、建立。吸引搜索引擎对该网站的关注及关键词排名、权重的提升。随着现在算法的不断更新，现在外链群发的效果完全不如以前了。当然，现今各大搜索引擎对群发早就有了针对性的检测与评判标准，也会进行处罚，不建议使用。并且还要提防别人对你的网站使用。
　　当然群发的方式还有很多，就不一一例举了。
 
*** 黑帽SEO作弊手法十六：蜘蛛陷阱 
　　蜘蛛陷阱是阻止蜘蛛程序爬行网站的障碍物，通常是那些显示网页的技术方法，目前很多浏览器在设计的时候考虑过这些因素，所以可能网页界面看起来非常正常，但这些蜘蛛陷阱会对蜘蛛程序造成障碍。如果消除这些蜘蛛陷阱，可以使蜘蛛程序收录更多的网页。
 
　　蜘蛛陷阱也是以前常常使用的黑帽方式之一，就是用一些动态网站代码中，写一个无线循环的页面，使得蜘蛛爬进去后在这个无穷循环中轮回收录，这样虽然会使得网站疾速进步排名，而且也会随时给我们网站带来杀身之祸，所以大家不要使用。特别是现在这个方法还真是不咋地。

　　以下木木SEO简单为大家介绍几种易导致蜘蛛陷阱的建站技术:
**** Flash动画
　　有得网站喜欢在首页放一个Flash动画片头、用户访问网站看完片头后被转向得真正得HTML版本得文字网站首页。搜索引擎不能读取Flash、一般也没办法从Flash Intro跟踪到HTML版本页面。如果Flash效果是必需得、至少也需要在首页加上一个通往HTML版本得链接。这个链接应该是在Flash文件之外得HTML代码中、搜索引擎跟踪这个链接可以抓取后面得HTML版本页面。
**** Session ID
　　有些网站使用Session ID跟踪用户访问、每个用户访问网站时都会生成独特唯一得Session ID、加在URL中。搜索引擎蜘蛛的每一次访问也会被当成一个新得用户、URL中会加上一个不同得Session ID,这样搜索引擎蜘蛛每次来访问时所得到得同一个页面得URL将不一样、后面带着一个不一样得Session ID。这也是最常见得蜘蛛陷进之一。这样就会产生了同一个页面但URL不同的情况，这种的一来会产生复制内容页面，造成了高度重复的内容页。
**** 框架结构
　　对搜索引擎来说、方位一个使用框架得网址所专区得HTML只包含其他HTML文件得代码、并不包含任何文字信息、搜索引擎根本无法判断这个网址得内容是什么。虽然蜘蛛可以跟踪框架中所调用得其他HTML文件、但是这些文件经常是不完整得页面、比如没有导航只是正文。搜索引擎也无法判断匡建忠得页面内容应该数属于主框架、还是属于框架调用文件。
**** 动态URL
　　动态URL指得是数据库驱动得网址所生成得、带有问号、等号及参数得网址。一般来说动态URL不利于搜索引擎蜘蛛爬行、应该尽量避免。有的url会造成蜘蛛的死循环。
**** JS链接
　　由于Javascript可以创造出很多吸引人得视觉效果、有些网址喜欢使用Javascript脚本生成导航系统。这也是比较严重得蜘蛛陷阱之一。虽然搜索引擎都在尝试解析JS脚本、不过我们不能寄希望于搜索引擎自己去克服困难、而要让搜索引擎跟踪爬行链接得工作尽量简单容易。
**** 要求登录
　　有些网站内容放在需要用户登录之后才能看到得会员区域、这部分内容搜索引擎无法看到。蜘蛛不能填写用户名、密码、也不会注册。
**** 强制使用Cookies
　　有些网站为了实现某种功能、如记住用户登录信息、跟踪用户访问路径等、强制用户使用Cookies、用户浏览器如果没有启用Cookies、页面显示不正常。搜索引擎蜘蛛就相当于一个禁用Cookies得浏览器、强制使用Cookies只能造成搜索引擎蜘蛛无法正常访问。
 
*** 黑帽SEO作弊手法十七：[[my-anchor-virtual-links][虚伪链接]]
　　大家都知道蜘蛛都是依照连接地址去爬行的，对于虚假连接蜘蛛是很厌恶的，好比说这是一个页面，当蜘蛛进去后，里面除了关键词别的内容什么都没有，又比如你是做网上食品店的，你为了吸引人进你的网站，外链锚文本用淘宝啊、最新电影啊等词来吸引人，总而言之，反正链接文不对题带有一定的欺骗性质的都可以说是虚伪链接。这样一来蜘蛛也就会被逼迫爬行并且收录，固然蜘蛛无奈辨认你的网站是否是虚假连接，但是搜索引擎一旦发现，你的网站也会被k掉，并且这样做对用户体验非常不好。如果你的网站不是为短期性盈利的网站，完全不必这么做。
*** 黑帽SEO作弊手法十八：欺骗点击链接 
　　当用户打开一个网站，该网站声称其网站已移至新域名下，并请用户点击新域名链接进入网站。但当用户进去后才发现，这个链接是一个“会员”链接或与原网站毫不相干的网站。这也属欺骗性重定向行为。
 
　　还有一种就是黑客们可以利用“肉鸡”设备诱导用户点击欺骗性链接，进行DNS高速缓存毒害攻击，或是对其他操作系统发起攻击
*** 黑帽SEO作弊手法十九：弹窗广告
　　弹窗广告是在网站中加入弹窗，通过采用标签或者Javascript实现，指打开网站后自动弹出的广告，无论点击还是不点击都会出现在用户的面前。
[[file:./tomsinsight-hack/弹窗广告.jpg][弹窗广告.jpg]] 
　　不管是导出到外部网站还是内部链接，对搜索引擎而言都是不友好的，有网站的朋友应该都知道,给客户做短期广告时候就加入了弹窗，由于种种原因，关键词排名会掉好多页，所以新站，尤其是PR、权重比较低的站，一定要注意，千万别做弹窗。
 
　　目前采用弹窗广告的在游戏行业中主要体现在web游戏上面，从追求流量的角度讲,MP3弹窗是目前利用最多的.曾经论坛回帖中利用过,后来转嫁到博客中.09年的时候新浪博文中加载mp3弹窗也算是比较流行的。
 
　　一般弹窗广告之中都具有强制性，并且可能包含挂马病毒，木马病毒。用户一般都对这种强迫式的广告形式很厌恶，而且现在大多数浏览器会提供一些插件来屏蔽弹出广告。
 
　　弹窗广告对百度SEO优化是一个致命的伤害，同时也看得出对用户体验不够友好。如果大家对自己的网站想往正规站发展做大做强就不要图眼前的利益，也去做做弹窗广告害了自己。
 
　　如果网站要长期的发展，就要细微之处见真情，如果打开一个网站，弹窗网页漫天飞，让你第一印象就是垃圾站一个，那么你留住的用户群就少的可怜了，更不用说你的流量了，没有了固定的访问群，你的流量也就是引擎收录的那些了，不利于网站的发展。并且现在百度对弹窗之类也表现得比较反感，还推出石榴算法。
 
*** 黑帽SEO作弊手法二十：刷站
**** 刷百度排名
　　各大站长讨论平台随处可见各种类似的广告，一种叫做“快速刷百度排名”的广告很是泛滥。如“三天排名进前三”、“24小时关键词上首页”、“6小时进百度首页”、“无需更新文章，动动鼠标就能排名”“3天上首页”“8小时前三”等的服务，根据百度指数收费几百到几千不等。
 
　　百度刷排名的原理一个基于用户点击的原理，百度认为质量高的网站必然是用户最喜欢点击的网站，搜索一个关键词，一个网站点击的次数越多，说明这个网站是更受用户欢迎的。通过不同的ip使用百度查询某一关键词，点击你要刷的网站，当一个网站点击的次数越多，那么百度就会认为这个网站是对用户最有帮助的网站，会在短时间内将其排名提前。从而通过欺骗百度的方式刷排名。刷百度排名的核心技术就是模仿大量真实IP搜索某个关键词并直接点击目标网站,一般是通过adsl换ip或者是换代理ip的方式刷排名。
 
　　目前刷百度排名的主要方式可以说是两大类，一个就是手工刷，一个则是软件刷。原理很简单，利用搜索引擎对用户的行为来判断我们的网站是否属于垃圾网站，是否应该给予网站排名，这个方面，在百度的web2.0反垃圾升级之后更加明显。利用点击原理刷上去的排名不能持久的主要原因就是网站受到的点击不是长期的，而是短暂的，自然排名也是昙花一现的。
*** 百度又是如何判断刷排名作弊的呢?
　　1.搜索和地域不相干的词。比如广东的Ip搜索“上海SEO公司”，那就肯定有问题了。并且对于地域类词语，不同区域搜索出的结果也不一样，也会造成刷排名是没法刷的。
 
　　2.Ip过多集中在同一区域或者是同一ip段。如果是用adsl拨号换ip的话，尽管ip能切换成不同的ip，但是始终都是在同一ip段内，并且ip所在地是不变的。如果点击某网站的ip过多集中在同一区域，也很有可能触发百度的人工审核。
 
　　3.不点击排名在前面的网站，而直接点击某一特定排名的网站。由于是刷排名，软件一般会通过定位或者是查找的方式，直接跳转到某一页中，点击某个特定的网站。这就和普通用户的浏览习惯方式大相径庭了。一般很少有人会不点击前面的网站链接，而直接跳过去点击排名稍靠后的网站，因此这也很有可能被百度发现。具体参看《[[my-anchor-baidu-ranking][点击对网站排名的影响]]》  
*** 刷百度下拉框(相关搜索)
　　百度下拉的官方正式叫法是百度推荐词(Baidu Suggest Word)，民间又称之为百度联想词或百度下拉菜单。是百度为了方便广大网民搜索，提高输入效率而推出的一项服务。
 
　　百度下拉的作用:大部分人在搜索某一个关键词的时候，其实他并不知道该如何组织语言以便更加精确的达到搜索目的，下拉框就为他提供了便捷。如果搜索词比较长的话、这样子也节约了时间，所以下拉框是很便捷的。
 
　　制造虚假搜索由于百度、google都提供了相关关键字的功能，于是有人就自己发明一些与热门关键字相关的关键字，比如说“土豆网”热门，他就发明一个“挖土豆”的关键词，预先自己先建立好相应的页面，通过搜索这个新的关键词能排到第一。然后通过软件在搜索引擎里不断地搜索这个关键字，于是这个关键词就出现在了相关搜索的位置，吸引用户点击搜索。
 
　　相关搜索是搜索引擎用户体验的一个部分。刷一些自造生僻的关键词出来,影响用户体验,明白人一看就知道是刷出来的,刷新量太高，百度人工核查时被发现，封锁关键字，重者K站。
*** 刷百度分享
　　通过百度分享按钮，您网站上的网页将更容易被百度搜索引擎所发现，从而有机会从百度搜索带回更多的流量。可以在搜索结果中,出现百度大拇指,就算排名不在第一,也会引导用户注意您的网站。
 
　　百度分享根据百度官方的说法:
 
　　1).用户将网站内容分享到第三方网站，第三方网站的用户点击专有的分享链接，从第三方网站带来社会化流量。
　　2).使用了百度分享的网页可以更快地被百度爬虫发现，从而帮助网站的内容更快地被百度抓取。
　　3).使用了百度分享的网页被用户分享后，可以使该网页被分享的次数展示在百度的搜索结果页中，辅助用户判断网页质量。
 
　　搜索引擎本身的运营指导方针就是不断的提高SEO的质量，提供访客更具价值的信息，并且它希望所有的站点都可以遵循其制定的游戏规则走。作为国内最大的搜索引擎百度推出这一分享工具的初衷是为了提供给他们可以一个更加有价值的搜索结果。我们假设其对我们的排名有一定的作用，而你采用刷的方法来提供这一数值，这种行为无异于购买链接，你的站点将有可能面临搜索引擎的惩罚。
 
　　如果只是单纯的分享，造成网站的跳出率高，这样的分享应该算是做弊,因为软件刷都是自动定时换IP进入网站分享之后关闭页面，所以不仅造成PV过低而且跳出率很高。因为半夜12点-早上8点的时间段自然IP很少，但软件刷分享的IP很多，造成了每天早上一打开统计，看到网站的跳出率都在90%以上。使用不正规的手段来刷高百度分享小拇指的分享次数可以说弊大于利，而对于一个站点如果你想要累积你的用户群，站在用户的角度来建设站点才是真正的成功之道，切勿使用这些旁门左道来投机取巧。
*** 刷网站流量
　　通常说网站流量是指网站的访问量，是用来描述访问一个网站的用户数量以及用户所浏览的页面数量等指标，常用的统计指标包括网站的独立用户数量、总用户数量(含重复访问者)、页面浏览数量、每个用户的页面浏览数量、用户在网站的平均停留时间等。
 
　　刷网站流量(alexa流量和IP流量)对网站排名的危害:
 
　　(1) 流量大起大落存作弊嫌疑
　　由于平台刷流量的速度是非常快的，一天的IP量就有上万，一个网站流量每天上百就已经是很不错的网站了，一个新站流量突然间由原来的一天不到10个增加到一天上万，作弊嫌疑相当明显。
 
　　(2) 重复IP严重引起注意
　　由于同一个刷IP平台的用户也就几千个人，长久互刷IP重复严重，很容易引起搜索引擎和alexa的注意。
 
　　(3) 页面浏览时间太短
　　由于使用软件平台刷IP，软件打开页面以后就要立即关闭，否则浏览器无法承受同时打开太多的页面，所以页面浏览时间是很短的，而且即便是真的是网民自然浏览的话，一个网站浏览的时间过短也从一个侧面证明该网站可读性不强，用户体验不好，不能留住客户。
 
　　(4) 流量不均匀
　　尤其对一个新网站，刚开始的时候没有流量，一天每个时间段内IP访问量几乎是零。当你打开软件刷流量的时候，IP访问量瞬间增加到几十，几百甚至上万，严重的IP访问不均匀，被搜索引擎和alexa降权也是情理之中了。
 
　　(5) 外链和流量严重不平衡
　　新网站在几乎没有高质量外链的前提下，流量上千甚至上万，即便是一个网站高手都不能够做到，更何况一个新的草根站长。想要骗过搜索引擎和alexa这样的顶级公司就更是痴人说梦了。当然上面说的都比较极端，其实合理的刷流量根本不会带来搜索引擎的惩罚，对网站排名确实有一定好处，不过这仅仅是为了seo而seo，网站带来的流量都是子虚乌有，不过等你排名上去了，同样是可以获得更多有效流量，这和购买链接是一个意思。
 
　　关于刷流量问题具体可参看《[[my-anchor-flow-attack][全方位解析网站流量超额和流量攻击]]》。
 
　　好了，20种黑帽seo手法已经全部说完，搜索引擎在进步，算法也一直在改变，黑帽作弊手法都是为了短期牟利，达不到长期的排名。并且随着搜索引擎的制约，这个牟利时间会越来越短而且越来越少。但是大家都知道黑帽seo就是利用搜索引擎的一些弱点，所以合理的利用黑帽seo，或从黑帽seo中学习优化手法也是现在很多人用的，希望大家也能够发散思维、活学活用，始终把握网站质量和用户体验。
** DONE #<<my-anchor-pictural-linkwheeler>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dwm8.html][图解seo链轮]]
     CLOSED: [2015-11-22 Sun 18:28]
     - State "DONE"       from ""           [2015-11-22 Sun 18:28]
标签： seo链轮 站群 博客群 链轮 图解seo链轮	分类： SEO策略技巧
*** SEO链轮(SEO Link Wheels)
　　SEO链轮(SEO Link Wheels)是从国外引入国内的，一种比较新颖的SEO策略。是一种比较先进的网络营销方式。SEO链轮是指通过在互联网上建立大量的独立站点或是在各大门户网站上开设博客，这些独立站点或是博客群通过单向的、有策略、有计划紧密的链接，并都指向要优化的目标网站，以达到提升目标网站在搜索引擎结果中的排名。
 
SEO链轮是指通过在互联网上建立大量的独立站点网站或是在各大门户网站上开设博客，这些独立站点网站或是博客群通过单向的、有策略、有计划的紧密的链接到一个要优化的目标主网站(或主关键词);同时各站点或者各博客也依次互相紧密链接，形成一张紧密的蜘蛛链接网，将主目标网站(或者主关键词)团团围住，以达到快速增强目标主网站(或主关键词)在搜索引擎结果中的权重，进而获得非常好的排名的策略目的。
 
seo链轮的工作原理是为要进行优化的网站建立高质量的单向导入链接，从提高网页的排名。在搜索引擎眼里，单向链接比双向的链接具有更好的权重，能有效提高网页在搜索引擎中的权重,而seo链轮正是充分利用这点。除此之外，Linkwheel还可以通过网站建立的单向链接，有效传递网页权重，使PR值高的网页能把权重传给PR值较低的网页，linkwheel还加大了搜索引擎抓取网页的几率。
*** 一般seo链轮策略分两种
站群或是博客链轮(BLOG-LinkWheeler)，两者的区别大概分为以下几种：
**** 资金投入
建立站群要比建立博客群投资大。因为，建立站群不但要买域名还要买空间，而且网站都要使用不同的IP地址，以防止很容易被搜索引擎看穿。如果用免费空间，那会有诸多限制条件，用起来很不顺畅，也不稳定。而建立博客群，不需要任何资金，各大门户网站都可以免费建立自己的博客。
**** 技术层次
建立站群时每个网站都需要安装独立的建站程序，无疑增加了自己的劳动量和技术操作程度。虽然有很多开源的建站程序，但安装起总还是需要你懂点技术、程序的。而建立博客，只需要你会注册邮箱，再注册个ID，那么你的博客就开通了。
**** 维护上
站群，每个站都需要你去定期地维护，有时会遇到空间问题，有时会遇到域名解析问题，有时会遇到备案问题，有时会遇到不和谐问题等等，而门户博客却没这类问题，发文章时有不和谐词语，你也发不了，更省去了备案的烦心事。
**** 损失程度
虽然，用站群或是博客群进行SEO链轮策略时，操作不好都有可能会被搜索引擎K掉，先不考虑都被K后，目标网站影响程度如何。可以肯定的是K掉博客总比K掉群站的损失度要小得多。因为，投入的资本大小不同。
**** 权重传递
在权重传递方面来说，站群更具有优势，毕竟站点都是一级域名，而博客基本上都是二级域名。权重传递肯定会比博客群效果好。
*** SEO链轮的优势
SEO链轮的好处是，不仅可以传递网站权重，当蜘蛛爬进来的时候，可以在里面打转，增加页面爬行的广度和深度。增加网站的收录量和访问量。 
SEO链轮策略是一个有组织、有策略、有计划的链接系统。他会使博客与博客之间也有紧密的链接，每个博客不再是一个个独立的个体，那么每个独立博客的权重也会得到相应的提升。每个博客权重提升后，自然对目标网站的投票能力度增强，目标网站的权重、排名将会有质的提升。
**** SEO链轮的缺点
**** 耗费时间
不管是用站群还是用博客群进行SEO链轮策略时，都不是随便添加几篇文章就可以一劳永逸的，更多的时候是需要有策略、有计划地更新。需要投入精力细心去琢磨的，工作量相当的大，浮躁的人肯定是做不来的。
**** 让人无聊
在进行链轮建设时除了脑力劳动外，更多的还是体力劳动。不仅蜘蛛会在链轮里一直转，你也会在里面晕头转向，短时间还可以忍受，时间一长，如果你从中找不出乐趣的话，更多的就是无聊了。 
**** 周期长
建立这些链轮前期是需要你静下心来慢慢养的，等链轮中的站点或是博客的PR值、权重全都提升到一个乐观程度上时，目标网站的权重、排名将会有质的飞跃!不过整个过程是很漫长的，独立站可能好点，其它博客就很难养了。
** DONE #<<my-anchor-baidu-market>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dh7z.html][百度竞价（推广)与seo优化]]
     CLOSED: [2015-11-22 Sun 18:25]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 18:25]
百度竞价排名是把企业的产品、服务等通过以关键词的形式在百度搜索引擎平台上作推广，它是一种按效果付费的新型而成熟的搜索引擎服务。用少量的投入就可以给企业带来大量潜在客户，有效提升企业销售额。竞价排名是一种按效果付费的网络推广方式，由百度在国内率先推出。企业在购买该项服务后，通过注册一定数量的关键词，其推广信息就会率先出现在网民相应的搜索结果中。目前已更名为百度推广。
 
    [[my-anchor-inner-SEO][SEO优化]]，是对网站进行调整，进而获得百度快照的自然排名。网店代销至于如何对网站进行SEO优化，博客有些文章讲的比较详细。
*** 百度竟价和SEO优化有什么关系?
　　可以这么说，百度竟价和SEO完全没有关系，只不过他们都是SEM营销中的两个不同的操作方式，一种是出钱，一种是所谓的SEO技术。
 
　　百度竟价对网店代理有促进作用，如果两个网站都采用这两种方式，其实表面看起来没有什么，但是竟价会给网站带来非常自然的用户群，这就是网站SEO优化所需要的资源，有人认为经过百度竟价的网站同时做SEO，效果比不做百度竟价的快些，记得是自然的，那种不自然的没有太大的用，比如刷流量。至于到底有没有关系就众说纷纭了，2者的使用度要平衡，
*** 百度竟价会影响SEO效果吗?
　　百度竟价和网站快照是两个不一样的管理系统，服务器个人认为也是不一样的，因为这两块是不同的用途和目的。百度竟价是为了公司发展;百度快照是为了给用户提供更多相对好的搜索结果资源。
 
　　那么到底是seo优化好还是竞价好呢，下面说一下两者的优缺点
 
　　竞价排名在网络营销中有着非常多的优势，主要表现在以下几点：
　　一、按效果付费，根据点击量收取费用;
　　二、网站会在搜索引擎靠前的位置显示，容易吸引客户点击，效果显著;
　　三、关键词单价和推广费用可以控制;
　　四、见效快，设置关键词价格后即刻就可以进入百度排名前十，位置可以自己控制;
　　五、关键词数量无限制：可以在后台设置无数的关键词进行推广，数量自己控制，没有任何限制;
　　六、关键词不分难易程度：不论多么热门的关键词，只要你想做，你都可以进入前三甚至第一。
*** 竞价的缺点：
　　1、被取代性高。百度竞价的竞争程度很高，尤其是越是热度很高的行业，比如整容、医疗。网站被随时取代的情况屡见不鲜。
　　2、同业恶性点击。同行业的恶意点击的情况也是有的，一些同行业为了打压你的网站，外聘很多水军，恶意点击计划。但是，现在百度掌握了一些基本的识别恶意点击的技巧，实行了恶意点击不计费的制度。但是一些高质量的恶意点击，百度现在还不能判断。
　　3、价格越来越高。如果客户的网站需要排名在第一位，在同等质量度星级的时候，就要在出价高于其他竞价网站，但是随着行业竞争的激励，竞价的价格也是水涨船高。竞价的成本越来越高。
　　4、覆盖面只限在百度搜索引擎。
*** SEO的优点：
　　1、不易被其他网站取代名次。通过SEO手段运营的网站，一旦获得好的排名，一般能获取很长时间的排名。不容易被其他网站所代替。
　　2、为自然搜索结果。SEO运营的网站，都是显示的自然搜索结果，这样看起来更加真实可信。
　　3、品牌形象建立。利用SEO手段运营网站，能让自己网站的形象和品牌得到很好的建立。扩大用户的份额。
　　4、上线越久成本下降。SEO手段运营网站，网站上线越久，现对而言成本就越低。
　　5、长期效应 — SEO优化能够帮助你提高网页的综合指数，如果你的网站排名已经得到提升，除非后期应用了作弊的方式而受到惩罚或停止后期的维护，否则排名是不会轻易下降的。而竞价广告如果停止了，网站排名也就即可消失。
　　6、覆盖面 — SEO优化是针对大部分专业搜索引擎的，你的网站不仅在百度、google上得到排名提升，同时在其它各大搜索引擎也会提升你的网站排名。而选择竞价广告方式要达到这一效果则必须和各搜索引擎签订广告协议，这无疑增加了巨大的成本。
*** SEO优化的缺点：
　　1、显示效果较慢。通过SEO手段来运营网站，需要周期性的时间，一般的周期是三个月看到效果。所以说网站的排名显示效果较慢。
　　2、关键字排序位置精确预估较难。现在估计没有一个SEOer能准确的的预估网站的排名。因为做SEO的，只能大概性的预计网站的排名，因为搜索引擎是自家商业性质的服务机构不是SEOer所有的。
** DONE #<<my-anchor-hidden-links>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e5xq.html][全方位解读网站黑链]]
     CLOSED: [2015-11-22 Sun 18:27]
     - State "DONE"       from ""           [2015-11-22 Sun 18:27]
标签： 黑链 暗链 隐链 什么是黑链 查找黑链	分类： SEO策略技巧

*** 什么是黑链
　　黑链，也叫暗链、隐链。顾名思义就是以用不正当的手段在你的网站挂上别人链接，通过网站程序漏洞、服务器漏洞拿到网站的webshell之后加入暗链，这类网站一般管理疏忽，多见于gov、企业站，PR和权重都比较高。所谓的暗链就是将链接文本的颜色做成与网站背景色一致，或者是通过隐藏层。这样做是为了不让别人发现，这样做已经存在欺骗搜索引擎的嫌疑，但是现在的搜索引擎不是万能的，它不能区分暗链是站长自己加的还是别人挂上去的，这个漏洞也是很多人实行黑链策略的原因之一。使用黑链的大多数为比较热门行业：私服、医疗等暴利行业。黑链都是单向链接，权重比较高，对于网站的排名很有一定帮助。 
　　黑链的含义是：站点被黑客利用技术入侵，并且取得权限，经过代码的添加，实现隐藏的一个或者多个导出链接，这样的方式是为了不让站长以及管理员发现链接的存在，实质上与正常的友情链接导出是没有多大区别的，黑链挂上后，在页面是看不见其链接与描述和链接的站名的，但是你利用各大站长站的模拟引擎抓取工具测试打开一下页面的源码或者导出链接后，你会发现实际上搜索引擎是认可这些链接，并且会抓取的。
*** 黑链好处
　　(1)短时间内突然导入自己网站众多高权重、高or单向外链，这样可以迅速提高排名，获得高额流量。
　　(2)黑链成本很低，而外链对排名很重要，花钱在PR5以上的网站做个链接少则上百多则500乃至上千上万，成本费极高。“不劳而获”、“物美价廉”的超值优惠，给不少站长带来了致命的诱惑，并且通过软件得到对方ftp用户名和密码，可以随挂链，获得超额利润。完全是空手套白狼!
　　(3)买黑链的网站一般都是暴力行业的网站。两性站、减肥、医院、卫星电视等网站增加黑链迅速提高排名有益于他们快速获得优质客户，获得不菲的收入。
*** 被黑链的网站有哪些害处?
　　(1)一般被挂的网站很多是公司性质、政府教育机构等网络安全意识单薄的机构，而这些网站由于权重高，pr高，挂入黑链能很快起到提升权重作用，这些网站也是黑客主要攻击的目标。但是一个网站被过多的挂入黑链，很容易打不开网站，严重影响某些公司的业务往来。
　　(2)因为黑链一般都是违法的网站，企业公司等网站被挂入黑链后被挂的网站很容易被搜索引擎惩罚。主要表现首页被K，甚至全站被K。因此给企业在搜索引擎中的排名带来极大的危害。
　　(3)被挂的网站很容易被搜索引擎或浏览器注意到，网站打开后会主动提示有病毒等信息，给用户的体验度带来极大的影响。
　　(4)被挂黑链后你的权重会流失。
*** 常见黑链的形式
**** 黑链代码一、链接颜色与背景颜色相同，链接文字小于或等于1像素。
　　<a herf=# style=”color:#FFFFFF;font-size:1px;line-height:1px;”> 黑链购买 </a>
 
　　<NOSCRIPT>
　　<a herf=# style=”color:#FFFFFF;font-size:1px;line-height:1px;”> 黑链购买 </a>
　　</NOSCRIPT>
　　这种情况很常见在一些论坛的帖子里面，当论坛不允许发锚文本链接的时候，有的站长就很喜欢在帖子里做，这样不注意是看不出来的，完全和背景一个颜色。当然，你也可以将黑链代码分开来写。
　　<a herf=# style=”color:#FFFFFF;”> 黑链交易 </a>
　　<a herf=# style=”font-size:1px;”> 黑链交易 </a>
　　<a herf=# style=”line-height:1px;”> 黑链交易 </a>
　　对于这种黑链代码的写法，我建议不要使用，字体颜色弄成白色，以及字体像素为1，这种很可能会被搜索引擎识别出来。
**** 黑链代码二、链接位于网页可见范围外。这种黑链代码有两种写法，分别如下。
　　<div style=”position: absolute; top: -999px;left: -999px;”>
　　<a href=#> 黑链交易 </a>
　　</div>
　　<div style=”position:absolute;left:expression_r(1-900);top:expression_r(3-999);”>
　　<a href=#> 黑链购买 </a>
　　</div>
**** 黑链代码三、链接以跑马灯形式快速闪现。卖黑链的人基本上都是采用这种方式，将你的链接快速闪过。但是有点问题就是，在个别浏览器下会显出原形。
　　<marquee height=1 width=5 scrollamount=3000 scrolldelay=20000>
　　<a href=#> 黑链购买 </a>
　　</marquee>
**** 黑链代码四、通过CSS样式控制层展现。这种黑链写法被过度用于SEO作弊，搜索引擎对它很敏感。
　　<div style=”display:none;”>
　　<a href=#> 黑链购买 </a>
　　</div>
**** 黑链代码五、JS代码控制链接展示。搜索引擎对JS代码有点不买账。
　　<script language=”javascript” type=”text/javascript”> document.write(“ div style=’display:none;’ ”);
　　</script>
　　<div>
　　<a href=#> 黑链购买 </a>
　　<script language=”javascript” type=”text/javascript”> document.write(” /div ”);
　　</script>
**** 黑链代码六、高级复合形。
　　<div id=”linksID”> <a href=”#”> 黑链购买 </a> </div>
　　script document.getElementByIdx_x_x_x_x_x(“linksID”).style.display=”none” /script
**** 黑链代码七、JS调用跑马灯闪现。该写法是将代码是跑马灯黑链代码和JS的结合产物。
　　<script language=”javascript” type=”text/javascript”> document.write(“ marquee scrollAmount=5000 width=’1′ height=’5′ ”); </script>
　　<a href=”#”> 黑链购买 </a>
　　<script language=”javascript” type=”text/javascript”> document.write(“ /marquee ”); </script>
**** 黑链代码八、高级隐藏层。
　　<div style=”position:relative”>
　　<div style=”position:absolute;left:0;top:0;z-index:999;width:90%;height:100px;border:1px solid #333;background:#eee”> 遮挡层 </div>
　　<div> 隐藏内容 </div>
　　</div>
    如果真不在乎关键词排名，只是针对PR的，那么你完全可以挂个明链，做的不显眼就是了，比如原来没有超级链接的地方给他做上链接，或者给一个标点符号做上你的超级链接。这些完全需要动动大脑就可以了。
**** 这么多代码，到底那种黑链代码的写法最好呢。
   含有display:none;的黑链代码已及使用JS的黑链代码不要使用,搜索引擎比较敏感并且用处不大，那么剩下的就只有跑马灯和显示在可见范围外这2种选择了。找黑链的时候可以多留意。
*** 如何检查网站黑链
　　对于很多在网站管理方面还很年青的站长来讲，其网站一旦被挂了黑链，都会担心自己的网站排名会受到影响，但自己又找不到原因。那么我们应该怎么样有效的防止自己的网站被挂上黑链呢?
**** 第一点、要做到定期查看网站的源代码
　　黑链都是挂在网站首页的源码里面。或许某些出售黑链的朋友也会有喜欢挂在网站内页的喜好，这样可以稍微加深一点难度吧，站长需要经常查看网站的源代码，点击网站文字位置，右键，有一个“查看源文件”的选项，点开即可查看。如果你自己的网站设置了禁止右键，可以通过下载一些比较好用的浏览器，来查看网站源代码。在这里我个人就给大家推荐一下火狐浏览器。因为火狐有friebug插件其对于网站查看源码有着很强大的功能。
**** 第二点、使用站长工作检查黑链、死链
　　作为站长，我们应该做到定期的使用站长工具查检网站的死链、黑链。站长工具都有查看网站页面的功能。可以查看网站的所以页面的链接。这个工具即可以查看你网站里面的链接可否访问，也可以显示出网站页面里所有的链接，当你发现有未知名的链接时，马上采取相关措施，删除此链接，有可能是黑链。
**** 第三点、查看网站里的文件最后修改时间
　　这一点对于许多的站长都是比较难做到。但是如果你是一个对于网站有记录的站长话，其是很容易看出来。作为站长，我们要记录好自己对于网站做了哪些改变。在网站中，每个文件都有自己的最后修改时间。如果没有修改时间，其系统也会按照文件的创建时间来显示。如果突然看到某个文件的修改时间变成了与现在相近的时间，那么你的这个文件就有可能已经被人家动了手脚，被修改了文件源代码，挂了黑链，现在你最好是把这个文件下载到本地，详细查看一下文件源代码里有没有挂黑链的痕迹。
**** 第四点、更换网站FTP用户名与密码
　　对于网站被挂了黑链，很多的情况下都是因为给你网站挂黑链的朋友用非法的手段取得了你网站的FTP密码。特别是你的网站FTP密码设置的非常简单的时候，如“123456”之类的纯数字，可以说是没有特别安全性可言。这种情况下，他们就更好对你的网站“下手”了，我们需要设置的复杂一点的密码，可以设置为大写、小写、标点符号相结合的密码，修改下至少可以安全一些，不要等到被挂黑链了才想起来需要修改密码，那就来不及了。并且处理完黑链之后也要及时修改密码。
**** 第五点、确定是网站被挂还是服务器被挂
　　可能很多新的站长还不知道，在站长工具里面有一个功能可以查同IP下的站点。很多的情况下，其也有可能是网站的服务器被挂了链。这个时候我们就需要使用站长工具里的“同IP站点查询”功能，查询到跟你网站在同一服务器的部分网站，如果你自己的网站被挂黑链了，那么你在查一下同一服务器的其它网站，当你查到其他的某个网站也有被挂黑链的时候，这时候我们就可以怀疑到服务器安全的问题了，而不是自己网站程序的漏洞问题，现在要做的事，就是马上联系服务商，让他详细做一下服务器安全策略。
**** 黑链的清除
　　知道了黑链的所在，也就好办了，大家只需将网页中的这些黑链肃清掉就可以了，不过有些黑链是调用的，这时分你要找到这个调用的文件，让后将其删除，这样干才将黑链完全删除。但光删除首页的黑链数据是不够的，因为有些黑客会通过程序将“黑链”挂遍你网站的每个页面，这样我们在清理的时候就需要借助一些批量文件内容替换工具了，例如“文本替换专家”，以某个“黑链”为关键字进行搜索并替换即可。
*** 黑链杂谈
　　黑链对网站排名真的有好处吗?其实试想一下，这么多权重高网站链接到你的站点，对自己的排名肯定是有好处的，黑链的好处就在于能够以低价买到高权重的链接。
 
　　黑链最大的问题在于不稳定，黑链通过不正当手段挂在别人网站上，一旦网站管理员发现，即会去掉这个链接，对于搜索引擎怎么看呢?今天我在这个网站上爬到了这个链接，明天再来就爬不到这个链接，搜索引擎对于外链的态度是链接的时间越长，链接越有价值。要是这种情况频繁出现，搜索引擎会怎么想?这点大家自己去体会。
 
　　那黑链到底用不用呢?如果你发现你的竞争对手已经大量使用黑链并且排在你前面好几页的时候，也许你不得不考虑黑链，但是选择黑链不要一次导入太多，一次导入黑链的数量应该控制在5---10个左右，制定好自己网站的外链策略，然后用大量原创内容更新填充来掩护黑链，选择黑链的时候也需要凭自己的经验去观察这个网站，是否管理得比较严格或者疏漏，对方管理员很厉害的话，你还是放弃吧，多一个死链而已，所以尽最大努力做到外链的稳定。
 
　　如果你是正规站，那就最好不用选择黑链，坚持更新和外链，是你网站发展的重点。如果垃圾站或者暴利行业网站想短时间迅速取得排名，可以购买黑链(比较黑链的投资成本低)，我能告诉你，控制好黑链的数量，排名很有效果。
 
　　SEOER在互联网采用黑链这种不正当的竞争，搜索引擎们也在不断的改进算法，会有那么一天，搜索引擎们对黑链的判断会变得很准确，打击力度也会加强。所以，选择黑链并不是长久之道。

** DONE #<<my-anchor-link-decoy>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dvzp.html][你知道链接诱饵吗？]]
     CLOSED: [2015-11-22 Sun 18:54]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 18:54]
标签： 链接诱饵 外链 链接 外链诱饵	分类： SEO策略技巧
　　链接诱饵简单的说是指的是创建有用、有趣、吸引眼球的内容，从而吸引其他站长、博主的注意力，生成的外部链接。现在的链接诱饵，在SEO的外部链接建设中成了新一轮的焦点。搜索引擎优化专家们给靠内容来吸引导入链接起了个有趣的名字：链接诱饵(Link Baiting)。
 
　　合理规划的链接诱饵页面，能够让网站获得数量极其庞大的反向链接，这不仅可以提高网站的曝光度和访问量，更重要的是，这些链接是自然获得的，而且具有较强的文本相关性，能够有效地提高网站的链接广度，从而提高网站在搜索引擎中的排名。
 
　　高质量的外部链接对于快速提升网站权重有着功不可没的作用。而现在随着搜索引擎对垃圾链接的打击，seo人员做高质量的外部链接没有以前那么容易了。不过链接诱饵仍然是一个不错的方法，只要你知道链接诱饵怎么做，如何控制好链接诱饵。链接诱饵这个词指的是专门为获得链接目的而创建的内容。内容发布在自己网站或者另外一个网站上，有足够的吸引力使很多人愿意链接过来。链接诱饵做得好可以获得大量的流量。 
*** 链接诱饵七大特点： 
**** 第一、选择对象：
链接诱饵的最终目的是链接，能够给予网站链接的并不是普通的用户，而是站长、博主以及活跃会员。所以首先要考虑的是网站管理员的需求而不是普通用户的需求。要知道这类人群对什么比较感兴趣，方向正确了，事半功倍，否则事倍功半。
 
**** 第二、不要太刻意：
我们都想自己的网站能快速有好的外部链接，但是不要过于追求速度。有时候很刻意制作的链接诱饵常常没有效果，反倒是偶然写的帖子和文章有不错的效果。建议在制作的时候不要带有太强的目的性，因为大部分站长很清楚哪些东西真正有价值。
 
**** 第三、注意标题：
现在互联网信息层出不穷，所以再好的内容也需要有好的标题去点缀，特别是资源性链接诱饵，好的标题就是成功的一半。比如常常用的top5等等都是不错的标题。因为很多站长都觉得此类东西有实用价值，所以愿意去转载。
 
**** 第四、注意广告：
链接诱饵虽然是为了外部链接的建设，我们自己可以理解为广告的一种，但是千万不要穿插很多广告在其中。再好的内容如果穿插很多广告在其中也会用户体验差，让人产生逆反心理。
 
**** 第五、易于推广：
在链接诱饵页面，我们应该在醒目的地方设置分享或转载按钮，现在rss订阅也比较受欢迎，可以让站长容易的分享。只要站长想分享，需要点击一下就能够放在自己网站上或者其它媒体中。有时，一些细微的变化就能让链接诱饵的成功率提高很多。
 
**** 第六、版面设计：
打开一个网页，用户首先看到的不是他的内容，而是他的版面设计。一个层次分明、排版整洁、颜色搭配合适的页面能让站长产生愉悦感和信任感，也就更容易吸引其分享。另外，在内容中加上图片、视频、列表等更容易让站长分享。
 
**** 第七、文章长度：
实验表明，过短的文章对用户的影响不是很强烈，文章的长度和权威度有时候成正比，虽然这个并不是一定的，但是有可能的话尽量把网站的内容制作的稍微长些，这样，带来的外部链接相应会多些。
 
*** 链接诱饵的种类 
**** 1.新闻诱饵
 
　　新闻是我们日常生活中必备的元素。不管是大街小巷的市井民生，还是行业内部的重大消息，都可算作新闻。新闻本身就能当做一种链接资源。我们也能看到，百度指数中，某个关键词在一两天内猛涨，这样的情况就是新闻爆发的效应。作为外链获取者，把握新闻的先机，能获得很好的推广效果。如何找新闻，很简单，通过微博，论坛，qq全还有行业中的大站，或者是国外网站等等，都能找到最新的文章。剩下的，就是发新闻链接诱饵了，首先是发到自己的网站上。随后，通过博客和论坛，去发新闻链接，一般发些简介和图片，再留个链接一方面能直接获取流量，一方面能获取链接的转发性。以新闻做为链接诱饵必须具备2个特点，一是够快够新，等其他网站都已经报道了，你在添上一笔，就不会有人注意。无论事情大小，第一个报道的总是获得眼球和链接最多的网站。二是够专业化，聚集于某个垂直领域，切勿贪多，最好还能有自己专业独特性的见解。如果大家想看一般性新闻就直接去新浪了，哪还会去你的网站来看，专业快速的新闻报道才能使用户产生依赖性，一想到某个行业就想到了你的网站。
 
**** 2.资源型链接诱饵
 
　　这是最简单也最有效的一类链接诱饵。提供某一个话题的全面、深入资源，就能成为吸引外部链接的强大工具。所谓说的资源，既可以是一篇深入探讨的教程或文章，也可以是连接向其他资源的列表。
 
**** 3.争议性话题
 
　　带有争议性的话题显然是可以吸引到眼球的，而且经常能吸引到争议双方你来我往的进行辩论，围观者的传播与评论。
 
**** 4.线上工具
 
　　网上seo方面的工具种类繁多，诸如查询PR值、查收录数、查外链、计算页面关键词密度、百度指数、长尾关键词等，既有搜索引擎提供的，也有站长们自己开发的工具。这些工具都是seo人员所需要的，所以好多站长们会在自己的博客上、网站上、论坛里推荐给其他人。其他行业相关实用工具也可以如此利用。
 
**** 5.插件
 
　　对有技术基础的公司，写插件或自己开发的程序等也是一个非常有效的链接诱饵。
 
**** 6.利益吸引
 
　　根据一些互利的因素获得其他网站过来的单向链接。不过很多网站在当利用结束后就会撤掉链接。
 
**** 7.幽默搞笑
 
　　笑话和段子是网上传播最快的内容之一。幽默搞笑的内容也经常吸引到很多外部链接，不过要合理的用来吸引。
你知道链接诱饵吗？

[[file:./tomsinsight-hack/SEO流程.jpg][SEO流程.jpg]]
*** 常见的链接诱饵的方式
**** 1.网络软文
 
　　网络软文里面插链接是一个不错的选择。因为软文可以在推广的时候大部分不会被判为纯广告而被编辑、管理员删掉。但现在百度打击力度大，需要注意的是，链接位置要对，插的链接不要太多，由文章直接转型成了广告。还有就是软文的核心内容要用户喜欢，所以要写一些最热，受欢迎的内容。
 
**** 2.征文活动
 
　　如果你不会写软文，那还可以征文，花少量的钱买链接诱饵，现在网上很多代写，征文应该难度不是很大。
 
**** 3.导出链接
 
　　导出链接?对!你没看错。这属于利益吸引，而你要做的暂时导出给别人而换取好的文章，但不保证长期免费链接。不过建议网站不是很牛就不要这样了。
 
**** 4.公益赞助
 
　　给一些公益组织网站赞助点费用，他们会为了你的爱心做链接的，而当同样有爱心的人经常发现你的赞助链接的时候，他们也会觉得你这个网站是值得尊敬的。于是你的单向导入链接开始不局限于那些被赞助的公益网站了。
 
**** 5.免费(下载)工具
 
　　这类链接诱饵，最容易做的，就是通过文档、图片、视频、软件等下载资源来制作话题，可以将资源放到论坛、百度文库、一些专业下载网站等地方供大家下载，记住，下载的资源一定要对用户有价值。这个方法是十分有效果的，特别是针对一些行业类型的资源。如果你觉得自己收集麻烦，可以在淘宝上花几块钱，能够买一堆这样的东西。如果有时间或能力制作一个简单实用的免费工具，不仅仅在下载站点可以获得链接，而你的工具升级将吸引他继续来的你网站，久而久之他厌倦了百度、下载站搜索来找你的更新版本。直接把你的网站加入书签或自己的博客收藏链接里了。
 
**** 6.话题链接诱饵
 
　　什么是话题。常见的凤姐，微话题，这样的都是话题。这里值得注意的是，我们的话题最好带有争议性，能够引起大家去辩论，传播的话题才是我们获取外链的目的。站长们可以通过对当前热门话题的反驳，名人的质疑来获取这样的链接诱饵。但是这样的行为，不要做成无事生非的了，自己掌握一个度。
 
**** 7.新闻资讯
 
　　看新闻是中国网民主要的互联网应用。而且搜索引擎对新闻的抓取频率高，传播效应快。所以你要做的时，发觉行业内的新闻，第一时间报道，如果你没有新闻权，那就第一时间评论，别忘了插链接，加“首发”之类的字样。然后向递交了搜索新闻协议的网站发送(百度指数旁边可以看到递交了新闻协议的网站)。
 
**** 8.炒作八卦
 
　　没有什么比互联网娱乐八卦更强大的链接诱饵了。互联网造就了一代又一代网络红人，但别人是看红人，我们要研究的是“链接诱饵”。你可以搜集一些热点或行业相关星系写一篇分析报告，也可以搜集文档、工具进行专辑整理。
 
**** 9.病毒营销
 
　　在销售产品的时候注明：“每买一件商品，你就将捐献一分钱给希望工程”。然后通过推介、CPA，网站联盟的类似阿里妈妈的模式进行病毒营销，宣传的重心当然不是阿里妈妈的推荐网站而是捐钱给希望工程。
 
**** 10.知识链接
 
　　百度知道、新浪Iask、SOSO问问、雅虎知识堂等的火爆一部分反应的是人们对知识了解的需求，还有一部分就是对新鲜陌生名词的了解。就如本文涉及的“链接诱饵”当然你做的准备是，做好链接。把诱导词做到搜索结果第一位，如果你选的词第一位已经被学科性网页代替，那选词存在着问题。然后你要做的是把这些贡献给百度百科等wiki网站，并进行集中的整理。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503

** DONE #<<my-anchor-original-creation>> [[http://blog.sina.com.cn/s/blog_c206a2c30101ebsq.html][你有你的原创，我有我的伪原创]]
     CLOSED: [2015-11-22 Sun 17:55]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 17:55]
标签： 网站原创 原创文章 伪原创 原创	分类： SEO策略技巧
　　网站内容的评判到目前还没有一个好的评价方法,虽然百度推出原创星火计划，但是作用目前看来也不是很大，它主要是靠用户进行内容的评判。而访问者的评判方法也很简单：好的内容继续阅读，不好的直接走人。
 
*** 衡量一个网站的内容好坏与否，可以通过几个大致的指标进行判断：
 
　　(1)自然的链接是用户主动转载了你的网内容，一个网站上的内容如果得到了用户的认可，那么对搜索引擎来说也是非常值得收录的，并且还能算做有价值的外链。
 
　　(2)通常情况下，访问网站的用户在网站上停留的时间越长，说明网站提供的内容就越有价值，用户愿意花更多时间进行阅读和浏览。
 
　　(3)如果网站内容够好，那么用户会访问多个相关页面，我们可以称之为PV。
 
　　(4)网站的内容质量越高，那么网站的老用户数量就会越多，新用户会再次来访你的网站，也就是RV(重复访问者)。
 
　　虽然网站的内容也没有统一的衡量标准，但是可以从上述几个方面大致看出一个网站的内容建设得当与否。如果将一个精心编排的网站内容和一个靠采集、复制过来的网站进行比较，可以很明显的看出其中的区别。
 
　　大家从事优化行业，对于站内的基石文章的更新一定是非常注重的，对于百度而言，站内文章的质量，直接影响到赋予站点的权重，好的高质量文章可以给文章带来意想不到的效果。今天我们就来讨论一下，百度蜘蛛是如何进行网站文章原创的判断的。也方便站长们更好的进行站内文章的更新。
[[file:./tomsinsight-hack/搜索引擎整体架构.gif][搜索引擎整体架构.gif]]
*** 首要，文章标题和内容的唯一性
 
　　蜘蛛来到网站，首要看的是页面的头部信息，若是蜘蛛发现有和索引库中一样的标题，则食欲就大减。文章的内容应具有唯一性，站内不要有太多的相同内容。注意的是搜索引擎不是人，它判断内容是根据文档指纹并非有人那么智能。这也是我们做伪原创的一个突破点。
 
[[file:./tomsinsight-hack/搜索引擎近似重复网页检测流程.gif][搜索引擎近似重复网页检测流程.gif]]
 
*** 其次，文章标题与网站内容的相关性
 
　　标题是网站的点睛之笔，好的标题能招引证户，但切忌做标题党，不然即便招引证户也只能添加跳出率，形成不良的用户体会。搜索引擎对此也反感，经过搜索引擎采集发现你词不达意，同样会降低信任度。
 
　　再者，文章内容阶段层次的独立性与主题的相关性及关键字的密度。
 
　　软文不同于通常的写作，更注重的是用户体会，除了内容的实用性，需注意文章的排版，阶段层次分明。切忌为了添加关键字的密度而堆积关键字。这也是做伪原创经常用到的，可以把伪原创做得比原创更受用户欢迎，尽管不可堆砌关键词，但是可以调整关键词密度。
 
*** 最后，文章的内部锚文字连接数量与外部连接多少
 
　　蜘蛛是顺着连接爬行，合理的內链不但能引导蜘蛛，还能引导用户检查更多的页面。外链的数量则影响着对应文章在查找成果中的排行，一起还能起到引流的效果，外链既导权又起了推行效果。不要说百度有星火计划了，我发一个原创为什么别人复制走了却在我前面。这与发布平台的质量、内链、外链等等都有很大的原因。
 
*** 还有发表文章的转发与引证次数。
 
　　转发与引证相当于第四点所说到的外链，是用户对内容的必定，自然而然也添加了查找引擎对网站的友好度。
 
*** 伪原创小技巧
　　虽说总在强调原创，但是实际上还是弄伪原创的多，也真的是很多优化工作者没有那么多时间去写原创。
 
(很多企业给优化人员的工作内容是很多的)那么我们就说说伪原创，伪原创同样是有很大用处，各大新闻网一家出新闻，其余的全部会挪用，这是伪原创。行业牛人发布的最新文章，你第一时间拿去投稿，通过率很高，这样是伪原创。收集改编权威性文章同样是伪原创。这些伪原创的收录率、访问量等作用相信做过的人都知道，就不用我多说了。网站内容无非就是获得用户访问和信任，所以你能第一时间把热点、最新、时效、权威性、学术性等的新闻发布到你的网站上，这就是你的资源，这就能获得流量。对于采集过时信息的，那只会让用户反感。就算是做伪原创也不能随便的去采集、复制粘贴、甚至有的连别人的链接也一起复制过去。伪原创也有它的技术：
 
　　1、跟从法：把每一个阶段的结束都添加一段话，可所以有情提示，小调查，或是其他文章的引荐。
 
　　2、添加法：在每篇文章的结束处添加一段话比方：以上是“标题”的内容，若是你对以上该文章内容感兴趣那么你可能对以下文章也感兴趣“随机调用几篇有关文章”，或许，你能够看看咱们为您引荐的“几篇引荐文章”，从而将原文章给主动伪自创了。这样大大的降低了页面的类似度。
 
　　3、拆分法：把原有接连的文章，均匀的截取变成2段3段或是更多，或把文章阶段的方位调整一下排放的次序，加点修饰。这个对搜索引擎来说毫无用处，但对于用户还是有用的。
 
　　4、隐身法：将一些没有实践用途的词用图像来进行替代，通过优化的GIF图像只要十几个字节，将文章中呈现的有些特定字或词进行隐身，也能够极好的。
 
　　这些只是找到要处理为伪原创的文章后的一些技巧，至于如何去寻找伪原创源就不多说了，仁者见仁智者见智，各行有各行的源。
 
[[file:./tomsinsight-hack/如何巧妙地写出高质量的原创文章.jpg][如何巧妙地写出高质量的原创文章.jpg]]　　

*** 注意事项
 
   第一，标题及内容不要出现一些敏感词汇。
                      
   第二，文章请勿内部出现“联系方式”“各种连接”等刺眼的词汇,特别是还放大字体换颜色的。
   很多平台也是不允许留的，文章中的联系方式一定要少，只留一个常用的联系方式就行啦。多了看着心烦。
 
   第三，网站尽量不要过多的出现转载的文章。
　　转载的文章，我们做seo的都知道，对自己对别人对搜索引擎都不是很友好，因此，少一点这样的文章，多增加一点相关行业的系统知识，慢慢的，你的站点会完全被百度所信任，那时候的站肯定极其稳定。当然转载有营养质量高的还是建议的。
 　
   第四，文章的无效链接尽可能的要少。
　　这样的情况容易在网站搬家后出现，或者你删除了一些文章后，其他的文章里包含该文章，这就间接地制造了很多死链接，如果后期随着这样的链接增多，对网站是很不友好的，唯一的解决办法就是增加404，打通网站各部分的链接，这样搜索引擎才会喜欢你的网站。
 
   第五，文章内部切勿过多的出现其他网站的链接。
　　一些人在做网站内部文章更新的时候，经常会复制一些其他网站的东西，而且这篇文章的内链大多数出自于这个网站，这样对自己的网站并不好，一定要格式化文字后，再发布在自己的网站内。
 
　　第六，文章尽量不要做成flash类的形式来给用户阅读。
　　如果你的网站不想被百度抓取，那就请你随意。你可以用robot.txt或其他办法去屏蔽搜索引擎的蜘蛛们。

　　第七，对于一些特别明显的文章，最好还是加个转自，最少是个纯文本介绍。这样能增加用户好感。
 
　　本文只是一个框架性的建议，并非详细学术性的指导，详情可以一一参照，如文中有不对的，欢迎大家指正。
** DONE #<<my-anchor-baidu-ranking>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dxip.html][点击对网站排名的影响]]
     CLOSED: [2015-11-22 Sun 20:14]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 20:14]
标签： 点击 点击排名 搜索引擎 点击软件	分类： SEO策略技巧
　　用户的点击行为可以分为两种情况：一是用户访问网站后，发现有效价值并继续浏览其他网页，停滞网页时间长或者进行其它操作，称为有效行为。显然另一种就称为无效行为。
 
　　搜索引擎最终目标是提供给用户有价值的信息，这可以从用户的点击行为来分析，通常有效行为点击的网站比无效行为点击的网站更有价值，搜索引擎也会通过研究用户行为数据并用于网站排名，以改善用户的搜索体验。
 
　　这样，点击排名软件就出来了，点击排名作弊手段，就是通过模拟用户的点击行为来提高自己的网站排名，虽然说点击优化在百度一轮又一轮的算法更新下，已是昨日黄花，效果已经微乎其微。
 
*** 排名点击的来源
 
　　随着搜索引擎积累的用户行为数据增多，搜索引擎也加入了用户行为分析。所以自然而然的出现了针对这一特点的作弊行为，这类作弊效果为什么会如此有效，原因也莫过于搜索引擎注重民主选举的一种体现了，按照常理来说用户点击越多的page自然也是最具价值的页面。
 
　　但是真正的搜索引擎点击评价应该是这样的：同一时间或者者说相应的周期内排名是固定不变的，那么这个时候用户点击是多样化的。
 
　　补充一点：一般情况下搜索引擎按照用户行为一般会把用户行为分为：
 
　　导航类：导航类用户基本上是寻找一些已知的信息，用户目标很明确。
　　信息类：一般用户是没有明确是意图，一般会去检索，不像导航类用户一样有明确要检索的内容。
　　事物类：事物类型客户的意图也是非常明确。
 
　　为什么要提到分类呢?的目的也是为了告诉大家其实搜索页面不仅仅会表现一种类型的页面，既然有用户分类，搜索引擎为了获得较好的用户体验同样也会把搜索结果划分成类似的几块来满足用户的基本需求。
 
　　当初的百度排名点击器也是按照这个逻辑一直在做，认为排名在100名内通过点击甚至是分时段的点击量来获得排名，可以说前期这类工具效果尤其突出，但是这只是钻了漏子。
 
　　按照常理来说，一个用户检索一个内容只点击一个page，的几率微乎其微。以前搜索引擎算法工程师没有想到这个问题。但是现在搜索引擎很容易就可以识别这类点击了。
 
*** 为什么排名点击工具现在out了，因为他具备这样一些用户没有的特征：
 
　　1.结果点击单一。
　　2.页面停留时间较短。
　　3.IP集中，其实这点根本就无需判断。
　　4.逆常规行为，比如直接去点击5页的某一结果。
 
　　而正常的用户绝对不会这样去查找结果，用户一般会点击2-5个结果页面。
 
　　不仅因为这些问题，现在百度搜索引擎，存在某一种猜测性算法来检测页面的用户体验度，就是通过2次页面的点击时差来计算页面的价值，比如可以直接计算页面平均停留时间，预计浏览页面数，跳出率等等。
 
　　当然点击器确实可以短时间内让网站排名提高，不过别高兴太早，只不过时候未到。
 
　　文章来自：木木seo  http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE #<<my-anchor-flow-attack>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e7qu.html][全方位解析网站流量超额和流量攻击]]
     CLOSED: [2015-11-22 Sun 18:22]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 18:22]
标签： 流量攻击 ddos攻击 恶意刷流量 刷流量 网站流量	分类： SEO策略技巧

经常看到有人说网站无法访问了，网站瘫痪了，网站服务器流量超额被暂停等等，下面就讲讲主要的2种情况：[[my-anchor-flow-fetch-method][网站流量]]攻击和恶意刷流量。
 
*** 网站流量攻击
 
　　流量攻击主要说DDos攻击，DDos攻击即分布式拒绝服务(DDoS:Distributed Denial of Service)攻击指借助于客户/服务器技术，将多个计算机联合起来作为攻击平台，对一个或多个目标发动DoS攻击，从而成倍地提高拒绝服务攻击的威力。通常，攻击者使用一个偷窃帐号将DDoS主控程序安装在一个计算机上，在一个设定的时间主控程序将与大量代理程序通讯，代理程序已经被安装在Internet上的许多计算机上。代理程序收到指令时就发动攻击。利用客户/服务器技术，主控程序能在几秒钟内激活成百上千次代理程序的运行。由于DDoS攻击往往采取合法的数据请求技术，再加上傀儡机器，造成DDoS攻击成为目前最难防御的网络攻击之一。
 
[[file:./tomsinsight-hack/DDoS攻击演示图.jpg][DDoS攻击演示图.jpg]]

　　DDoS攻击分为两种：要么大数据，大流量来压垮网络设备和服务器，要么有意制造大量无法完成的不完全请求来快速耗尽服务器资源。有效防止DDoS攻击的关键困难是无法将攻击包从合法包中区分出来：IDS进行的典型“签名”模式匹配起不到有效的作用;许多攻击使用源IP地址欺骗来逃脱源识别，很难搜寻特定的攻击源头。
 
**** 两类最基本的DDoS攻击
 
　　● 带宽攻击：这种攻击消耗网络带宽或使用大量数据包淹没一个或多个路由器、服务器和防火墙;带宽攻击的普遍形式是大量表面看合法的TCP、UDP或ICMP数据包被传送到特定目的地;为了使检测更加困难，这种攻击也常常使用源地址欺骗，并不停地变化。
 
　　● 应用攻击：利用TCP和HTTP等协议定义的行为来不断占用计算资源以阻止它们处理正常事务和请求。HTTP半开和HTTP错误就是应用攻击的两个典型例子。
 
　　下面是2中常见的攻击界面：
[[file:./tomsinsight-hack/HmDdos V2011 完美升级版.jpg][HmDdos V2011 完美升级版.jpg]]

[[file:./tomsinsight-hack/Netbot Attacker VIP 5.5 Version.jpg][Netbot Attacker VIP 5.5 Version.jpg]]

**** DDOS攻击原理
 
　　拒绝服务攻击即攻击者想办法让目标机器停止提供服务或资源访问。这些资源包括磁盘空间、内存、进程甚至网络带宽，从而阻止正常用户的访问。其实对网络带宽进行的消耗性攻击只是拒绝服务攻击的一小部分，只要能够对目标造成麻烦，使某些服务被暂停甚至主机死机，都属于拒绝服务攻击。拒绝服务攻击问题也一直得不到合理的解决，究其原因是因为这是由于网络协议本身的安全缺陷造成的，从而拒绝服务攻击也成为了攻击者的终极手法。攻击者进行拒绝服务攻击，实际上让服务器实现两种效果：一是迫使服务器的缓冲区满，不接收新的请求; 二是使用 IP 欺骗，迫使服务器把合法用户的连接复位，影响合法用户的连接。
 
**** 如何判断网站是否遭受了流量攻击呢?
 
　　可通过 Ping 命令来测试，若发现 Ping 超时或丢包严重(假定平时是正常的)，则可能遭受了流量攻击，此时若发现和你的主机接在同一交换机上的服务器也访问不了了，基本可以确定是遭受了流量攻击。当然，这样测试的前提是你到服务器主机之间的ICMP 协议没有被路由器和防火墙等设备屏蔽，否则可采取T elnet 主机服务器的网络服务端口来测试，效果是一样的。不过有一点可以肯定，假如平时 Ping 你的主机服务器和接在同一交换机上的主机服务器都是正常的，突然都Ping 不通了或者是严重丢包，那么假如可以排除网络故障因素的话则肯定是遭受了流量攻击，再一个流量攻击的典型现象是，一旦遭受流量攻击，会发现用远程终端连接网站服务器会失败。相对于流量攻击而言，资源耗尽攻击要容易判断一些，假如平时Ping 网站主机和访问网站都是正常的，发现突然网站访问非常缓慢或无法访问了，而 Ping 还可以 Ping 通，则很可能遭受了资源耗尽攻击，此时若在服务 器上用Netstat -na 命令观察到有大量的SYN_RECEIVED、TIME_W AIT、FIN_W AIT_1 等状态存在，而EST ABLISHED 很少，则可判定肯定是遭受了资源耗尽攻击。还有一种属于资源耗尽攻击的现象是，Ping 自己的网站主机 Ping 不通或者是丢包严重，而 Ping 与自己的主机在同一交换机上的服务器则正常，造成这种原因是网站主机遭受攻击后导致系统内核或某些应用程序 CPU 利用率达到 100%无法回应 Ping 命令，其实带宽还是有的，否则就 Ping 不通接在同一交换机上的主机了。
 
**** 防御方法
 
　　DDoS攻击的一个致命趋势是使用复杂的欺骗技术和基本协议，如HTTP，Email等协议，而不是采用可被阻断的非基本协议或高端口协议，非常难识别和防御，通常采用的包过滤或限制速率的措施只是通过停止服务来简单停止攻击任务，但同时合法用户的请求也被拒绝，造成业务的中断或服务质量的下降;DDoS事件的突发性，往往在很短的时间内，大量的DDoS攻击数据就可是网络资源和服务资源消耗殆尽。不管哪种DDoS攻击，当前的技术都不足以很好的抵御。到目前为止，进行DDoS攻击的防御还是比较困难的。首先，这种攻击的特点是它利用了TCP/IP协议的漏洞，除非你不用TCP/IP，才有可能完全抵御住DDoS攻击。不过这不等于我们就没有办法阻挡DDoS攻击，我们可以尽力来减少DDoS的攻击。下面就是一些防御方法:
 
　　1.确保服务器的系统文件是最新的版本，并及时更新系统补丁。
　　2.关闭不必要的服务。
　　3.限制同时打开的SYN半连接数目。
　　4.缩短SYN半连接的time out 时间。
　　5.正确设置防火墙
　　禁止对主机的非开放服务的访问
　　限制特定IP地址的访问
　　启用防火墙的防DDoS的属性
　　严格限制对外开放的服务器的向外访问
　　运行端口映射程序祸端口扫描程序，要认真检查特权端口和非特权端口。
　　6/认真检查网络设备和主机/服务器系统的日志。只要日志出现漏洞或是时间变更，那这台机器就可　能遭到了攻击。
　　7.限制在防火墙外与网络文件共享。这样会给黑客截取系统文件的机会，主机的信息暴露给黑客，　无疑是给了对方入侵的机会。
　　8.直接使用安全性和防护性更好的服务器，当然相应的价格也高一些。
 
*** 恶意刷流量
 
　　恶意刷流量相信大家都知道，就是别人用流量点击软件对你的网站进行流量堆积。
 
　　而对于网上面说，可能导致网站降权本人还在观望中，因为确实不敢肯定，但如果用正常思维来考虑的话，基本上出现降权的情况应该不存在。因为如果都是竞争对手进行恶意刷你网站的流量，那么你的网站被降权，其他人都会这样做，这样的网络环境会如何呢?百度搜索引擎在国内老大的地位将会被打破，虽然算法上肯定是有这样一部分的，但是应该所占的比例微乎其微。笔者也听有的人曾说过，流量猛增是好事啊，百度是不会因为流量的猛增而K站或者降权的，那么竞争对手这么做是为什么?目的无非是想将网站流量刷完，并让服务器关闭或者网站关闭，之前在网络上也发现了这样的情况，比如国家GVM机关的网站曾经被刷流量导致网站瘫痪。昨天本人也与流量软件公司进行沟通，问及了关于刷流量的影响，他们的回答是：不会被百度等搜索引擎降权，但是如果竞争对手使用，如果网站空间较小，流量较少的话，网站会被刷关闭或者服务器出现瘫痪状态。当然流量的突变肯定是会引起搜索引擎的注意，老站可能还好点，新站还是有可能被K站的，这样的例子也数不胜数。所以笔者觉得适当的对网站刷流量还是可行的，并且笔者在竞争对手网站都发现了这一点。

[[file:./tomsinsight-hack/竞争对手的刷流量行为.jpg][竞争对手的刷流量行为.jpg]]
 
**** 恶意刷流量的类型
 
　　从恶意刷流量的类型来分,大概可以分为两种,一种是少IP多PV,另一种是多IP多PV。
 
******* 一、少IP多PV(SEO适用)
 
　　此种情况IP数量不会太多，一个人可能会变换着IP对网站进行刷新，但可以变的IP是有限的，比如使用ADSL的不断拨号，可以变换IP，但效率不高，如果对方使用工具软件变IP，原理也是一样的，IP数量有限，有可能2-3个IP就产生了几十万的PV。可以这样理解,第一种是个别客户机对某个页面进行F5式的刷新,单纯的对一个页面进行刷新。此前遇到的就是这种情况的恶意刷流量，这个情况比较容易解决,只要判断出对方是恶意刷流量的,可以直接屏蔽ip。虽然这个问题解决方法并不难，但如果解决不及时，网站可能因为PV的突然升高或者突然降低而被搜索引擎放入沙盒。
 
******* 二、多IP多PV(竞价推广适用)
 
　　此种情况IP数量跟PV值不会相差很多，可能每个IP对应有2-3个PV，目前网络上存在大量这类型软件，只要你开这个软件，你就进行一个全国性的互刷圈子。通过挂机或者RMB购买可用点击或者刷新数。有些人利用此软件对百度的竞价广告进行恶意点击，或者对淘宝的直通车进行恶意点击，灵活应用，这种软件杀伤力不可小看。虽说百度或者淘宝有能力，或者有实力去组织或者建立一个反制这种软件的团队或者技术，但从商业角度来看，这种软件短期内是促进他们的广告收入的，长期来说，这种软件会导致不正当竞争，最终扰乱市场，从而影响竞价广告的根本利益。回到解决问题的方法上来，这种软件不单单是随机IP，而且智能到可以随机打开被刷网站的首页中的链接，还带有随机停留N秒的“浏览时间”，如此的仿真，又要如何来防范呢?这一点，真的是一个难题，就算是百度，我想也不能给出完美的解决方案。但是没有完美解决方案，我们也要退而求其次，寻找降低损失的办法。至于此处寻找解决办法，又需要从两方面分析：
 
　　1、对于[[my-anchor-baidu-market][网站SEO]]
 
　　对于网站SEO，这种刷流量似乎百利而无一害，所以这里就不去谈解决方法了，因为没有竞争对手会这样帮你刷流量。
 
　　2、对于竞价广告
 
　　对于竞价广告，此种恶意点击基本上是防不了的。那么要如何降低损失呢?网络上普遍的防恶意点击说法一般有两种，一种是限制关键词的消费额度，另一种是限制访问IP。在这里，第二种方法显然就不可行。那么第一种方法可行?随便用脑袋想想，都知道这根本就不现实，恶意流量关键词带有不确定性，不可能每个关键词都限制流量，最主要一点是恶意点击的关键词都是重点关键词，高转化的关键词，如果限制了费用，那就等于放弃了重点关键词的竞争。
 
**** 防御恶意刷流量
 
　　经研究，此类型软件种类多，虽说种类多，但都很相似，似乎是同一个源码，最大的特点是基本都依赖于虚拟机(vmware)，另外就是，这些软件的支撑用户都不多，大多几十个或者百来个人在使用。也就是说，我们通过屏闭这几十个或者百来个人的机器，还是有可能降低损失的。我们首先，要对访问网站的访客机器进行记录，这一点用ASP或者PHP都非常容易做到，然后是对比这些访问者是否近几天内有多次点击，关键词是否相同，如果一台机器点击某关键词的次数超过N次，那么可以初定此访客可能是恶意点击者，如果用户某关键词的点击量超过N+?次，说明此用户不听劝告，只能来硬的了，通过屏闭或者简单提示，让恶意点击机器无法再进行点击行为。这个方法虽说很笨，但总比什么都不做好。
 
　　首先要冷静下来，分析一下究竟是被哪种软件刷了流量，如果已经查明就要马上通知对方停止对网站的刷流量工作。同时做好上面说的关注，如果还是没有办法，首先要做的是观察空间的流量限制，要保证不会因为被刷而导致空间停止服务。一旦服务器暂停不稳定，网站非常容易受到影响。最后要做的是继续稳定发布高质量文章，做原来该做的事情，这点是不可以中断的，对方即使恶意刷流量也会是有限度的，如果没有效果，那么竞争对手也不会去做一件没有意义的事情。
 
**** 下面给大家分析一个网站流量超额的实际案例和解决过程（这是一个特例）:
 
　　被刷流量站长网站虚拟主机的流量超额暂停，该站长登陆主机管理后台查看数据报表，的确是超额了!为了避免网站被关闭，充了30元购买了10G备用流量，但时该站长心中总有些奇怪，于是开始对流量超额原因和解决办法进行分析。
 
　　该站长租用的主机每月流量限额是8G，超过10G会被暂时关闭，平均到每天的可用流量为266M，他点开了最近三个月的流量走势图，发现了问题。

[[file:./tomsinsight-hack/最近三个月的流量走势图.png][最近三个月的流量走势图.png]]
 
　　从流量走势图上看，在11月1日之前，网站流量一直是非常稳定的处于低流量水平，每天所消耗的流量仅仅在50-60M左右，远远低于266M的限额水平，从11月1日开始，流量开始猛增，到12月份甚至冲到了每天600M以上的流量，流量比之前提高了10倍!这本事就是存在问题的。是访问网站的人多了?于是该站长又进入百度统计的后台进行分析，发现网站近三个月内的访问IP数和PV数，一直很稳定，特别是12月份，还比9月份的访问IP数和PV数，还略略低了一些。所以因为访客增多造成流量超额这一点，可以排除。
 
　　那么是网站遭到了恶意攻击?或者是程序有问题?被挂了马?我马上对网站上的所有文件和本地文件进行分析对比，发现也不是程序或挂马的原因，而从流量的走势分析，又不像是被恶意攻击，没有哪个黑客会连续2个月时间24小时不休息的对我一个小站发动恶意攻击。特别是上面所说的DDos攻击完全可以排除。
 
　　最后该站长从主机空间里下载的网站访问日志文件中，找到了最终的原因：搜索引擎!
 
　　搜索引擎可以给网站流量，也就是正常的访问量，所以很多做网站的人会去做SEO，优化搜索的关键字排名，吸引更多的访客来访问网站，但是搜索引擎那无孔不入的搜索蜘蛛会将你网站空间中所有的资源共享给大众，而一旦网站中的图片、动画、音乐这些资源被搜索引擎盗链，特别是一些比较大的软件。其后果就是主机的流量被白白的消耗掉，这是我们这些有流量限额的个人小站承受不起的。
 
　　但是，上面这个还只是造成该站长流量超额的次要原因，最重要的原因，是被一个垃圾搜索蜘蛛盯上了!这个搜索引擎叫宜搜，其蜘蛛代号：EasouSpider，在访问日志中，居然有90%的访问记录，是这个搜索蜘蛛连续两个月每天24小时而且是每分钟都在该站长的论坛里乱爬，极大的消耗了他网站的流量，是造成网站流量超标的最大元凶!(见下图的访问日志截图)
　　
[[file:./tomsinsight-hack/访问日志截图.png][访问日志截图.png]]

　　找到这个搜索蜘蛛的官网，上面说遵守robots规则，于是该站长马上更新了网站的robots.txt，对这个EasouSpider搜索蜘蛛进行阻止，并且还对所有搜索蜘蛛屏蔽了网站图片和动画文件的采集链接。如下：
　　User-agent: EasouSpider
　　Disallow: /
　　User-agent: *
　　Disallow: /*.jpg$
　　Disallow: /*.jpeg$
　　Disallow: /*.gif$
　　Disallow: /*.png$
　　Disallow: /*.bmp$
　　Disallow:/*.swf$
 
　　经过近几天的观察和分析，他发现百度、谷歌两个大搜索引擎的蜘蛛很快有了反应，他们在进该站长网站时，会先访问robots.txt，可是这个EasouSpider根本对robots规则置之不理，仍然每分钟多次的对我的论坛进行访问采集。
 
　　于是该站长在主机后台对EasouSpider的多个IP地址进行阻止(见下图)

[[file:./tomsinsight-hack/对EasouSpider的多个IP地址进行阻止.png][对EasouSpider的多个IP地址进行阻止.png]]　　

　　效果仅仅维持了一两个小时，很快他发现这个蜘蛛又换了其他的IP地址继续对我的网站进行骚扰，而他的主机只能最多阻止10个IP地址，于是该站长对其进行了最严厉的封禁，在论坛后台设置对其183.60.212.*，183.60.213.*，183.60.214.*，183.60.215.*四个IP段全部禁止访问，同时为了避免其他类似搜索蜘蛛对网站的骚扰，防范于未然，他对论坛的图片展示、下载、搜索等功能进行了游客限制，避免那些不守规则的搜索蜘蛛对网站文件的恶意采集和盗链。
 
　　在做完一系列的组织和防范措施之后，网站的访问流量终于恢复了正常，每小时的流量消耗低于5M，每天的流量低于100M，尽管从主机日志看，搜索蜘蛛还在一刻不停歇的尝试访问，但已经带不走多少实际流量。
** DONE #<<my-anchor-flow-fetch-method>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dsuw.html][网站流量获取方法]]
     CLOSED: [2015-11-22 Sun 18:26]
     - State "DONE"       from ""           [2015-11-22 Sun 18:26]
*** 自然优化获取流量
　　这个方法还是目前用得最多的，seo做好了可以获得比较稳定的浏览量，具有长效性，可以起到建立品牌的作用。
*** 百度竞价获取流量
　　可以获得很定向的流量，一般产品成交率比较高。并且获得流量比较快，不像做seo需要一段时间优化工作。如果做的好的话，竞价排名可以产生立竿见影的效果。
　　关于自然优化和竞价排名就不多说了，两者的关系可以参看[[my-anchor-baidu-market][百度竞价（推广)与seo优化]]
*** 利用信息类网站获得流量
　　这种方法是在各种信息类平台发布企业相关信息及产品信息，这种推广方式可以获得流量、树立品牌，在有外链时还可以有seo作用，就不多说了。对于有自己产品和品牌的企业，效果更为明显。各类信息网站很多，有分类信息网如58同城、赶集网、百姓网，慧聪网等还有很多的　地方信息网，均可作为发布信息的平台。相信你在很多信息类网站搜索一个商品时都看到同一家商品的信息，你买这个的可能性就会大些。
*** 软文营销及获得流量
　　这个简单，就是我们常说的写一篇高质量的软文获得大量转载和好评，第一给企业打了广告，第二给优化网站带来自然外链，增加信任度。
*** 利用百度产品获得流量
　　百度产品比如百度知道，百度经验，百度百科，百度文库等产品首先是比较权威，群众基础好，信任的人多，浏览量大。然后通过百度搜索引擎访问的占80%之多，百度会照顾自己的产品，排名靠前。你利用百度推广百度会喜欢，对你的网站优化也有帮助。
*** 利用网盘获得流量
　　网盘上的文件访问量也可观。如果你的文件确实不错的话，还有可能被很多人推荐和转载。上传和你的网站或产品相关的文件。上传文件的时候，你可以把宣传文件一同打包上传。这样别人下载后，还会看到你网站的介绍，有兴趣的就会按照上面的网址打开你的网站。上传文件的标题尽量包含选定的关键词。这样有利于人们搜索，除了在网盘上可以搜索到，在搜索引擎中也有被搜索出来的可能性，这样流量就比较大了。现在总体来讲，网盘的访问量相对较小，但随着发展的日益成熟，流量会变得越来越大，早点行动可以抢占市场的先机。
*** 视频营销获得流量
　　利用视频来宣传自己的网站或销售自己的产品其实和文字是一样的。看多了搜多了用户自然记得了，广告作用也自然起到了。
*** 论坛营销获得流量
　　论坛营销可以做为主站seo的一个辅助方法。没有网站的，也可以做为一种独立的营销方式来使用。因为有的论坛的人气非常大，因此，我们在这些高流量人群的相关网站上发贴，可以给我带来源源不断的流量。甚至可以直接销售出去产品。
*** 博客营销获得流量
　　博客营销和信息平台营销、论坛营销其实是一样的。可以去高流量博客推广也可以自己养博客。
*** 微信营销获得流量 
　　现在利用微信营销的也越来越多，原因很简单，现在用微信的人多，流量大。并且微信操作简单容易上手。
*** 通过qq、邮件、其他即时聊天软件营销获取流量
　　拿qq举例，在中国使用QQ的人有多少就不用我多说了，正确的使用QQ和邮件甚至是QQ空间都可以带来很多的流量，但是值得提的是实用这个最好正对对用群体，并且用一个对方可以接受不反感的方法最好，其次QQ群发之类的对seo没什么实质用处。

** DONE #<<my-anchor-inner-SEO>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e974.html][网站内部整体seo优化]]
     CLOSED: [2015-11-22 Sun 19:19]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 19:19]
标签： seo 站内优化 网站优化 网站内部优化	分类： SEO策略技巧
　　[[http://blog.sina.com.cn/mumuhouzi][SEO]] 
是通过采用易于搜索引擎检索的合理手段，在网站规划，制作，推广等环节贯穿SEO的思维，使网站对用户和搜索引擎更友好(Search Engine Friendly)，从而通过自然搜索，低成本的引入流量并转化为销量。将SEO视为一种营销手段。而不仅仅是对搜索引擎的排名，排名只是争取流量的手段之一，目标是流量。最终目的是销量的转化，因此一定要清晰分辨手段和目标。在做其他seo优化手段之前，网站内部的优化一定要做好，网站内部规划好了，优化起来得心应手，事半功倍。
 
*** 第一：SEO的定位
 
　　在了解了SEO所有段之后，是不是所有方法我们都用，各种手段使用的力度如何，在整体SEO过程中所占的比重如何，哪种手段先用?哪些手段后用?
 
　　只有对自己的优化有一个定位才能做好内部优化，通常SEO的目标大体上分为企业推广站和大型商务站，根据这两者的定位，站内SEO是有着孑然不同的侧重点和执行手段，以及验证标准。简单的说，企业推广站大多以关键词为核心重点手段，主要目的是通过企业相关的特定关键词，获取一个相对满意的排名，从而达到企业宣传推广的作用。
 
　　而大型商务网站，则一般以流量提升作为检测标准，从而关键词就不能成为大型商务网站的主导手段。商务网站的最终目的是要完成销售，因此，流量提成被大型商务网站认可为盈利的必要条件。
 
*** 第二：SEO重点流程走向
 
　　确定了网站的定位和SEO的目标，确定了网站的SEO定位后，我们就得围绕我们目标利用一切合理手段巧妙的配合达到一个最佳优化效果，而不是对着一个部位使蛮劲，对着一个部位穷追猛打，一方面来看，会遇到发展瓶颈，导致用力不见效，另一方面来看，专注一个方面容易给人有“过度优化”的嫌疑，从搜索引擎来看就有极大的打入作弊“黑名单”的可能。
 
　　因此，在SEO的过程中，手段的筛选和组合是非常有学问和技巧，当然也贯穿着SEOer们对规律的全面认识以及通过规律做出的预见性判断。
 
*** 第三：站内seo具体措施 
　　这里重点描述在大型商务网站的整体SEO思路和流程步骤在各个流程步骤中SEO的相关手段：
**** 1：争取海量的[[my-anchor-page-record][页面收录]] 
 
　　这是是大型商务网站的一个必经之路，通过海量的页面收录，可以再搜索引擎的索引记录中扩散关键词的覆盖量，从而达到再搜索引擎争取到较高的页面曝光几率。当页面覆盖量到达一定程度，再审视网站的关键词流量，会发现成千上万的生僻关键词和一些特殊目标的高级搜索只达网站各个页面。虽然这些词语的单个流量，不如一个热门关键词，但是，成千上万的集合就不是一个热门关键词所能媲美的。
 
　　争取海量的页面收录就是尽可能的在热门关键词结果中出现的同时，尽量让自己的网站页面在剩下上亿的关键词中尽可能的出现一次[在生僻关键词中出现的结果，一般排到第一页甚至是前5名是很容易做到，而且容易保持]这样我们以1000次曝光换1次流量进入，那么我们可以计算一下我们的流量是什么样的增长方式了。就如何争取海量的页面收录，我们看看都有哪些具体方式：
 
　　a、Url策略
　　Url策略是争取海量页面收录的第一步，希望被收录，就必须有友好的Url，这个是被业内普遍认可的。　　  b、首页内容曝光
　　首页内容曝光主要是给哪些无定期内容更新的网站用，必须主动将自己的网站公共内同用一定的技术手段实现在首页的链接轮播展示，一般周期以1-2天即可。这样可以主动引导搜索引擎深处收录网站内容。
　　c、站点地图

**** 2、重点关键词推动
 
　　这里强调的是一个重点关键词推动的概念，并不是把关键词作为核心优化手段。当做好第一步工作，页面覆盖量达到了一定规模，再来做想做的关键词就容易得多，可以达到事半功倍的效果.再高覆盖量的基础上，我们适时调整网站，也一些页面的关键词取向，可以灵活的，季节性的通过热门关键词为我们带来想要的流量。[流量再如何转化为销量，这就是我们的市场营销策略了，这里不展开]带来我们销量的种子。具体做法：
 
　　A：再网站的入口关键词中做数据统计和调研，根据搜索引擎的关键词数据结合做未来关键词预测。[该工作至少要提前2-3周预测到未来的关键词动向]然后及时的调整页面内容的关键词[尽量保证关联的原则]，之后的工作一定得检索关键词调整的页面是否已经被收录否则该工作无意义
 
　　B：做好站内关键词的关联链接大家一定不陌生，在一些网站的内容中，会发现有某些词语带链接可以点击的，并进入到相关页面。这就是所谓的关键词链接，是大型网站都必须完善的。
 
**** 3、[[my-anchor-site-struction-optimization][网站结构优化]]
 
　　前面两步工作做好了，相信网站已经可以通过自然搜索带来相当稳定的流量了，如何留住流量，如何通过较好的IP访客流量再转化一下提升PV流量，就是这个阶段不得不考虑的问题。如果说前面的工作更多的是为了给搜索引擎看，那么从现在开始后面的工作更多的将是以人为中心，为用户而做，同时兼顾搜索引擎。网站结构优化主要有以下几个必须工作：
 
　　A：导航结构优化
　　导航结构的优化的原则不仅仅是要对人的交互友好，同时必须满足和搜索引擎的沟通无障碍，优秀的导航的结构将可以引导用户在网站上做更多的事情，如：阅读，学习，咨询，购物…..这一切都建立在网站有良好的导航的系统，让用户能在茫然的时候进入任何的位置，在逐步清晰思路的时候找到想要的内容，在建立一定的信任基础后他可以了解到网站的产品。导航结构优化的目的就是要让用户在适当的时候可以做想做的事情。
 
　　B：内容结构优化
　　内容优化也是网站结构优化的一个重要内容。如何展示网站现有内容，哪些内容要提到网站首页来展示，哪些繁琐的内容需要区域概括化展示，哪些内容可以回归导航….这些都是内容结构优化的工作。通常内容安排注意一下几个原则和规律：
　　更新频率较快的尽量提升到首页展示区块;
　　用户关注的内容提升首页展示;
　　容易形成行业权威气氛的内容提升到首页显示;
　　约定性习惯性内容尽量导航归属;
　　功能性业务内容尽量导航归属[含按钮工具导航];
　　FAQ或类似客服内容集中导航归属化。
 
**** 4、业务架构优化
 
　　业务架构优化主要是根据网站的业务功能，业务定位等将网站的业务流等做一些功能性和用户关联性开发。
 
**** 5、技术架构优化
 
　　技术架构的优化是SEO底层工作的一个重点工作了。良好的技术架构将使整个网站从先天上具备良好的搜索引擎友好度.基于一个优异构架的网站系统，即使不做附加的基础优化[如:url优化，站内链接优化等]都可以在搜索引擎看到优异的表现，这时可以专注的做好基于业务的优化。
 
　　SEO一些主要工作我们在上面已经做了，涉及到了内容策划，业务规划，技术构架，界面结构，系统维护等几个方面。但这不是终点，还有追求更好的余地。
 
　　按规范走完本章的优化流程，目录结构，url问题，导航结构，框架，图像，表格，页面代码减肥等一些基础问题都迎刃而解。因此大型商务网站尽量按照该流程来做优化将可以节约时间和人力成本，将一些棘手的明显问题都融入在流程中逐步解决了。
 
　　当然这里所说的只是一个大体思维，具体优化可以参看《网站的整体优化步骤》和下面相关文章。
　　文章来自：木木seo  http://blog.sina.com.cn/mumuhouzi
** DONE #<<my-anchor-page-record>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e974.html][解密网站收录减少原因]]
     CLOSED: [2015-11-22 Sun 19:21]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 19:21]
*** 一.网站访问时间太慢
 
　　一个好的网站空间的打开速度应该是在5秒之内当大于5秒的时候不仅仅是对搜索引擎不友好了你还会严重影响用户体验，这是百度不会容忍的，如果你网站长时间这样的话用户在点击网站是会立即关闭不再访问你的网站，同时百度蜘蛛也不会再去爬行的网站，因为你的访问速度回影响蜘蛛的工作效率，这样的话搜索引擎是不会收录你的网站的，因为你的网站是一个没有人打开的网站，解决的方法是立即换一个空间，访问速度必须要好，这也是进行SEO优化的一个基本前提!
 
*** 二.网站内容重复度过高或者多为采集站
 
　　搜索引擎一直以来都是对于采集站持打击的态度，当一个网站大量的采集其他网站内容时会与搜索引擎数据库中大量的网页出现相同的内容，而这些内容会被搜索引擎认为是没有收录价值的内容，所以即使当时收录了你的网站他也会在下一次更新中删除这些内容，所以不要存有侥幸心理，这也就是网站收录减少的原因，不要去随便采集，最笨的方法就是你进行一下伪原创，解决的方法就是多进行原创内容，或者是进行深度的伪原创这样的话就可以提高网站的收录量。
 
*** 三.网站内部链接太差
 
　　网站内部链接在SEO优化中具有重要的作用，一个好的网站会用内链合理的将网站内容穿插起来，整个网站就形成了一个网络整体，这样既利于提高蜘蛛的爬行效率也有利于提高网站的收录，同时一个好的内链可以很好的传递网站的权重，这就是很多网站把内链作为一个重要优化项目的原因，所以一个内链很差的网站对于收录和蜘蛛的爬行都是不利的，这也就导致了网站收录迟迟提高不了的原因，当出现这样的现象后站长应该合理的布局网站的内部链接，比如在相关阅读中添加相关性较高的文章，在文章中对于重要的词给予链接，注意网站的内链锚文本最好不要用相同的文字，不然会被认为是作弊的,例如研科呼叫中心和智能呼叫中心系统，采用不一样的文字做链接。
 
*** 四.网站收录减少或者不多的另一个原因是新站刚建立不久
 
　　对于一个新站无论是谷歌还是百度都会有一个所谓的考察期也就是我们所说的沙盒期，在这段时间里搜索引擎可能不会收录你的网站，在这段时间后会开始收录你的网站，这个时期大概是一到三个月左右，这短时间只有坚持更新就没有什么问题，因为这段时间有另一种可能就是搜索引擎搜录了你网站的内容但只是没有放出来罢了，所以你只需要等，解决方法就是不断的保持网站的内容更新，慢慢的等待，这个过程是每个站长都经历过的。
　
*** 五.网站权重过低也是网站收录减少的一个原因
 
　　网站收录过少与网站权重有着或多或少的关系，SEO优化中网站权重过低时还会导致误判的发生，比如当一些全中较高的网站转载了你的网站时一旦被搜索引擎发现并收录了之后他会误以为是你转载了高权重网站的内容进而删掉你的网页，这是很苦逼的，而网站权重低主要是于网站外链的多少有关系，所以要想提高权重就需要你适当的提高一下外链的数量，注意我说的提高不是在论坛里随便发发外链，我说的是在一些权重较高的网站发一下高质量的外链，进而带动网站权重的提高，从而提高网站的收录量!
 
*** 六.网站代码中存在大量的JS代码也是导致网站收录少的一个原因
 
　　一个网页中如果存在大量的JS代码会导致网站代码臃肿，当蜘蛛过来爬行网站的时候会降低他的爬行效率一旦被蜘蛛发现有这样的情况时搜索引擎会减少蜘蛛爬行的次数或者是不在爬行，这也就直接导致了网站的收录减少，所以这种情况的解决方法是减少网站JS代码，或者是将JS代码全部移动的网站底部或这是直接打包调用，这样对于JS的使用是没有影响的，却提高了蜘蛛的爬行效率，增加了网站的收录!
 
*** 七.网站有大量的图片也会影响网站的收录
 
　　一个网站有大量的图片时，并且这些图片很大未经过压缩时也会影响网站的加载时间，降低网站的收录，对于图片的处理包括压缩图片、添加ALT描述也是SEO优化中一个必要的基础!解决方法就是对于大图片要进行处理压缩，添加好ALT 描述，能不用图片就尽量不用图片!
 
*** 八.网站改版或者是网页被修改也会导致收录减少
　　网站随意的修改也是对于收录很不利的，这也是搜索引擎不喜欢的，这样的情况一般多出现在新手站长手中，新手刚学习SEO对于这些问题都很难注意到，所以解决方法也很简单那就是在网站SEO优化为完成之前尽量不要把网站开通，或者是少量的修改。
 
*** 九.搜索引擎本身的原因
 
　　由于搜索引擎本身的原因导致的收录减少也是很常见的，常见的就是算法的改变，或者是搜索引擎故障这些都是会导致网站收录的减少，而这种原因出现的问题普通人是没办法解决的，我们能做的就是等待，期待网站的恢复。
 
　　文章来自：SEO博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE #<<my-anchor-site-struction-optimization>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e8g5.html][结合网站实例分析数据，改进网页]]
     CLOSED: [2015-11-22 Sun 19:54]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 19:54]
标签： 数据分析 网络推广 数据统计	分类： 网络推广运营
　　数据在很多网站都被看作是衡量一个产品或者一个设计好坏的基本指标之一。[[my-anchor-statistics-analysis-data][统计分析数据]]是网络推广必须做的。下面是一些经常统计的数据的简称。
 
　　– [[my-anchor-ip-pv-uv][PV]] (即Page View，综合页面浏览量)
　　– CLICK(页面点击量)
　　– DISPLAY(单个页面浏览量)
　　– UV(即Unique Visitor，独立访问者)
　　– BUYER(购买者)
　　– CTR(点击转化率，也就是Click/Display)
　　– 广告位转化率(也就是PV/Click)
 
　　下面是一些数据实例：
*** Banner篇
**** – 案例一
[[file:./tomsinsight-hack/banner篇 案例一.png][banner篇 案例一.png]]
 
　　A 广告位转化率:1.9
　　B 广告位转化率:10.8★
 
　　该数据告知我们，在一个页面中不明显的位置的广告位，如果做成文字形式会很容易被很多其他信息干扰的看不到，这个时候如果放上吸引人目光的图片，很可能效果会非常的好。
 
**** – 案例二
[[file:./tomsinsight-hack/banner篇 案例二.png][banner篇 案例二.png]]

　　测试目的是：在该banner尺寸中商品数量和大小的最优表现。
[[file:./tomsinsight-hack/banner篇 案例二 table1.png][banner篇 案例二 table1.png]]　　

 
　　该数据告知我们，作为banner块的商品数量并不是越多越好，它会有一个最合适的大小和数量的比配，如图所示，4个商品虽然图片大，但是由于选择相对狭小，数据表现果然比较差，但是8个商品相对同尺寸的banner来说图片会比较小，给予用户的吸引力也会受一定影响，因此6个商品就在商品数量和大小上为最优化。当然该测试也有一定的弊端，当6个或者8个商品的图片中有一个特别受用户欢迎也会影响数据的表现。因此针对该测试只能多次尝试才能看出最优的组合。
 
**** – 案例三
[[file:./tomsinsight-hack/banner篇 案例三.png][banner篇 案例三.png]]　　
 
　　测试目的是：banner改版过程中各个类别的表现对比。

[[file:./tomsinsight-hack/banner篇 案例三 table2.png][banner篇 案例三 table2.png]]
 
　　当A版本改版至B版本的时候，banner的尺寸相对阔大，而其中商品图片内容也增加，因此我们认定上线后的表现一定会优于A版本，结果发现完全不是这样，B版本反而比原来A的转化率下降了不少，一开始我们以为是否因为新版本上线导致老用户不习惯于新设计造成一些操作中的困扰，但是发现过了1个月数据仍然无很大起色。于是我们上线了C版本，索性加大了单个banner的尺寸来查看数据表现，果然这次数据不仅优于B也优于A表现。
 
　　其中的原因我们细细分析，觉得可能是由于，B版本给到用户的选择增大，对于整体的banner让用户无从选择入手，对于广告类的banner来说可能大型单一的广告会更优。
 
*** 导航篇
**** – 案例四　　
[[file:./tomsinsight-hack/banner篇 案例四.png][banner篇 案例四.png]] 
　　测试目的是：改版过程中各个类别的表现对比。

　　
　　A版本是老版本，数据为占首页CLICK:9%，CTR:4.6%。B版本上线后，数据表现一下子下降为占首页CLICK:2%，CTR:0.5%。C版本上线后，数据略有回升占首页CLICK:9%，CTR:2.7%，虽然转化率并不理想，但是click占比已经上升和A一样。D版本上线后，数据终于上升为占首页CLICK:12%，CTR:5.2%。
 
　　我们分析了一下整个导航的click分配占比发现，其中最重要的原因是由于频道导航的点击，A的频道入口非常明显;B删掉了频道导航入口;C虽然增加回导航入口，但是还并没有做的很明显;D又将入口加回，并且删掉了其他干扰信息，使得其更加明显。
 
　　就导航而言，D版本表现是优秀的，但是如果频道首页入口的增加对首页来说是否真的有效呢。因此我们查看了频道页面的BUYER转化率，发现频道首页BUYER转化率表现虽然没有优于流程页，但是相对表现也算不错，相对于首页一些其他的位置，比如社区和一些广告的位置来说，频道导航转化率还是比较高的，因此最后我们认定对于导航而言，频道首页的入口不仅需要加，还需要明显。因此D版本为比较优的选择。
 
*** 页面篇 
**** – 案例五
　　
[[file:./tomsinsight-hack/页面篇 案例五.png][页面篇 案例五.png]] 
　　测试目的是：首页改版后的市场推广类位置的表现比对
[[file:./tomsinsight-hack/页面篇 案例五 table3.png][页面篇 案例五 table3.png]]

 
　　上述数据表可以看出改版后，CTR上升模块为2、3、6，于是我们查看了2、3、6的Buyer转化率，结果发现除了3的表现较高之外，其他两个都是数据BUYER转化率排名非常靠后，而很多Buyer转化率偏高的模块，却CTR下降非常明显，因此就市场推广模块来说这次改版是失败的。
 
　　从下面的总表就可以更加明显的看出了：
[[file:./tomsinsight-hack/页面篇 案例五 table4.png][页面篇 案例五 table4.png]]　　
 
　　虽然HP的页面Display增长的，但是其他数据均下降了。但是最终我们并没有回退前版本，其中有各种原因，其一是在新版本中增加了自动维护模块而该模块所带来的BUYER的增长非常的明显，并且新版本中的关键字部分的调整也使得整个页面的表现增长非常明显，因此最后只是针对一些重要的位置再次进行了设计和位置上的调整，而没有对整个页面进行回退的操作。
 
**** – 案例六
[[file:./tomsinsight-hack/页面篇 案例六.png][页面篇 案例六.png]]　　

　　测试目的是：这是多版本测试以同时间，同商品，同链接页面来比对四个版本的表现。
[[file:./tomsinsight-hack/页面篇 案例六 table5.png][页面篇 案例六 table5.png]]　　

 
　　就CTR而言，A版本的转化率优于其他版本，原因是商品区域重点突出，其他相对较弱，干扰不大。而D版本不仅使用了双栏结构，并且加重了LP BTU的视觉效果，使得D版本的LP BTU的点击大于了A版本。
 
*** 如何正确看待数据 
**** – 案例一
[[file:./tomsinsight-hack/如何看待数据 案例一.png][如何看待数据 案例一.png]]　　

　　当老板设定了一个离谱的数据指标后，各部门为了达到该指标各管各想出了各种应付的手段。然而这些手段导致最后的虚假指标对于公司的业绩没有任何帮助。
 
　　这个说明了：数据不是为了制定不切实际的指标。在制定数据指标的时候应该有一定的合理增长的分析，而不该拍脑袋的方式来决定。
 
**** – 案例二
[[file:./tomsinsight-hack/如何看待数据 案例二.png][如何看待数据 案例二.png]]
 
　　当一个比较有创意的大型项目上线，而三个月的数据表现并不是表现非常好的时候，是否需要马上撤换下马呢?虽然数据的好坏也需要看，但未必一定看的是绝对值，其中增长趋势也是很重要的环节。而一个大型项目在上线前应该做比较充分的准备，但一旦上线后，如果表现不够好，也可以通过一些用户的调研再次调整来修正它，马上撤换下马不一定是最好的方法。
 
　　这个说明了：很多项目要看长期的数据趋势，在过程中可以做一些其他UER调研来完善它。
 
**** – 案例三
[[file:./tomsinsight-hack/如何看待数据 案例三.png][如何看待数据 案例三.png]]
 
　　每个部门都会有针对该部门所制定的不同的指标，这个也就是矛盾的产生，比如市场部觉得A版本好，因为他们对该版本有自己的数据分析，而设计部门也会有自己一套数据分析，结论可能完全不同，业务也是一样。这个就会带来很多争吵，那么如何避免这些争吵。一定是有一个最大的目标值，比如最后会以BUYER为最终指标值，那么就会在此基础上来对其他的数据进行优化。
 
　　这个说明了：数据需要统筹考虑，不同角度会有不同结论。
 
**** – 案例四
[[file:./tomsinsight-hack/如何看待数据 案例四.png][如何看待数据 案例四.png]]

　　这个是我们以前一个领导经常挂在口头的话，他老是自以是的说有了数据，UER就可以全部都不要了。但是终于有一天我们一个超级牛叉的UER反驳他这样一句话，导致他以后再也不敢提这个论调了。数据告诉我们哪里出问题，用户调研能告诉我们问题出在哪里。这里的两个哪里让我觉得非常的经典。
 
　　尾声：数据是个双刃剑。虽然数据分析是非常重要的，也是每个公司的老板非常看重的部分，但是它需要我们合理分析，综合考量。如果它的分析出了错，那么可能会导致一个决策上致命的错误。因此数据需要我们认真和全面的思考。
 
　　欢迎关注木木SEO博客：http://blog.sina.com.cn/mumuhouzi 微信公众号：mumuseo，如果你觉得这篇文章有价值，可以分享给你的朋友，如果你觉得没有价值，没有关系，请给以指导，这是一次改变的机会。
** DONE #<<my-anchor-site-struction-optimization-workflow>> [[http://blog.sina.com.cn/s/blog_c206a2c30101e1iw.html][网站的整体优化步骤]]
     CLOSED: [2015-11-22 Sun 20:11]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 20:11]
标签： 网站优化 seo优化 关键词优化 关键词	分类： SEO策略技巧
　　网站整体优化是做好网站各个方面的优化工作，而不只是网站优化推广这个小项目。矮化，窄化，或者简单化，让那些站长认为网站优化只是关键词排名，只要关键词排名到了第一页，流量就会上去，其实那是把事情看的过于简单了。
 
　　我们要思考客户为了什么而做网站的优化，肯定是为了盈利，如果客户在网络里面得不到利益，请问，客户还会继续做网站优化吗?这样只会让SEO走向陌路，做多元化的网站优化是比较好的出路之一，才不会被社会所淘汰。如果现在还仅仅停留在思考关键字排名问题那么你已经是跟不上时代的步伐，即将被淘汰。
 
*** 概述
 
　　网站整体优化是做好网站各个方面的优化工作，而不只是网站优化推广这个小项目。矮化，窄化，或者简单化，让那些站长认为网站优化只是关键词排名，只要关键词排名到了第一页，流量就会上去，其实那是把事情看的过于简单了。
 
　　那么什么是优化呢?所谓优化，即：并不以某个关键词为最终目的，而是对一个网站进行综合的优化，包括了域名选择、网站结构或栏目设置、内部及外部链接，内容建设，访问者体验等多个方面进行的优化，关键词的排名只是一方面，更重要的目的是为最终的销售服务。有人说优化之终级目的是品牌优化，但品牌也是为销售服务的，所有的工作都可以归结为销售。
 
*** 优化具体方案
 
　　1、 title优化
　　2、 url优化
　　3、 内链优化
　　4、 外链建设
　　5、原创内容建设
 
*** 工作内容 
　　优化要考虑的问题比较多，和100%追求排名效果相比，控制好各个方面的工作，做好平衡，很重要。这些平衡包括：
 
　　一、首先是用户体验，任何的优化都不可以以牺牲用户体验为代价。
　　二、网站的内部链接和外部链接要配合得当，而且链接词要合适，多元化，不要千篇一律。
　　三、关键词的选择要平衡好主要关键词和次要关键词<</FONT>即长尾关键词>的关系，不可偏废。
　　四、优化推广的过程中要注意基于页面的优化和基于网站之外的优化。
　　五、网站的各种标准化也要同时做好。
　　六、优化的手段要多样化。
　　七、网站的优化推广的力度要适中，古人说的好，走中庸之道，千万不要过犹不及。
　　在网站优化的工作中，主要做的就是网站的整体优化。所以说，整体优化要比片面优化要好得多。
 
*** 优化策略 
　　1. 先对网站做性能优化(域名空间诊断、网站访问速度、站内SEO设置、UEO建设)，即，站内优化，提升用户体验和搜索引擎体验，打好网站的基础;
 
　　2. 网站基础打好之后，开始做站外优化，加强网站在各大搜索引擎上的宣传推广，提升网站关键词排名加强口碑宣传推广，引入流量;
 
　　3. 网站关键词排名能上升到首页、能够获取流量，是因为网站在搜索引擎中有了良好表现，称之为权重。所以第三步要做的就是维持并继续提升网站权重，加强网站外部推广宣传，提升网站批量关键词排名，网站曝光率，大幅度引入流量;
 
　　4. 开始精准关键词优化，精准流量引入，关键词大批量上线不是最终目的，这个阶段不仅考虑流量引入，更要考虑精准流量引入和转化，因此需要挖掘更加精准的关键词，通过排名和口碑宣传，带来精准的流量;
 
　　5. 市场是在不断变化的，因此需要定期进行数据分析和效果监控，监测效果和市场变化，及时调整策略以保证效果的持续性和市场适应性。
 
　　6. SEO培训，网站在搜索引擎中已经有了良好的表现，只需要对客户进行一些基本的SEO设置、SEO维护培训，只要执行到位，即可保持网站效果的稳定，控制网络投放成本。
 
　　优化流程网站优化是一个系统的工程，涉及网站策划、设计、程序、优化、营销等一些列内容，虽然如此，我们还是可以总结一些经验，让网站优化有章可循。
 
*** 网站策划
 
　　这一步也是最重要的一步!俗话说思路决定出路，所以在做任何事情之前，我们都应该有一个规划策划，以便任务的正常进行，网站优化也不例外。在网站策划时我们需要考虑很多的问题：
 
**** 网站设计
　　根据网站策划设计网站各个页面效果图，注重网站的视觉形象的把握。好的网站设计会给访客好的视觉印象，增加访客信任度，提高访客回头率，所以这一步对于网站的转化率有很大的影响，也是一个不可忽略的步骤。
 
**** 切图生成
　　从技术上来说，切图需要注意的是页面的兼容性和响应速度。而从优化的角度来看，注重的不仅仅是这些，还包括重要页面权重的提升。当然，这个从网站策划中就应该已经明确了，只是在一步才得以实施。如非重要页面如联系我们、在线订购、意见反馈等的处理。
 
**** 程序定制
　　同样以网站策划为原则，以网站优化为目的，定制网站程序，需要注意的是尽可能利用程序实现某些优化功能，以便减少后期优化的工作量。如title中的关键字布局、title的长度控制、页面关键字的分布、内链的建设、关键字的密度控制、内容的长度控制等等。
 
**** 测试细节
　　这一步主要要看，切图、程序是否满足网站策划中的各种要求。当然，还需要校验网站策划的可行性和不足等。如果所有细节都考虑到位并得以实现，那么你可以上传网站了!
 
　　ps：千万不要等网站上线运营后再测试，一旦被搜索引擎降权，等待恢复是一个痛苦的过程!
 
**** 完善内容
　　网站刚上线时需要更新大量的内容来丰富网站，保证每个栏目都有几条相关的内容，访客不会感觉到“空”即可。达到这个要求后就不要再一鼓作气地更新了，每天或者每周更新一次即可。但一定要原创!要有规律!要坚持!
 
**** 外链建设
　　网站有了内容，我们就可以让搜索引擎来抓取了!怎么让搜索引擎抓取呢?两种方式，一是提交给搜索引擎，一是外链来引搜索引擎。广拓企业网站推荐使用后者，建立外链!当然，外链的建设也不可以一蹴而就，需要循序渐进，一点一点的来，千万不要使用外链软件来造势，结果会适得其反的!
 
**** 成效分析
　　持续更新网站内容和外链一段时间(一般需要2月左右)，搜索引擎应该会带来一定的访客了。这时，网站访问统计就有了很大的作用，通过访问统计，我们可以清楚明确地了解是哪里的访客?通过什么渠道来的我们网站?在看了我们网站中的哪些内容?待了多长时间?如果是从搜索引擎来的，我们还可以知道他是通过哪个词来到我们网站的!通过这些内容的分析，我们可以总结经验，发现网站的不足之处并加以改正。如每个用户来到我们网站立马离开，说明什么?网站内容不够吸引他或者与他要找的东西不相干!如每个用户来到我们网站只看了一个页面就走了，说明什么?我们的网站没有引导好客户看我们希望他看的内容!如搜索引擎通过搜索“企业网站一条龙服务”来到我们网站，而实际上我们的网站并没有这样的内容，又说明什么?不要告诉我，我们的网站做的很好!你应该发现一个长尾关键词，把它做到第一去!
 
*** 优化方案优化流程
 
　　1：网站诊断分析(网站构架分析，网站内容分析，网站系统分析，网站功能分析)
　　2：网站竞争性分析(行业搜索引擎竞争分析，竞争对手分析，搜索引擎友善度分析，关键词分析，链接分析)
　　3：SEO培训咨询(SEO基础知识培训，SEO实践专业培训，SEO评估方法及工具培训，SEO实践效果验收及维护)
　　4：数据跟踪分析(数据跟踪监测，效果维护及调整，策略测评及调整，流量分析)
　　5：优化策略构架及实施(优化策略，关键词策略，内链优化，外链部署策略，软文编辑及站外推广，搜索引擎表现预测)
 
*** 优化方案
**** 1、网站导航优化
 
　　是否锚文本导航，以文本形式做网站导航，不要用flash，图片，js，因为这没有锚文本做的导航好，锚文本导航蜘蛛更喜欢。
　　导航锚文本关键词相关性，这也就是栏目的定位了，尽量以你首页的长尾关键词做你的栏目。
　　主导航和次导航，主导航只放栏目，频道，不要放无关的内容。次导航可以放一些相关关键词的页面导航或者栏目导航，但切记不要堆积。
　　是否有面包屑导航，首页>栏目页>内容页。
　　面包屑导航优化需要注意的细节：当前页面(落地页面)一般不需要添加链接;可以适当使用关键词为面包屑的锚文字;一个页面可以有多个面包屑(以不对用户造成困扰为根本)。
 
**** 2、栏目页优化
 
　　三个标签，title，keywords，description，合理填写，不要堆积。
　　标题结构，标题名称>栏目名称>网站名称
　　关键词相关性，
　　分页标题重复度检测，不宜过多重复。
　　分页链接URL是否加深了URL深度，URL建议在3层内。
 
**** 3、内容页优化
 
　　内容来源，来源以原创为主，参考编写为辅，再不行就伪原创，复制粘贴就不用做了，对网站百坏无一利。
　　URL是否包含关键词(英文)，做英文的URL带关键词效果较好，中文拼音也可以。
　　标题格式，简短，精要，标题中要出现网站主关键词。
　　H标记的使用，在网站第一次出现的关键词加上H标记。
　　文章写作是否符合SEO规范，分清主次，合理关键词分布。
　　图片ALT属性，可增加关键词密度及搜索引擎对图片的认知度。
 
**** 4、链接优化
 
　　建设网站地图，Html格式的网站地图是根据网站结构特征制定的，需要尽量把网站的功能结构和服务内容富有条理地列出来，并力求页面简洁大方，以便于用户浏览。
　　建设Robots文件，注意Robots.txt必须放置在一个站点的根目录下，而且文件名必须全部小写，将网站地图写进Robots文件。
　　设置404页面，符合网站自身的设计风格，最好能加入网站导航和底部(尤其是网站地图)，并确保404页面返回的http状态码为404。
　　检测网站的死链并删除，建议使用Xenu工具检测。一个网站就如同一个人一样，只有身体好了才能获取和创造更多。如果把内部链接比作经脉，那么网站内容就是血肉。一个网站即使内容在丰富，如果经脉不通，最终的结果是排名不好，收录增加缓慢。内链建设在网站建设中的重要性与外链担当不同的角色作用。反向链接除了网站与网站之间的链接还有网站内部网页和网页之间的链接，对排名也是有帮助的，个人理解这是内链的实质，内链的意义在于用户更方便的找到信息。我想这也是现在流行的(UEO)用户体验优化实践操作的一种手段。
 
*** 逆向思维分析
 
　　网站内容聚其一点是关键词，关键词定位了访问者。很多人爱说专注，搜索引擎也是这样看待网站的，标题的作用在未来细分化发展中更显重要。主题突出，内容丰富粘度大，领域纵向深度，这应该是未来几年的网站主流趋势。生活中都爱说顺其自然，网站优化也是这样，不要刻意迎合搜索引擎的喜好而SEO，更多的是应该考虑到访客。因为不论搜索引擎还是SEO最终的客户都是访客，都是以人为核心。一味的讨好搜索引擎，极易被认为是作弊行为，人讲究个性，网站也同样如此。SEO策略的实施是因人而异的，我们在研究搜索引擎的同时，搜索引擎也在学习我们。
 
*** 优化方案格式
 
　　当拿到一个网站需要优化时,不是一拿到网站就去做关键词去做外链,第一步应是了解网站,制作可执行的网站优化方案.而便是这是一个较为简单的网站优化方案撰写格式。
 
**** 网站SEO信息：
 
　　1、ALEXA排名
　　2、域名年龄
　　3、百度权重、谷歌PR及其收录情况
　　4、网站流量情况
　　5、关键词排名情况
　　6.网站的外链数据情况
 
**** 网站优化目标：
 
　　1.制定目标关键词，预期排名目标。
　　2.制定网站IP和PV值，预期网站增长多少流量。
　　网站站内优化(注：详细的站内优化请借阅《SEO站内优化操作流程》)
 
　　相信很多很多新手站长或新手SEOer一上手就会咨询外链哪里发更好，更有甚者巴不得外链遍布天下。其实对于网站优化而言，外链自然是重要，可用户体验更为重要，从百度频频升级算法我们也可以察觉，百度在不断打击用户体验差的网站呀!因此叶剑辉认为做好网站内部优化，做好网站的用户体验比外链更为重要。那么网站内部优化有哪些方面呢?
 
　　1.首页标题，观察网站首页标题数量。
　　2.网站关键词分布，即页面关键词密度，不要刻意堆积，自然就好。
　　3.网站内容更新，网站内容更新是否规律很重要，尤其对于新站，规律更新方能更好的走出沙盒。
　　4.网站内链，无论站大站小，内链重要性都不可忽略。
　　5.网站地图和网站静态化，均影响着蜘蛛爬行。
　　6.图片优化，ALT标签说明。
 
*** 网站优化策略
 
　　网站优化策略需具体情况具体分析，如企业站与资讯站有着不同优化策略，企业站需保持更新，而资讯站需更多的挖掘关键词，带动流量。
 
**** 人员分工
 
　　没有完美的个人，只有完美的团队。做网站SEO优化也是如此，团队作战，各施其职，方能做到更好。
 
用户群体
 
　　1.经营大量产品的企业网站
　　2.提供广泛服务的行业网站
　　3.至少有100个关键词能够概括服务或者产品信息
　　4.专业的商城,如：服装类商城、首饰礼品类商城、化妆品类商城等
　　5.品牌产品或者代理品牌
　　6.热门行业
 
**** 如何提高有效流量 
　　优化首先关注长尾关键词。长尾关键词通常是指除核心关键词及次级核心关键词以外的网站关键词。一个网站除核心关键词可以带来很多流量以外，长尾关键词也可以为网站带来很大的流量，甚至其总量比核心关键词所带的流量更大。比如有一家汽车音响店，可能会选择音响作为核心关键词，汽车音响作为次级核心关键词。那么他做竞价排名的话，选择这两个关键词的价格都很贵，可能每个点击3元左右;那么他可能选择在google里做seo,可是排在google首页的都是响当当的网站：慧聪网，瀛商网，新浪汽车频道，中国汽车影音网，中国音响网，太平洋汽车用品频道…一个普通的汽车音响店要想排在前十名，行吗?行，但是很难。但是他又往往很着急，希望1-3个月内出效果，最后seo服务商只好通过不好的手段去运作，这就是国内的seo界的普遍现状。
 
　　那么，其实转变一下思路，我们可不可以选择一下长尾词：汽车音响改装、惠威汽车音响、先锋汽车音响、汽车音响论坛、二手汽车音响、松下汽车音响、漫步者汽车音响、jvc汽车音响、汽车音响解码、汽车音响网……等等。可能用户通过搜索引擎检索的所有关键词中，核心关键词产生了50%的访问量，另外50%的访问量是这些长尾关键词带来的。长尾关键词通常为冷门的词语，或者是短语，甚至是一个句子，有那么多的用户使用搜索引擎的时候可能会输入一些你意想不到的东西，比如搜“北京汽车音响公司”、“北京的汽车音响”这样的词，甚至“哪里有廉价的二手汽车音响”等等这样的短语甚至句子。
 
　　很多的时候，对于模板的修改和链接结构的调整以及页面结构的调整，使之更加符合搜索引擎的计算规则，同时更加对浏览者友好，这样进行优化后，可以利用搜索引擎在排序计算中对关键字列表的提取原则，挖掘出很多关键字，使之获得好的排名，从而使得该站的流量大增。大多数是数倍的上翻。优化的最大的特点就是，不是自己在指定某个关键字，是随着你的内容的增加，搜索引擎自动提取很多的关键字进行排序。这样的做法，极端的符合搜索引擎的计算规则。
 
**** 较好的用户体验
 
　　前文说过seo的目标是用户体验和流量，优化必须考虑网站的结构、内容、美工设计、栏目构成、服务器和域名等等，这些基础构成了高用户体验的关键因素，优化基础也是基于此，而关键词优化一般不用考虑这些全部的因素。
 
**** 提高网站转化率
 
　　流量无论多高，提高访问者到商机的转化率才是企业最需要的，而优化能显著提高转化率。
　　从搜索引擎来看：假设你是一家打印机公司的营销经理，你需要用网络推广打印机，通过长尾词“个人家庭用彩色双面打印机”搜索来的客户，比简单搜索核心词“打印机”而看到满满一百度首页的“打印机”的客户，显然前者的需求与网站呈现的内容更加匹配，因此前者打电话给打印机公司的可能性更大。
 
　　从网站的流程及内容设计上看：服务或产品的内容选择、表达方式、以及方便简捷的引导流程设计，互动方式设计都会大大提高访问者的参与度，有效激发访问者的购买欲望。
 
　　转化率才是seo必须重视的数据，好的转化率，能将有限的流量转化为高质量客户。优化的目地，就是为了转化率和流量而努力，各种信息以及网站结构的调整，利于企业获得较高的站点流量转化率，创造更多利润。
 
**** 更多的信息展示
 
　　优化的最终，还是为了企业营销而努力，因此，seo优化人员必然更多的去注意信息的发布量和覆盖平台，这些信息，将会使得企业信息获得更多的展示机会。
 
**** 控制广告成本
 
　　一方面优化可以带来可观的流量和转化，同时因为竞争对手不可能花这么多精力去琢磨这几百个长尾词，因此不存在恶意点击，另一方面不是按照点击收费，所以被竞争对手点击了也没有损失。所以竞价排名中代理商和竞争对手恶意欺诈点击的就不存在了，自然投资回报率就提高了。
 
　　因此，优化的目的从根本上改善企业网站的质量，从而带来高质量的持续的大量的流量;显著改善转化率。从而让企业彻底告别竞价排名依赖症。显然，在核心关键词价格虚高的情况下，优化的投资回报率远远好于竞价排名。
 
**** 优化与搜索引擎优化的关系
 
　　优化就是通过对网站定位、网站内容及网站结构的整体优化，确保网站所有页面都具备搜索引擎友好性，让网站在各大搜索引擎都有比较高的收录量和好的整体排名表现。优化是搜索引擎营销的最佳实践。
 
　　网站整体优化与单纯的关键词优化的不同
 
　　网站整体优化除了考虑排名外，更注重点击率和网站转换率。它并不以某个关键词在某个搜索引擎上的排名为得失，而是注重所有高质量相关关键词在所有搜索引擎的整体表现。
 
　　网站优化比单纯的做关键词竞价更有效
 
　　与关键词竞价不同，优化可以让贵网站通过更多的高质量关键词从更多的搜索引擎获得自然的流量，而且不需要担心恶意点击和恶意竞价。
 
**** 网站整体优化的目标
 
　　1、实现提高目标及长尾关键字的关键词优化。
　　针对流量分析并时常关注网站关键字密度的分布，增加目标关键字排名。关注准及长尾关键字受关注水平和在首页的分布情况。
 
　　2、保证网站最新发布的内容被搜索引擎收录。
　　通过对长尾关键字分布和选择的优化，使得网站页面被搜索引擎收录几率大大增加。从整体上增加网站的有效访问量。随着访问量的增加实现了网站整体排名的提升。
 
*** 优化技巧

　　网站整体优化并不以某个关键词为最终目的，而是对一个网站进行综合的优化，包括了域名选择、网站结构或栏目设置、关键词分析，内部及外部链接，内容建设，访问者体验等多个方面进行的优化，关键词的排名只是一方面，更重要的目的是为最终的销售服务。具体来讲优化的方法包括如下结果方面：
 
**** 高质量的链接
 
　　要做有高质量的链接。链接的数量不一定要多，但要注重高质量。一个单一的、良好的权威的链接，要胜过几十个劣质的链接。 如果没有合乎逻辑的理由，有不好的网站链接了你， 这种链接也别要。
 
**** 加强内链建设
 
　　加强内链建设和外链建设，在新文章中适当的回链老文章的地址，文章底部根据TAG建立相关文章链接。寻找和增加一些好的外链。
 
**** 长尾关键词
 
　　优化中要学会把主关键词分成多个长尾关键词，化整为零，实现关键词的多元化，当然这个多元化不是要求大家无限制的拆分关键词，这样就变得过于分散，反而造成不好的效果 !所以说，这里有个关键的因素就是适度!
 
　　木木博客(http://blog.sina.com.cn/mumuhouzi)，关注互联网营销，注重网络推广策略、营销引流技巧及思路。另外，关注公众号mumuseo，回复“提速”可以免费获取《搜索引擎营销：网站流量大提速》!已经关注的直接回复即可。
** DONE #<<my-anchor-statistics-analysis-data>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dxk6.html][SEO数据如何搜集和分析]]
     CLOSED: [2015-11-22 Sun 19:58]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 19:58]
标签： 搜索引擎 seo数据 数据分析 搜集seo数据 seo数据分析	分类： SEO策略技巧
　　现在越来越多的人开始谈数据，无论是网络营销还是线下的市场营销都意识到了数据的重要性，凡是都以数据来说话。通过数据获得更多的有价值信息和利益已经成为这个时代关注的内容，但是很多人不清楚需要搜集什么样的数据;也有的不清楚通过什么渠道来搜集数据;还有大部分不清楚搜集整理的数据如何去分析，进而也就不清楚怎么去利用这些数据。所以，很多数据无法去转化和为公司利益服务，反而成为一堆让人头疼的数字。
*** 先来说说三类将数据做成摆设的类型： 
　　1、“被数据”类型，这一类型重视数据但不清楚如何搜集，对数据处于模糊了解状态，针对数据的重要性，也重视数据。但是由于没有专业的相关数据人员，不知道该做哪些数据，通过什么渠道来搜集整理，可谓是一知半解。最后可能是通过头脑风暴和网上的所谓教程来总结数据，这样的数据的实用性就很小了，有时候甚至是错误的。
 
　　2、“误数据”类型，这一类型了解所需数据但来源不规范，对数据比较了解。但是同样由于没有专业的相关数据人员，对于数据的来源和制作并不规范，数据采集也可能存在误差。所以，这些数据就可能失真，利用价值自然也不是很大。其实，这类数据比第一类更加成了摆设。
 
　　3、“贱数据”类型，这一类型会做数据但不会解读分析，对数据有清楚了解，并有准确的数据来源和较明确的数据需求，但是却等于入宝山而空回，坐拥金矿却不会利用。
 
　　同样，网络营销中也有很多相关网站SEO的数据搜集和分析。这对网络营销有很大的推进作用，下面就是一些较为大众化的数据模式。
SEO数据如何搜集和分析
*** 1、做哪些数据。有关SEO的数据应该需要三方面：
**** ①自身及竞争对手网站外部可统计查询数据：
这部分数据可以通过外部站长工具综合查询得出。主要包括但不局限于：
 
　　网站网址、快照日期、域名年龄、网站响应时间、同IP网站、pr值、百度权重、各搜索引擎收录量、各搜索引擎反链数、友情链接详情、24小时百度收录、百度排名词量、预计百度流量、外链数、标题、meta标签、服务器信息。这些数据除适用于首页外，也可以适当用来查询内页数据。
 
**** ②网站流量统计数据
　　目前现在大部分网站均采用流量统计工具，极大的方便了SEO相关人员统计整理数据的工作。具体有哪些统计工具就不多说了，流量数据主要包括但不限于：
 
　　IP、PV、独立访客、人均浏览量、平均访问页数、平均访问时长、跳出率、受访页面和域名、来源、搜索引擎比例、搜索关键词、访客详情、时段分析。 
**** ③可监控关键词数据
　　关键词监控需要很大的工作量，不仅需要统计自己的，最好也要统计同行及整个行业的，建议把关键词进行分类监控汇总。主要包括但不限于：
 
　　主关键词、主要长尾词、重要流量词、品牌词等，并且需要根据热点和实际情况不断的挖掘更多的关键词。
 
　　这些数据都可做成表格，以供定期查询，按照实际需求增减相关数据的查询。不断对比数据，获取优化方案。
 
*** 2、通过什么渠道来搜集数据
 
　　①自身及竞争对手网站外部可统计查询数据。既然是外部可查询，一般的站长类工具都可以去查询。
 
　　②网站流量统计数据。流量统计工具的功能已经很全，还可以进行相关数据的下载。不过只能针对有权限的网站。
 
　　③可监控关键词数据。这个可以一些通过辅助工具和人工搜索结合起来统计。
 
*** 3、如何分析搜集整理的数据
**** ①自身及竞争对手网站外部可统计查询数据。
　　这些数据分析是作为一个SEO分析自身网站和竞争对手最常用也是最基本的能力。通过这些数据可以比较清楚的了解自身网站和竞争对手的网站优化情况以及在搜索引擎的权重表现。也可以了解整个行业的情况。具体包括：
 
　　百度快照：一个网站快照越新，起码证明一个网站的内容每天都有新鲜的，百度蜘蛛的抓取更新也是比较频繁的，换言之，快照是百度蜘蛛对该网站的认可度。
 
　　域名年龄：同等条件下，域名越老在搜索引擎获得权重相对越高。
 
　　响应时间：这反映出网站的服务器性能的好坏。响应值越大，服务器性能越差，当然无论对于用户体验还是搜索引擎都是极为不利的影响。
 
　　同IP网站：可以查看该IP下有多少网站，可以大致区分出网站所有者是选择网站托管还是购买独立IP，如果是独立IP，顺便可以看出该所有者还有哪些网站，顺藤摸瓜查看其他网站情况，知己知彼。
 
　　PR值：虽然现在PR值越来越被淡化，但是pr值依然是判断一个网站外链质量的最好依据。
 
　　百度权重：尽管这个数据并没有得到百度的官方认可，但是却是现在广大站长最关心的一个数据之一。
 
　　反链数（外链）：通过站长工具查询的搜索引擎的反链数值其实大多都不是很准确，尤其是百度反链，查询命令得出的结果很不理想，百度反链值其实只是查询的域名相关域的搜索结果。但是反链数体现了一个网站的被推荐程度，也是数据统计必不可少的一个。
 
　　收录量：各搜索引擎的总收录反映出网站在各个搜索引擎的表现。如果了解网站的总页面数，也可以更清楚的判断网站被各个搜索引擎收录的情况，从而分析网站是否存在问题以及存在哪些问题。收录的速度也体验了搜索引擎对网站的喜爱程度。
 
　　排名词量：通过查看自己和竞争对手网站的排名词量，可以寻找网站优化之间的差距，进而查看各个网站针对这些排名关键词相对应页面的具体优化情况。
 
　　meta标签：查看网站该页面title、description、keywords是如何撰写的，进行比较分析。
 
**** ②网站流量统计数据
 
　　自身精确的网站流量统计数据可以让站长对网站得到更多的了解。看出网站目前的优化情况，并可以为网站以后运营提供很好的参考。
 
　　流量的分析往往不是单一的，是综合多种数值进行分析判断。这块的分析也是最为复杂的。
 
　　IP、PV：这类数值一般是进行周期性的比较，往往与跳出率和平局访问时长、页面数进行对比，从而判断网站的用户体验和用户黏性。
 
　　uv：独立访客量，可以反映出有多少台电脑，也可能接近于多少真实人在访问网站。
 
　　人均浏览量、平均访问时长、跳出率：IP与PV的比值，反映出网站用户体验好坏。
 
　　受访域名和页面：可以看出网站哪些页面比较受欢迎以及在搜索引擎的权重表现。
 
　　来源：访客是通过何种渠道进入到网站的，再进一步分析来源相关属性，可以更加清楚网站的目标人群以及网站运营策略执行情况。
 
　　关键词：用户是搜索何种关键词来到网站，为网站布置关键词以及寻找关键词优化是一个很好的途径。
 
　　访客属性：通过对访客的地域、教育程度、浏览器、网络接入商、操作系统、终端类型等属性的分析，可以更加详细的了解网站用户的情况，为以后网站的优化和运营提供参考。
 
　　热点图：这个热点图功能，可以让站长看到页面内容被用户点击的情况，反映出网站页面的用户体验度以及为页面内容改进提供参考。
 
**** ③可监控关键词数据
　　相对来说这块数据分析较为简单些，通过对关键词分类整理，然后查询在搜索引擎的排名情况，进而对比分析关键词带来的转化，可以看出优化情况。同时通过关键词带来的流量和转化，也可以对比分析其它流量贡献的转化，进而为整个网站运营方向和公司预算做出参考。
 
　　欢迎分享本文（http://blog.sina.com.cn/mumuhouzi） 给你的朋友，特别是给那些在做人脉，玩社群，玩圈子的朋友，关注互联网和网络营销的朋友多多交流，QQ&微信：809472503。
 
　　公众号：mumuseo，有更多网络营销干货，网络推广策略，引流技巧，成功案例故事等诸多优质内容，提升自己的专业能力！如果你想和我扯扯，欢迎关注。公众号回复“SEO核心技术”可免费获取《这就是搜索引擎 SEO核心技术详解》完整版！　
** DONE #<<my-anchor-ip-pv-uv>> [[http://blog.sina.com.cn/s/blog_c206a2c30101d6so.html][seoer经常遇到的pv，ip，uv]] 
     CLOSED: [2015-11-22 Sun 20:00]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 20:00]
标签： seo pv uv ip	分类： SEO策略技巧
　　有一些行开始做seo的朋友在统计数据时经常分不清什么是pv，ip和uv，今天在这里我简单的说一下:
*** PV(访问量)、UV(独立访客)、IP(独立IP)
 
　　PV(访问量)：即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次。
　　UV(独立访客)：即Unique Visitor,访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次。
　　IP(独立IP)：即Internet Protocol,指独立IP数。00:00-24:00内相同IP地址之被计算一次。
　　访问出口入口应该是记录IP来源/接入网站名称。
 
*** 说下ip,pv,uv的区别
 
　　独立IP表示，拥有特定唯一IP地址的计算机访问您的网站的次数，因为这种统计方式比较容易实现，具有较高的真实性，所以成为大多数机构衡量网站流量的重要指标。比如你是ADSL拨号上网的，你拨一次号都自动分配一个ip，这样你进入了本站，那就算一个ip，当你断线了而没清理cookies，之后又拨了一次号，又自动分配到一个ip，你再进来了本站，那么又统计到一个ip，但是UV(独立访客)没有变，因为2次都是你进入了本站。
 
　　说明一下PV高不一定代表来访者多;PV与来访者的数量成正比，但是PV并不直接决定页面的真实来访者数量。比如一个网站就你一个人进来，通过不断的刷新页面，也可以制造出非常高的PV。
 
　　ip在这里是指公用的广域网传输协议族(Tcp/Ip)为每一台处在因特网上的计算机(可以是个人电脑、服务器以及其他兼容广域网传输协议族规定的接入设备)都定义了四个段落(例如：192.168.0.255形式，有时会加入第五段落端口号作为描述信息，端口号是介于1-65535之间的数字)共32位长度二进制代码的标识，叫IP协议地址，简称ip地址，俗称ip，它是一个一台连接着广域网的计算机区别于其他机器的标识，一般情况下，它在同一级别的网络(例如某个局域网、社区网、教学楼网或者INTERNET)范围内是唯一的。
 
*** 独立访客是指不同的、通过互联网访问、浏览一个网页的自然人。
 
　　比如，在一台电脑上，哥哥打开了微软的官方主页，注册了一个会员。弟弟一会儿也看了看，注册了另一个会员。由于兄弟两个使用的是相同的计算机，那么他们的 ip是一样的，微软的官方计数器记录到一个ip登陆的信息。但是具有统计功能的统计系统，可以根据其他条件判断出实际使用的用户数量，返回给网站建设者真实、可信和准确的信息。比如通过注册的用户，甚至可以区分出网吧、机房等共享一个ip地址的不同计算机。上面的例子就说明虽然是同一ip，但是有2个独立访客。再举个例子，比如一个网吧里，有100个人都进入了我的网站，但是一个网吧对外都是一个IP的，所以统计系统只统计到一个IP;但是因为网吧里有100人在访问我的站，尽管他们都仅仅打开我的网站的首页，或者这100人都把我网站所有页面都看过了一遍，统计系统都只统计到100个独立访客。
 
*** 使用独立用户作为统计量有什么好处?它比ip更加准确吗?
 
　　ip是一个反映网络虚拟地址对象的概念，独立用户是一个反映实际使用者的概念，每个独立用户相对于每个ip，更加准确地对应一个实际的浏览者。使用独立用户作为统计量，可以更加准确的了解单位时间内实际上有多少个访问者来到了相应的页面。
 
    文章来自：木木seo  http://blog.sina.com.cn/mumuhouzi
** 白帽SEO
*** TODO [[http://www.20shx.com/article_4/2014-02-15/24.html][如何增加网站访问量]]
*** TODO [[http://www.20shx.com/article_4/2014-02-12/19.html][网站收录方法(SEO)]]
*** TODO [[http://www.520link.com/][爱链网 -- 友链交易平台]]
** 黑帽SEO的实例
*** 链轮 aka.links farm
[[http://cyepu.com/wangshang_jianzhizhuanqian/][网络上做兼职正规赚钱方法项目大全]]
[[http://cyepu.com/wangluojianzhi_zhuanqiankuai/][2015年网络上兼职怎么赚钱最快的方法]]
[[http://cyepu.com/nvxingchuizhishequ_zhuanqian/][女性垂直社区最好赚的钱你想赚吗？]]
[[http://cyepu.com/caogenzhuanqian_muyingchanpin/][草根如何操作母婴产品月入过万]]
[[http://cyepu.com/weixinyingxiao_qqqunyingxiao/][玩赚微信营销别忘了QQ群营销]]
[[http://cyepu.com/wangluoyingxiao_kehuxiadan/][网络营销最新技巧是什么怎么做好]]
[[http://cyepu.com/zuoyingxiao_fenxikehu/][做营销分析客户像把妹一样分析]]
[[http://cyepu.com/lanxiang_wangluoyingxiao/][哪家接地气的网络营销现在最强？]]
[[http://cyepu.com/o2o_jiediqiyingxiao_qqqun/][玩赚O2O还是大妈的QQ群最接地气]]
[[http://cyepu.com/kuaisuzhuanqian_yinliuliang/][网上靠谱快速赚钱发财的门路方法]]
[[http://cyepu.com/zaiwangshang_zhuanqian/][2015年怎么样在网上兼职可以快速赚钱]]
[[http://cyepu.com/xiangmu/][分类：赚钱项目]]
*** 链轮2
[[http://ssffx.com/SEOjishu/318.html][百度广告联盟从申请到赚钱的流程]]
[[http://ssffx.com/SEOjishu/129.html][如何利用时效性来引爆网站流量]]
[[http://ssffx.com/SEOjishu/91.html][百度SEO网站排名分析]]
[[http://ssffx.com/SEOjishu/50.html][百度绿萝算法2.0的目的是什么]]
[[http://ssffx.com/wangluoyingxiao/49.html][如何做网络营销]]
[[http://ssffx.com/zhanchangxinwen/48.html][让人爱恨惨半的微信5.0]]
*** #<<my-anchor-bbs-colloctor>> [[http://www.baike.com/wiki/%25E8%25AE%25BA%25E5%259D%259B%25E9%2587%2587%25E9%259B%2586%25E5%2599%25A8][论坛采集器]]
[[http://www.36dsj.com/archives/category/data-analysi][数据分析 -- 36dsj]]
[[http://yingxiao.tui18.com/bingduyingxiao/][病毒营销 -- tui18]]
[[http://www.mp4works.cn/][病毒营销 -- mp4works]]
[[http://iwebad.com/interactive-marketing/viral-marketing/][病毒营销 -- iwebad]]
*** Web页面信息采集
[[http://www.wanbizu.com/s/%25E7%2583%25A4%25E7%258C%25AB%2B%25E8%2582%25A1%25E7%25A5%25A8.html][烤猫 股票相关教程]]
*** #<<my-anchor-global.asa>> [[http://www.w3school.com.cn/asp/asp_globalasa.asp][ASP Global.asa 文件]]
*** #<<my-anchor-bbs-automately-post>> [[http://www.baike.com/wiki/%25E8%2587%25AA%25E5%258A%25A8%25E9%25A1%25B6%25E8%25B4%25B4%25E6%259C%25BA][自动顶贴机]]
*** #<<my-anchor-information-broadcast>> [[http://www.baike.com/wiki/%25E4%25BF%25A1%25E6%2581%25AF%25E7%25BE%25A4%25E5%258F%2591%25E8%25BD%25AF%25E4%25BB%25B6][信息群发软件]]
*** #<<my-anchor-virtual-links>> 虚假链接
[[http://blog.sina.com.cn/s/blog_c206a2c30101emv6.html][20种黑帽SEO作弊手法(下)]] 中 [[http://blog.sina.com.cn/s/blog_c206a2c30101cv3p.html][石榴算法]] 的链接跳转到一个采集页面 [[http://blog.sina.com.cn/s/blog_c206a2c30101cv3p.html][【木木推荐】网络营销/新媒体营销精彩文章汇总]]
*** #<<my-anchor-cheat-click-links>> 欺骗点击链接
[[http://blog.sina.com.cn/s/blog_c206a2c30101emv6.html][20种黑帽SEO作弊手法(下)]] 中 [[http://blog.sina.com.cn/s/blog_c206a2c30101dxip.html][百度刷排名的原理]] 链接到“点击网站排名的影响”这篇文章
*** [[http://www.cnjushui.com/cnjushui/flashsky%2B%25E5%258D%259A%25E5%25AE%25A2][关键词堆砌]]
通过关键词堆砌能做到google排名第一,query:"flashsky 我的安全之路".
** 其他关于SEO的文章
** DONE #<<my-anchor-baidu-Baiduspider>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dg0e.html][百度Baiduspider]]
     CLOSED: [2015-11-22 Sun 20:38]
     - State "DONE"       from ""           [2015-11-22 Sun 20:38]
*** 1. 什么是Baiduspider
 
　　百度蜘蛛，英文名是“Baiduspider”是百度搜索引擎的一个自动程序。它的作用是访问互联网上的网页、图片、视频等内容，建立索引数据库，使用户能在百度搜索引擎中搜索到您网站的网页、图片、视频等内容。
百度Baiduspider

*** 2. Baiduspider的user-agent是什么?
 
　　User Agent中文名为用户代理，简称 UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件等。Baiduspider的user-agent是指在网页robots.txt文件里表示针对百度蜘蛛禁止其访问及收录的内容百度各个产品使用不同的user-agent：
 
　　无线搜索Baiduspider
　　图片搜索Baiduspider-image
　　视频搜索Baiduspider-video
　　新闻搜索Baiduspider-news
　　百度搜藏Baiduspider-favo
　　百度联盟Baiduspider-cpro
　　商务搜索Baiduspider-ads
　　网页以及其他搜索Baiduspider
 
*** 3. 为什么Baiduspider不停的抓取我的网站?
 
　　对于您网站上新产生的或者持续更新的页面，Baiduspider会持续抓取。此外，您也可以检查网站访问日志中Baiduspider的访问是否正常，以防止有人恶意冒充Baiduspider来频繁抓取您的网站,那 如何判断是否冒充Baiduspider的抓取?直接记录下ip用一些工具查询即可，如站长工具中的ip查询,参考[[my-anchor-baiduspider-ip-from][百度蜘蛛ip来路]].
 
*** 4. 我不想我的网站被Baiduspider访问，我该怎么做?
 
　　Baiduspider遵守互联网robots协议。您可以利用robots.txt文件完全禁止Baiduspider访问您的网站，或者禁止 Baiduspider访问您网站上的部分文件。以下robots实现禁止所有来自百度的抓取：
 
　　User-agent: Baiduspider
　　Disallow: /
 
　　以下robots实现禁止所有来自百度的抓取但允许图片搜索抓取/image/目录：
 
　　User-agent: Baiduspider
　　Disallow: /
　　User-agent: Baiduspider-image
　　Allow: /image/
 
*** 5. 为什么我的网站已经加了robots.txt，还能在百度搜索出来?
 
　　因为搜索引擎索引数据库的更新需要时间。虽然Baiduspider已经停止访问您网站上的网页，但百度搜索引擎数据库中已经建立的网页索引信息，可能需要数月时间才会清除。另外也请检查您的robots配置是否正确。
 
*** 6. 我希望我的网站内容被百度索引但不被保存快照，我该怎么做?
 
　　Baiduspider遵守互联网meta robots协议。您可以利用网页meta的设置，使百度显示只对该网页建索引，但并不在搜索结果中显示该网页的快照。
 
　　和robots的更新一样，因为搜索引擎索引数据库的更新需要时间。以上可以参看[[my-anchor-search-engine-cache][搜索引擎缓存机制]]
 
*** 7. Baiduspider抓取造成的带宽堵塞?
 
　　Baiduspider的正常抓取并不会造成您网站的带宽堵塞，造成此现象可能是由于有人冒充Baiduspider恶意抓取。
 
*** 8. Baiduspider对一个网站服务器造成的访问压力如何?
 
　　为了达到对目标资源较好的检索效果，Baiduspider需要对您的网站保持一定量的抓取。我们尽量不给网站带来不合理的负担，并会根据服务器承受能力，网站质量，网站更新等综合因素来进行调整。如果您觉得baiduspider的访问行为有任何不合理的情况，您可以反馈至反馈中心。
 
　　文章来自:木木seo    http://blog.sina.com.cn/mumuhouzi，
QQ：809472503。如果你觉得这篇文章有价值，可以分享给你的朋友，如果你觉得没有价值，没有关系，请给以指导，这是一次改变的机会。
** DONE #<<my-anchor-baiduspider-ip-from>> [[http://blog.sina.com.cn/s/blog_c206a2c30101df52.html][百度蜘蛛IP来路分析]]
     CLOSED: [2015-11-22 Sun 21:46]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 21:46]
标签： 百度蜘蛛ip baiduspider	分类： SEO策略技巧
[[my-anchor-baidu-Baiduspider][百度蜘蛛]](Baiduspider)爬取是搜索引擎获得页面内容的一个重要的途径，通过蜘蛛的抓取可以得到一个页面的最主要的内容从而收录百度数据库系统，每次抓取之后都会再与数据库原有的信息进行比对，来确定页面的总体质量。

那么，每当[[my-anchor-search-engine][蜘蛛来抓取]]的时候都会被网站日志文件记录下来，具体包括抓取时间，抓取的页面以及蜘蛛来路IP地址，上次说到百度蜘蛛(Baiduspider)ip来路基本能够反映出不同蜘蛛对站点不同页面的喜好程度，从侧面也反映出整个网站不同页面的权重值，通过自己一系列的分析，可以较为准确的评估整站的权重分布，对于seo、文章内容价值、用户体验都起到很好的参考价值。
 
所以这次就分享一下，关于不同来路IP所代表的一些基本含义（注意，这是百度蜘蛛的ip）：
 
123.125.68.*  这个蜘蛛经常来,别的来的少,表示网站可能要进入沙盒了，或被者降权。

 
220.181.68.*  每天这个IP 段只增不减很有可能进沙盒或K站。

220.181.7.*、123.125.66.*   代表百度蜘蛛IP造访，准备抓取你东西。

 
121.14.89.*  这个ip段作为度过新站考察期。

203.208.60.*  这个ip段出现在新站及站点有不正常现象后。

 
210.72.225.*  这个ip段不间断巡逻各站。

125.90.88.*   广东茂名市电信也属于百度蜘蛛IP 主要造成成分，是新上线站较多，还有使用过站长工具，或SEO综合检测造成的。

220.181.108.95  这个是百度抓取首页的专用IP，如是220.181.108段的话，基本来说你的网站会天天隔夜快照。

 
220.181.108.92  同上98%抓取首页，可能还会抓取其他 (不是指内页)220.181段属于权重IP段此段爬过的文章或首页基本24小时放出来。

123.125.71.106  抓取内页收录的，权重较低，爬过此段的内页文章不会很快放出来，因不是原创或采集文章。

220.181.108.91  属于综合的，主要抓取首页和内页或其他，属于权重IP 段，爬过的文章或首页基本24小时放出来。

220.181.108.75  重点抓取更新文章的内页达到90%，8%抓取首页，2%其他。权重IP 段，爬过的文章或首页基本24小时放出来。

220.181.108.86  专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

123.125.71.95   抓取内页收录的，权重较低，爬过此段的内页文章不会很快放出来，因不是原创或采集文章。

123.125.71.97   抓取内页收录的，权重较低，爬过此段的内页文章不会很快放出来，因不是原创或采集文章。

220.181.108.89  专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

 
220.181.108.94  专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

220.181.108.97  专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

 
220.181.108.80  专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

 
220.181.108.77  专用抓首页IP 权重段，一般返回代码是304 0 0 代表未更新。

123.125.71.117  抓取内页收录的，权重较低，爬过此段的内页文章不会很快放出来，因不是原创或是采集文章。

注：以上IP尾数还有很多，但段位一样的123.125.71.*  段IP 代表抓取内页收录的权重比较低，可能由于你采集文章或拼文章暂时被收录但不放出来.。

220.181.108.83专用抓取首页IP 权重段，一般返回代码是304 0 0 代表未更新。

220.181.108.*  段IP主要是抓取首页占80%，内页占30%，这此爬过的文章或首页，绝对24小时内放出来和隔夜快照的!

一般成功抓取返回代码都200，返回304代表网站没更新。
 
文章来自:木木seo  http://blog.sina.com.cn/mumuhouzi， 以上信息仅供参考，因为并没有官方验证！ 
** DONE #<<my-anchor-search-engine-cache>> [[http://blog.sina.com.cn/s/blog_c206a2c30101d212.html][搜索引擎的缓存机制]]
     CLOSED: [2015-11-22 Sun 20:23]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 20:23]
标签： seo 搜索引擎 搜索引擎缓存	分类： 搜索引擎秘籍
　　百度几乎每个星期都会更新一次，而且通常会选择在夜阑人静的凌晨时分更新。这里所说的更新便是搜索引擎的缓存更新。本文将为大家简单介绍搜索引擎的缓存机制。

*** [[my-anchor-search-engine-sth][搜索引擎]]的缓存

　　缓存也即cache，是计算机领域非常常用的一种技术，我们最熟悉的，恐怕就是浏览器的缓存。

　　搜索引擎的缓存可以这样简单描述：在高速内存硬件设备开辟一块数据存储区，用来存储搜索用户的查询、索引数据、搜索的中间结果或者最终的搜索结果。缓存的大小是有限度的，不可能无限存储数据。因此搜索引擎会采取缓存更新策略和缓存淘汰策略管理维护缓存区存储的数据。

*** 搜索引擎缓存的价值

　　搜索引擎缓存具有两个价值：

　　一、加快响应搜索用户查询的速度，提高搜索用户体验;

　　二、减少搜索引擎后台的计算量，节省计算资源。

　　搜索引擎的缓存更新策略对提高搜索用户的体验方面起着举足轻重的作用。

　　不同网站的快照是不一样的，为何会这样?因为每个网站的更新频率和权重互异。即便是用不同关键词去搜索同一个网站，这个网站也会呈现不一样的百度快照。为何?因为搜索引擎的缓存。你搜索“厦门SEO”这个词所返回的搜索结果，很有可能是搜索引擎直接在缓存区直接调用的结果。因为缓存区中直接匹配到了你的搜索，搜索引擎无需重新计算排序。

　　即便你的网站不断有新的更新内容，而且搜索引擎也索引了你网站的最新内容，但当你搜索某些关键词时，你依然只能看到旧的网站内容，因为缓存内容不会随着索引内容发生即时的改变。这种不一致或多或少地影响了用户体验。

　　搜索引擎为了让索引内容与缓存内容尽量保持一致，推出了两种缓存更新策略：缓存——索引密切耦合策略;缓存——索引非耦合策略。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi
** DONE #<<my-anchor-search-engine-sth>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dn0p.html][揭秘搜索引擎算法背后的一些事]]
     CLOSED: [2015-11-22 Sun 20:36]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 20:36]
*** 一、搜索引擎算法
**** [[my-anchor-baidu-search-engine-principle][搜索引擎]]算法： 
获得网站网页资料，建立数据库并提供查询的系统，我们都可以把它叫做搜索引擎。搜索引擎的数据库是依靠一个叫“网络机器人（crawlers）”或叫“网络蜘蛛（Spider）”的软件，通过网络上的各种链接自动获取大量网页信息内容，并按一定的规则分析整理形成的。Google、百度都是比较典型的搜索引擎系统。 为了更好的服务网络搜索，搜索引擎的分析整理规则---即搜索引擎算法是变化的。
 
计算公式
 
GoogleScore = (KW Usage Score * 0.3) + (Domain Strength * 0.25) +(Inbound Link Score * 0.25) + (User Data * 0.1) + (Content Quality Score * 0.1) + (Manual Boosts) – (Automated & Manual Penalties)
 
翻译：
 
Google分数=（相关关键词分数X0.3）+（域名权重X0.25）+（外链分数X0.25）+（用户数据X0.1）+（内容质量分数X0.1）+（人工加分）-（自动或人工降分） 
阻尼因数(damping factor)。阻尼因素d就是当你投票或链接到另外一个站点时所获得的实际PR分值。阻尼因数一般是0.85。当然比起你网站的实际PR值，它就显得微不足道了。现在让我们来看看这个PR分值的计算公式：

PR(A) = (1-d) + d(PR(t1)/C(t1) + … + PR(tn)/C(tn))


其中PR(A)表示的是从一个外部链接站点t1上，依据Pagerank?系统给你的网站所增加的PR分值；PR(t1)表示该外部链接网站本身 的PR分值；C(t1)则表示该外部链接站点所拥有的外部链接数量。大家要谨记：一个网站的投票权值只有该网站PR分值的0.85，而且这个0.85的权 值平均分配给其链接的每个外部网站。
 
从公式中我们可以清楚的知道，影响pagerank分数的因素依次是“相关关键词”、“域名”、“外链”、“用户数据”、“内容质量”以及“人工干预”六个方面。
**** 那么又是哪些因素影响到了这几个方面呢？
***** 关键词分数
 
1.网页title中关键词的处理
2.H标签（h1-h6）中关键词的处理
3.文本内容中关键词的密度
4.外链中关键词的选择
5.域名中的关键词
 
***** [[my-anchor-domain-dns][域名]]权重
 
1.域名注册前的历史问题
2.域名注册时间的长短
3.外链网站的权重
4.外链、给出链接的相关度
5.是否使用历史、链接形式
 
***** 外链分数
 
1.链接域名权重
2.是否锚文本
3.链接数量/链接权重（PR或其他参数）
4.外链网页的主题相关度
5.链接的时间
 
***** 用户数据
 
1.搜索引擎结果页面(SERPs)的点击率(pv)
2.用户在网页上呆的时间
3.域名或URL搜索量
4.访问量及其他*可以监测到的数据（工具条、GA等）
 
***** 内容质量分数
 
1.内容的相关度
2.内容的原创性
3.内容的独特性
4.内容的抢先性和长效性
 
***** 人工干预
 
1.投票人员干预
2.关键词人工加（扣）分
3.机器算法干预
 
*** 二、搜索引擎工作内容
[[file:./tomsinsight-hack/SEO成功金字塔模型.jpg][SEO成功金字塔模型.jpg]]
 
谈搜索引擎工作内容之前，我们必须了解[[my-anchor-baidu-Baiduspider][搜索引擎蜘蛛]]。
 
搜索引擎蜘蛛即Search Engine Spider，是一个很形象的名字。把互联网比喻成一张蜘蛛网，那么Spider就是在网上爬来爬去的蜘蛛。搜索引擎蜘蛛是通过网页的链接地址来寻找网页，从网站某一个页面（通常是首页）开始，读取网页的内容，找到在网页中的其它链接地址，然后通过这些链接地址寻找下一个网页，这样一直循环下去，直到把这个网站所有的网页都抓取完为止。如果把整个互联网当成一个网，那么搜索引擎蜘蛛就可以用这个原理把互联网上所有节点的网页都抓取下来。

**** 1、[[my-anchor-baiduspider-crawl][抓取收录]]页面：
 
由于互联网上无数的网站页面，搜索引擎蜘蛛无法将所有的页面都下载保存到服务器。因此，许多搜索引擎的网络蜘蛛不是所有的页面都抓取的，只是抓取那些重要的网页，而在抓取的时候评价重要性主要的依据是某个网页的链接广泛度及外部链接的数量与质量。所以在给网站加外链时不要只给首页外链，其他页面也要加（这和外链的随机性也有关）。
 
在抓取网页的时候，搜索引擎蜘蛛一般有两种策略：广度优先和深度优先。广度优先是指搜索引擎蜘蛛会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。这是最常用的方式，因为这个方法可以让搜索引擎蜘蛛并行处理，提高其抓取速度。深度优先是指搜索引擎蜘蛛会从 起始页开始，一个链接一个链接跟踪下去，处理完这条线路之后再转入下一个起始页，继续跟踪链接。这个方法有个优点是搜索引擎蜘蛛在设计的时候比较容易。
 
由于不可能抓取所有的网页，有些搜索引擎蜘蛛对一些不太重要的网站，设置了访问的层数。例如A为起始网页，属于0层，B、C、D、E、F属于第1 层，G、H属于第2层，I属于第3层。如果搜索引擎蜘蛛设置的访问层数为2的话，网页I是不会被访问到的。这也让有些网站上一部分网页能够在搜索引擎上搜索到，另外一部分不能被搜索到。对于网站设计者来说，扁平化的网站结构设计有助于搜索引擎抓取其更多的网页。
 
**** 2、过滤页面：
 
很多页面被百度收录之后，百度认为该页面对用户没有太大的价值，或者是质量度比较低的页面，百度必然就会过滤，这也是用户体验好的一种表现。
 
**** 3、预处理：
 
（1）提取文字。除了用户可见的文字信息外，还有代码中的文字信息。
（2）中文分词。详见百度中文分词。
（3）去停止词。停止词即一些很常见的词，如：的、地、和、得等，百度搜索引擎会忽略掉这些词。
（4）消除噪音。根据html的标签对页面进行分块。
（5）去重。搜索引擎根据特征关键词计算指纹区分。
（6）索引。一般我们说的索引是正向索引，正向索引是将页面转化为关键词组成的集合。
（7）倒排索引。正向索引还不能直接用于排名，通过倒排索引将之前的页面对应关键词的集合转换成各个关键词对应的页面集合。
（8）链接关系计算。计算各网页间的链接流动信息。
（9）word、pdf等特殊文件的处理。
 
经过了收录页面以及过滤页面的工作之后，百度会对这些页面逐一进行标记和识别，并将这信息进行储存为结构化的数据，储存到百度的搜索的服务器中，这些储存的数据有网页的信息、网页的标题关键词页面描述等标签、网页外链及描述、抓取记录。还会将网页中的关键词信息进行识别和储存，以便与用户搜索的内容进行匹配。建立完善的索引数据库，方便呈现出最佳的显示信息
 
**** 4、显示信息：
 
用户输入的关键词，百度会对其进行一系列复杂的分析，并根据分析的结论在索引库中寻找与之最为匹配的一系列网页，按照用户输入的关键词所体现的需求强弱和网页的优劣进行打分，并按照最终的分数进行排列，展现给用户。一般显示出最佳信息需要是最适合匹配关键词相关的页面，包括站内优化和站外优化的因素。收索引擎显示信息的工作过程主要包括以下几方面：
 
（1）搜索词的处理。这一步和前面的预处理一样也要中文分词、去停止词。还要进行指令处理，拼写错误矫正，整合搜索触发。
（2）文件匹配。匹配出与搜索词相关的网页。
（3）初始子集选择。搜索引擎不可能去分析所有的相关的网页，需要选出页面权重相对高一些的一个网页集（1000个左右）。
（4）相关性计算。子集选好后计算排名，一般要考虑关键词的常用程度，常用的关键词加权系数低；关键词出现频率及密度；关键词的形式和位置；关键词的结构距离和链接距离；链接分析及页面权重，之后得出排名。
（5）排名过滤及调整，过滤一些作弊等。
（6）排名显示。
（7）搜索缓存。搜索引擎不可能对每次一样的搜索都做大量的计算，所以需要对一样的搜索做缓存。
（8）查询及点击日志，对搜索用户的搜索做统计，并根据该用户搜索习惯给出相应结果。
 
*** 三、百度搜索引擎的特点
 
**** 1. 基于字词结合的信息处理方式。
巧妙解决了中文信息的理解题目，极大地进步了搜索的正确性和查全率。
 
**** 2. 支持主流的中文编码尺度。
包括GBK（汉字内码扩展规范）、GB2312（简体）、BIG5（繁体），并且能够在不同的编码之间转换。
 
**** 3. 智能相关度算法。
采用了基于内容和基于超链分析相结合的方法进行相关度评价，能够客观分析网页所包含的信息，从而最大限度保证了检索结果相关性。
 
**** 4. 检索结果能标示丰硕的网页属性。
（如标题、网址、时间、大小、编码、摘要等）并凸起用户的查询串，便于用户判定是否阅读原文。
 
**** 5. 百度搜索支持二次检索（又称渐进检索或逼进检索）。
可在上次检索结果中继承检索，逐步缩小查找范围，直至达到最小、最正确的结果集。利于用户更加利便地在海量信息中找到自己真正感爱好的内容。
 
**** 6. 相关检索词智能推荐技术。
在用户第一次检索后，会提示相关的检索词，匡助用户查找更相关的结果，统计表明可以促进检索量晋升10-20%。
 
**** 7. 运用多线程技术、高效的搜索算法、不乱的UNIX平台、和本地化的服务器，保证了最快的响应速度。
百度搜索引擎在中国境内提供搜索服务，可大大缩短检索的响应时间（一个检索的均匀响应时间小于0.5秒）
 
**** 8. 可以提供一周、二周、周围等多种服务方式。
可以在7天之内完成网页的更新，是目前更新时间最快、数据量最大的中文搜索引擎。
 
**** 9. 检索结果输出支持内容类聚、网站类聚、内容类聚+网站类聚等多种方式。
支持用户选择时间范围，进步用户检索效率。
 
**** 10. 智能性、可扩展的搜索技术保证最快最多的收集互联网信息。
拥有目前世界上最大的中文信息库，为用户提供最正确、最广泛、最具时效性的信息提供了坚实基础。
 
**** 11. 分布式结构、精心设计的优化算法、容错设计保证系统在大访问量下的高可用性、高扩展性、高机能和高不乱性。
 
**** 12. 高可配置性使得搜索服务能够知足不同用户的需求。
 
**** 13. 提高前辈的网页动态摘要显示技术。
 
**** 14. 独占百度快照。
 
**** 15. 支持多种高级检索语法，
使用户查询效率更高、结果更准。已支持“+”（AND）、“-”（NOT）、“|”（OR）、“site:”、“link:”，还将继承增加其它高效的搜索语法。
 
*** 四、为什么要使用html的meta标签？
 
**** 1、 meta标签是内嵌在你网页中的特殊html标签，包含着你有关于你网页的一些躲藏信息。
meat标签的作用是向搜索引擎解释你的网页是有关哪方面信息的。对于高级的搜索引擎来说，html 的meta 标签并不是什么新颖的东西。但是不管如何它是一个优秀网页不可缺少的。下面我们就它进行一些讲解吧。
 
**** 2、当你计划搜索引擎优化策略是meta标签长短常重要的。
尽管如斯，一般的加入meta并不能匡助你在搜索引擎中获得更好的排名。有好几种meta标签，但重要的有以下几个：description标签， keywords标签，title标签（严格来说title不算是一个标签）。当你不时刷新标签时这几个标签显得特别的重要。假如你但愿搜索引擎对你的网站进行索引时就会用到 html标签的重定向（redirect）标签与robots标签。
 
**** 3、 title 标签，title 标签可能是你网页中最重要的标签，它是你网页中最先看到的部门。
把它放在description 与keyword前。在这个标签中最好是加上你网站的枢纽字，title标签在搜索引擎的搜索中据有非常重要的地位。最好是把它放在其他meta标签前，这更有利于你网站的排名。（留意：有些搜索引擎会按title标签的字母的优先权进行排名，尽量在你的title中使用开始的字母）title标签是人们在搜索引擎中第一个看到有关你网站的描述，所以尽量把它弄得简朴、明了。
 
**** 4、 Description标签，Description标签就在title后面，该标签可以是一小段（一个或者两个句子）。
用于描述你网站。与title标签一样，这也是人们在搜索引擎列表中链接到你网站的点击。这些描述将鼓动人们去浏览你的网站而不是你竞争对手的。（描述不能太夸张。不然，当访问者到你网站发现内容根本不是你说的那个样子，那么他很快就会退出去。）良多搜索引擎答应描述的字数在150个左右，所以你要保证你的描述在150以下，否则搜索引擎会自动把多余的部门剪去从而造成你网站的描述的不完整。搜索引擎以为描述里的枢纽字远比网页中的内容要重要。
 
**** 5、keyword 标签，比拟于description与title标签，keyword标签显得并不是那么重要了。
有些搜索引擎把它完全地忽略，但是使用准确的keyword标签对进步排名仍旧有效。
  
如果你觉得这篇文章有价值，可以分享给你的朋友。
** TODO #<<my-anchor-baidu-search-engine-principle>> [[http://blog.sina.com.cn/s/blog_c206a2c30101d6w8.html][百度搜索引擎原理]]
抓取网页
 
　　每个独立的搜索引擎都有自己的网页抓取程序（spider）。Spider顺着网页中的超链接，连续地抓取网页。被抓取的网页被称之为网页快照。由于互联网中超链接的应用很普遍，理论上，从一定范围的网页出发，就能搜集到绝大多数的网页。
 
处理网页
 
　　搜索引擎抓到网页后，还要做大量的预处理工作，才能提供检索服务。其中，最重要的就是提取关键词，建立索引文件。其他还包括去除重复网页、分词（中文）、判断网页类型、分析超链接、计算网页的重要度/丰富度等。
 
提供检索服务
 
用户输入关键词进行检索，搜索引擎从索引数据库中找到匹配该关键词的网页；为了用户便于判断，除了网页标题和URL外，还会提供一段来自网页的摘要以及其他信息。
 
搜索引擎的自动信息搜集功能分两种。一种是定期搜索，即每隔一段时间（比如Google一般是28天），搜索引擎主动派出“蜘蛛”程序，对一定IP地址范围内的互联网站进行检索，一旦发现新的网站，它会自动提取网站的信息和网址加入自己的数据库。
 
另一种是提交网站搜索，即网站拥有者主动向搜索引擎提交网址，它在一定时间内（2天到数月不等）定向向你的网站派出“蜘蛛”程序，扫描你的网站并将有关信息存入数据库，以备用户查询。由于近年来搜索引擎索引规则发生了很大变化，主动提交网址并不保证你的网站能进入搜索引擎数据库，因此目前最好的办法是多获得一些外部链接，让搜索引擎有更多机会找到你并自动将你的网站收录。　
　
　　你的网页被搜索引擎索引的越多，网站被用户访问的机会就越多。多数搜索引擎“拒绝”所递交URL的第二级或第三级以下层次网页的索引，如果你的网站有4-5级层次， spider就不带回网站的所有网页，解决的办法之一就是做一个“通道页”(hallway page)，“通道页”放置你网站的所有链接。
 
 百度搜索引擎原理


 
　　下面解释一下搜索引擎如何spider你的网站，假如你有一个网站—Chinese food，并向搜索引擎注册了网站的首页，首页即为树状结构的根部，如果首页包含两个链接，分别指向sichuan-food.htm和guangdong-food.htm，则这两个网页就是第二级，在sichuan-food.htm有链接指向chengdu-food.htm，则chengdu-food.htm为第三级，在 chengdu-food.htm有链接指向special-food.htm，则special-food.htm为第四级，如此类推。
 
　　第一级 index. htm
　　第二级 sichuan-food.htm和guangdong-food. htm
　　第三级 chengdu-food. htm
　　第四级 special-food. htm
 
　　多数搜索引擎“拒绝”索引第二级或第三级以下的层次，也就是说，第四级的所有网页(对某些搜索引擎包括第三级的所有网页)，将不能被搜索引擎发现，除非你直接注册这些网页，但不建议直接注册这些网页，因为这样将降低你的排名位置，并且容易超过搜索引擎规定的每日注册限制。这就是为什么要专门制作一个“通道页”的原因。
 
　  对于同一域名，某些搜索引擎限制接收的网页数，所以建议你在“通道页”中按网页的重要程度排序链接。
 
    文章来自：木木seo 　http://blog.sina.com.cn/mumuhouzi，QQ：809472503

** TODO #<<my-anchor-domain-dns>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dj44.html][DNS和域名解析相关知识]]
标签： dns 域名解析 dns域名解析	分类： 视觉/设计方案
1、什么是域名解析？ 
域名解析就是国际域名或者国内域名以及中文域名等域名申请后做的到IP地址的转换过程。IP地址是网路上标识您站点的数字地址，为了简单好记，采用域名来代替ip地址标识站点地址。域名的解析工作由DNS服务器完成。

2、什么是A记录？

A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的二级域名。

3、什么是MX记录？

邮件路由记录，用户可以将该域名下的邮件服务器指向到自己的mail server上，然后即可自行操控所有的邮箱设置。您只需在线填写您服务器的IP地址，即可将您域名下的邮件全部转到您自己设定相应的邮件服务器上。

4、什么是CNAME记录？

即：别名记录。这种记录允许您将多个名字映射到同一台计算机。通常用于同时提供WWW和MAIL服务的计算机。例如，有一台计算机名为“host.mydomain.com”（A记录）。它同时提供WWW和MAIL服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW和MAIL。这两个别名的全称就http://www.mydomain.com/和“mail.mydomain.com”。实际上他们都指向“host.mydomain.com”。

5、什么是TTL值？

TTL值全称是“生存时间（Time To Live)”，简单的说它表示DNS记录在DNS服务器上缓存时间。要理解TTL值，请先看下面的一个例子：
假设，有这样一个域名myhost.abc.com（其实，这就是一条DNS记录，通常表示在abc.com域中有一台名为myhost的主机）对应IP地址为1.1.1.1，它的TTL为10分钟。这个域名或称这条记录存储在一台名为dns.abc.com的DNS服务器上。

二、现在有一个用户在浏览器中键入一下地址（又称URL）：http://myhost.abc.com/ 这时会发生什么呢？
该访问者指定的DNS服务器（或是他的ISP,互联网服务商, 动态分配给他的)8.8.8.8就会试图为他解释myhost.abc.com，当然8.8.8.8这台DNS服务器由于没有包含myhost.abc.com这条信息，因此无法立即解析，但是通过全球DNS的递归查询后，最终定位到dns.abc.com这台DNS服务器，dns.abc.com这台DNS服务器将myhost.abc.com对应的IP地址1.1.1.1告诉8.8.8.8这台DNS服务器，然有再由8.8.8.8告诉用户结果。8.8.8.8为了以后加快对myhost.abc.com这条记录的解析，就将刚才的1.1.1.1结果保留一段时间，这就是TTL时间，在这段时间内如果用户又有对myhost.abc.com这条记录的解析请求，它就直接告诉用户1.1.1.1，当TTL到期则又会重复上面的过程。

三、为什么我做的解析没有生效？

以下的每种原因都有可能导致您的解析无法生效。
1、域名的DNS没有按要求设置成正确的DNS.
2、域名还没设置相应的解析记录.

四、怎样检查域名的DNS是否已经设置为有效的DNS服务器？
您可以在域名管理区的操作平台页面的右边区域，来检查DNS是否设置正确。
如果您要修改域名的DNS需要到注册商的域名管理界面操作。

五、已经在注册商修改了DNS，为什么DNS检查的还是旧的DNS？

我们的DNS检查是根据DNS的根服务器的当前数据为依据的，在注册商修改DNS可能需要12-72小时才能反映在根服务器上。

六、解析可以生效，为什么收不到邮件？

请检查您的MX记录是否设置正确；
请检查您的邮局服务器是否设置正确。
如果您没有自己的邮件服务器，可以使用别人的邮件转发。

七、设置了MX（MailExchanger）记录，为什么无效？

大多数SMTP要求MX记录指向一个主机名。因此请将MX记录指定到一个主机名，而不是IP地址。
举例，要让218.5.1.249做为xiaoh.net的邮件服务器可以这样设置:
1、将mail.xiaoh.net解析到218.5.1.249 (“主机名”栏填“mail”，“类型”选择“A”，“IP地址/主机名”栏填“218.5.1.249”，然后按“增加”)
2、xiaoh.net的MX记录设置为mail (“主机名”栏保留为空，“类型”选择“MX”，“IP地址/主机名”栏填“mail”，然后按“增加”)
3、在218.5.1.249上进行设置，允许接收@xiaoh.net的邮件

如果您在上述第二步中的“主机名”栏中填写了“mail”，则表示发到@mail.xiaoh.net的邮件由218.5.1.249接收，这可能不符合你的本意思

八、为什么有的主机名用“.”结尾，而有的没有？这有什么不同吗？

以“.”结尾的主机名表示主机名的全称(FQDN)；而不是用“.”结尾的主机名表示在该域名下的主机名。 举例:
1、在xiaoh.net域下加了个CNAME类型的记录“abc”指到“123”，那么abc.xiaoh.net表示123.xiaoh.net的解析。
2、在xiaoh.net域下加了个CNAME类型的记录“abc”指到“hj123.net.”，那么abc.xiaoh.net表示用hj123.net的解析。

九、为什么“优先级”设置总是为“0”？

“优先级”仅对MX记录有效，其他类型的记录将忽略优先级。

十、什么叫泛解析？

泛域名在实际使用中作用是非常广泛的，比如实现无限二级域名功能，提供免费的url转发，在IDC部门实现自动分配免费网址，在大型企业中实现网址分类管理等等，都发挥了巨大的作用。请在“主机名”栏中填“*”。

十一、DNS修改和域名解析有什么不同吗?

DNS修改和域名解析的含义完全不同：
1、 DNS修改是指域名解析服务器(Domain Name System)的修改。
如果您自己有独立DNS服务器，想通过此DNS解析己注册成功的域名，您可选择DNS修改业务（注：要改DNS的域名必须是在注册商注册或己成功转入至注册商的域名）。请您登陆域名管理区－点击相应域名－DNS修改处修改您的域名DNS信息
2、域名解析：域名与IP地址之间是一一对应的，它们之间的转换工作称为域名解析，域名解析需要由专门的域名解析服务器(DNS)来完成。

十二、英文域名修改DNS是否收费？

国际英文域名、国内英文域名可以修改DNS，这项服务是免费的。

十三、URL转发隐藏路径和不隐藏路径有何区别?

不隐藏路径URL转发：例如：http://b.com/指向http://a.com/xxx/（任意目录）；在浏览器地址栏中打入http://b.com/连接后地址栏会显示真正的地址http://a.com/xxx/
隐藏路径的URL转发：例如：http://b.com/指向http://a.com/xxx/(任意目录)；在浏览器地址栏中打入http://b.com/连接后地址栏显示的还是http://b.com/,但实际指向的是http://a.com/xxx/的内容 。
 
欢迎分享本文（http://blog.sina.com.cn/mumuhouzi）给你的朋友，特别是给那些在做人脉，玩社群，玩圈子的朋友，关注互联网和网络营销的朋友多多交流，QQ&微信：809472503。
 
公众号：mumuseo，有更多网络营销干货，网络推广策略，引流技巧，成功案例故事等诸多优质内容，提升自己的专业能力！如果你想和我扯扯，欢迎关注。公众号回复“SEO核心技术”可免费获取《这就是搜索引擎 SEO核心技术详解》完整版！　
** TODO #<<my-anchor-baiduspider-crawl>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dlwv.html][百度蜘蛛抓取]]
标签： 百度蜘蛛抓取 抓取 蜘蛛抓取 搜索引擎蜘蛛抓取	分类： 搜索引擎秘籍
　　网络蜘蛛也就是搜索引擎蜘蛛，是通过链接地址来寻找网页的。搜索引擎蜘蛛名称根据搜索引擎都不同。那它的原理是由一个启始链接开始抓取网页内容，同时也采集网页上的链接，并将这些链接作为它下一步抓取的链接地址，如此循环，直到达到某个停止条件后才会停止。同时页面信息的重要性为客观因素决定了蜘蛛对该网站页面的检索。
 
　　[[my-anchor-search-engine][搜索引擎]]蜘蛛与网站的交互问题

　　搜索引擎技术基础中，蜘蛛爬取到网站中，通常会去检索一个文本文件Robots.txt，通常存放在网站的根目录下。它是专门用来同网络蜘蛛交互用的专用文件。这也就是SEOer老是去屏蔽网站页面不想被搜索引擎抓取的原因，它是一个网站和搜索引擎蜘蛛对话的重要工具，但是蜘蛛是否都遵循站长对其实施的规则呢?其实蜘蛛遵循还是得看蜘蛛出身，素质高的会遵循规则，相反则不遵循。另外在网站中放入一个叫做sitmap.htm的网页，并将它作为网站的入口文件，这也是蜘蛛与网站的交互方法。
 
　　页面Meta字段也是站长经常使用的搜索引擎优化技术，这个字段通常会放在文档的头部，很多站点都只是简单的写个允许百度抓取的字段，正不正确笔者不清楚，SEO其实很多现象都是基于数据分析对比才能得知。Meta字段蜘蛛可以在没有读取到全部文档的情况下就了解文档的相关信息，可以避免将无效的网页取下来后又将其废弃而造成无谓的浪费。

　　搜索引擎蜘蛛对于文件的处理

　　(一)二进制文件处理

　　网络中除了HTML文件和XML文件外，也有大量的二进制文件，搜索引擎对二进制文件采用单独处理的方式，其对内容的理解完全需要依靠二进制文件的锚点描述来完成。锚点描述通常代表了文件的标题或是基本内容，也就是通常所说的锚文字这就是为什么我们要对网站锚文字的分析选择的原因所在。

　　(二)脚本文件的处理

　　网页中的客户端脚本，当网页加载至读取到该脚本，搜索引擎往往会直接省略对它的处理。但是由于现在网站设计者对于无刷新页面要求的提高和对ajax技术的大量使用，对它的分析处理往往会采用另外一种网页检索程序，由于脚本程序复杂和多样性，通常站长会根据自身网站将这些脚本存放到一个文档中，采用调用技术，从而加快页面加载速度，同时蜘蛛也不能对调用文件分析处理。这也属于搜索引擎优化技术，如果忽略了对它的处理将会是一项巨大的损失。

　　(三)不同文件类型处理

　　对于网页内容的提取分析一直是网络蜘蛛的重要技术环节，这也是SEO需要去了解的搜索引擎技术，这取决于网站信息更新的多样性。这也就是为什么专业网站上会在网站内附有下载的execl，pdf等各种文件类型，这也是属于搜索引擎优化过程中需要注意的。网上不同文件类型文件的处理，网络蜘蛛通常是采用插件的方式来处理。如果有能力，网站信息内容的更新尽可能采取多样性，来帮助网站达到一个搜索信息多样化的SEO体系。
 
　　四搜索引擎蜘蛛的策略分析

　　(一)搜索策略　　
 
　　搜索策略一般有深度优先的搜索策略和广度优先的搜索策略两种。

　　广度优先的搜索策略一般被认为是盲目的搜索。它是一种以搜索更多的网页为优先的一种贪婪的搜索策略。只要有东西检索，它就抓取。它会先读取一个文档，保存下文档上的所有链接，然后读取所有这些链接文档，并依次进行下去。

　　深度优先的搜索策略网络蜘蛛程序分析一个文档，并取出它的第一个链接所指的文档继续分析，然后如此继续下去。这样的搜索策略达到了网站结构的分析，以及页面链接深度分析，从而传达网站信息。

　　还有网络上说的算法，如Hash算法，遗传算法等都是基于搜索引擎核心技术，这些也可以去了解下，比如最新的熊猫算法，这也是基于搜索策略的一种新算法，谷歌对其已经更新好几次了。

　　(二)更新策略

　　以网页变化的周期为依据，广州婚礼策划公司，只对那些经常变化的网页做更新操作也是一些小型的搜索引擎常采用的方法。这也就是为什么站长会每个几周对网站页面内容的一个小更新，这是基于搜索引擎优化的技术。网络爬虫也经常采用个体更新的策略。它是以个别网页的变化频率来决定对网页的更新频率，这样一来基本上每个网页都会有一个独立的更新频率。
     简单谈谈搜索引擎爬行和抓取http://blog.sina.com.cn/s/blog_c206a2c30101ddkj.html。
　　如果你觉得这篇文章有价值，可以分享给你的朋友，如果你觉得没有价值，没有关系，请给以指导，这是一次改变的机会。
** TODO #<<my-anchor-search-engine>> [[http://blog.sina.com.cn/s/blog_c206a2c30101efif.html][不懂搜索引擎原理就是在裸奔]]
做网站优化，不懂搜索引擎原理就是在裸奔，只有了解了搜索引擎工作原理，我们才能更好的去针对搜索引擎做出相关优化工作。搜索引擎(search engine)是指根据一定的策略、运用特定的计算机程序从互联网上搜集信息，在对信息进行组织和处理后，为用户提供检索服务，将用户检索相关的信息展示给用户的系统。搜索引擎包括全文索引、目录索引、元搜索引擎、垂直搜索引擎、集合式搜索引擎、门户搜索引擎与免费链接列表等。百度和谷歌等是搜索引擎的代表。
 
　　搜索引擎的“三板斧”：数据搜集—>预处理【索引】—>排名。如下图
 
 
☞ <wbr>不懂搜索引擎原理就是在裸奔

 
　　数据搜集
 
　　即数据的搜集阶段，将网页从浩如瀚海的互联网世界搜集到自己的数据库中进行存储。搜索引擎派出一个能够在网上发现新网页并抓文件的程序，这个程序通常称之为蜘蛛(Spider)。搜索引擎从已知的数据库出发，就像正常用户的浏览器一样访问这些网页并抓取文件。搜索引擎通过这些爬虫去爬互联网上的外链，从这个网站爬到另一个网站，去跟踪网页中的链接，访问更多的网页，这个过程就叫爬行。这些新的网址会被存入数据库等待抓取。所以跟踪网页链接是搜索引擎蜘蛛(Spider)发现新网址的最基本的方法。搜索引擎抓取的页面文件与用户浏览器得到的完全一样，抓取的文件存入数据库。
 
　　1、搜索引擎抓取系统
 
　　Spider抓取系统是搜索引擎数据来源的重要保证，如果把web理解为一个有向图，那么spider的工作过程可以认为是对这个有向图的遍历。从一些重要的种子URL开始，通过页面上的超链接关系，不断的发现新URL并抓取，尽最大可能抓取到更多的有价值网页。对于类似百度这样的大型spider系统，因为每时每刻都存在网页被修改、删除或出现新的超链接的可能，因此，还要对spider过去抓取过的页面保持更新，维护一个URL库和页面库。
 
　　（1）spider抓取系统的基本框架
 
　　如下为spider抓取系统的基本框架图，其中包括链接存储系统、链接选取系统、dns解析服务系统、抓取调度系统、网页分析系统、链接提取系统、链接分析系统、网页存储系统。
　　
d}_dbS|~i
 
　　（2）spider抓取过程中涉及的网络协议
 
　　搜索引擎与资源提供者之间存在相互依赖的关系，其中搜索引擎需要站长为其提供资源，否则搜索引擎就无法满足用户检索需求;而站长需要通过搜索引擎将自己的内容推广出去获取更多的受众。spider抓取系统直接涉及互联网资源提供者的利益，为了使搜素引擎与站长能够达到双赢，在抓取过程中双方必须遵守一定的规范，以便于双方的数据处理及对接。这种过程中遵守的规范也就是日常中我们所说的一些网络协议。以下简单列举：
 
　　http协议：超文本传输协议，是互联网上应用最为广泛的一种网络协议，客户端和服务器端请求和应答的标准。客户端一般情况是指终端用户，服务器端即指网站。终端用户通过浏览器、蜘蛛等向服务器指定端口发送http请求。发送http请求会返回对应的httpheader信息，可以看到包括是否成功、服务器类型、网页最近更新时间等内容。
 
　　https协议：实际是加密版http，一种更加安全的数据传输协议。
 
　　UA属性：UA即user-agent，是http协议中的一个属性，代表了终端的身份，向服务器端表明我是谁来干嘛，进而服务器端可以根据不同的身份来做出不同的反馈结果。
 
　　robots协议：robots.txt是搜索引擎访问一个网站时要访问的第一个文件，用以来确定哪些是被允许抓取的哪些是被禁止抓取的。robots.txt必须放在网站根目录下，且文件名要小写。百度严格按照robots协议执行，另外，同样支持网页内容中添加的名为robots的meta标签，index、follow、nofollow等指令。
 
　　（3）spider抓取的基本过程
 
　　spider的基本抓取过程可以理解为如下的流程图：
　　
d}_dbS|~i
 
　　（4）Baiduspider 主要抓取策略类型
 
　　上图看似简单，但其实Baiduspider在抓取过程中面对的是一个超级复杂的网络环境，为了使系统可以抓取到尽可能多的有价值资源并保持系统及实际环境中页面的一致性同时不给网站体验造成压力，会设计多种复杂的抓取策略。以下做简单介绍：
 
　　抓取友好性
 
　　互联网资源庞大的数量级，这就要求抓取系统尽可能的高效利用带宽，在有限的硬件和带宽资源下尽可能多的抓取到有价值资源。这就造成了另一个问题，耗费被抓网站的带宽造成访问压力，如果程度过大将直接影响被抓网站的正常用户访问行为。因此，在抓取过程中就要进行一定的抓取压力控制，达到既不影响网站的正常用户访问又能尽量多的抓取到有价值资源的目的。
 
　　通常情况下，最基本的是基于ip的压力控制。这是因为如果基于域名，可能存在一个域名对多个ip(很多大网站)或多个域名对应同一个ip(小网站共享ip)的问题。实际中，往往根据ip及域名的多种条件进行压力调配控制。同时，站长平台也推出了压力反馈工具，站长可以人工调配对自己网站的抓取压力，这时百度spider将优先按照站长的要求进行抓取压力控制。
 
　　对同一个站点的抓取速度控制一般分为两类：其一，一段时间内的抓取频率；其二，一段时间内的抓取流量。同一站点不同的时间抓取速度也会不同，例如夜深人静月黑风高时候抓取的可能就会快一些，也视具体站点类型而定，主要思想是错开正常用户访问高峰，不断的调整。对于不同站点，也需要不同的抓取速度。
 
　　常用抓取返回码示意
 
　　简单介绍几种百度支持的返回码：
 
　　1)最常见的404代表“NOT FOUND”，认为网页已经失效，通常将在库中删除，同时短期内如果spider再次发现这条url也不会抓取；
 
　　2)503代表“Service Unavailable”，认为网页临时不可访问，通常网站临时关闭，带宽有限等会产生这种情况。对于网页返回503状态码，百度spider不会把这条url直接删除，同时短期内将会反复访问几次，如果网页已恢复，则正常抓取;如果继续返回503，那么这条url仍会被认为是失效链接，从库中删除。
 
　　3)403代表“Forbidden”，认为网页目前禁止访问。如果是新url，spider暂时不抓取，短期内同样会反复访问几次;如果是已收录url，不会直接删除，短期内同样反复访问几次。如果网页正常访问，则正常抓取;如果仍然禁止访问，那么这条url也会被认为是失效链接，从库中删除。
 
　　4)301代表是“Moved Permanently”，认为网页重定向至新url。当遇到站点迁移、域名更换、站点改版的情况时，我们推荐使用301返回码，同时使用站长平台网站改版工具，以减少改版对网站流量造成的损失。
 
　　多种url重定向的识别
 
　　互联网中一部分网页因为各种各样的原因存在url重定向状态，为了对这部分资源正常抓取，就要求spider对url重定向进行识别判断，同时防止作弊行为。重定向可分为三类：http 30x重定向、meta refresh重定向和js重定向。另外，百度也支持Canonical标签，在效果上可以认为也是一种间接的重定向。
 
　　抓取优先级调配
 
　　由于互联网资源规模的巨大以及迅速的变化，对于搜索引擎来说全部抓取到并合理的更新保持一致性几乎是不可能的事情，因此这就要求抓取系统设计一套合理的抓取优先级调配策略。主要包括：深度优先遍历策略、宽度优先遍历策略、pr优先策略、反链策略、社会化分享指导策略等等。每个策略各有优劣，在实际情况中往往是多种策略结合使用以达到最优的抓取效果。
 
　　重复url的过滤
 
　　spider在抓取过程中需要判断一个页面是否已经抓取过了，如果还没有抓取再进行抓取网页的行为并放在已抓取网址集合中。判断是否已经抓取其中涉及到最核心的是快速查找并对比，同时涉及到url归一化识别，例如一个url中包含大量无效参数而实际是同一个页面，这将视为同一个url来对待。
 
　　暗网数据的获取
 
　　互联网中存在着大量的搜索引擎暂时无法抓取到的数据，被称为暗网数据。一方面，很多网站的大量数据是存在于网络数据库中，spider难以采用抓取网页的方式获得完整内容;另一方面，由于网络环境、网站本身不符合规范、孤岛等等问题，也会造成搜索引擎无法抓取。目前来说，对于暗网数据的获取主要思路仍然是通过开放平台采用数据提交的方式来解决，例如“百度站长平台”“百度开放平台”等等。
 
　　抓取反作弊
 
　　spider在抓取过程中往往会遇到所谓抓取黑洞或者面临大量低质量页面的困扰，这就要求抓取系统中同样需要设计一套完善的抓取反作弊系统。例如分析url特征、分析页面大小及内容、分析站点规模对应抓取规模等等。
 
　　2、链接跟踪
 
　　蜘蛛是顺着链接爬行和抓取页面的。如何快速抓取到对用户来说相对重要的信息以及达到广阔的覆盖无疑是搜索引擎需要重点考虑的问题。由于互联网上无数的网站页面，搜索引擎蜘蛛无法将所有的页面都下载保存到服务器。因此，许多搜索引擎的网络蜘蛛不是所有的页面都抓取的，只是抓取那些重要的网页，而在抓取的时候评价重要性主要的依据是某个网页的链接广泛度及外部链接的数量与质量。所以在给网站加外链时不要只给首页外链，其他页面也要加(这和外链的随机性也有关)。
 
　　在抓取网页的时候，搜索引擎蜘蛛一般有两种策略：广度优先和深度优先。
 
　　广度优先是指搜索引擎蜘蛛会先抓取起始网页中链接的所有网页，然后再选择其中的一个链接网页，继续抓取在此网页中链接的所有网页。这是最常用的方式，因为这个方法可以让搜索引擎蜘蛛并行处理，提高其抓取速度。


☞ <wbr>不懂搜索引擎原理就是在裸奔

　　深度优先是指搜索引擎蜘蛛会从起始页开始，一个链接一个链接跟踪下去，处理完这条线路之后再转入下一个起始页，继续跟踪链接。这个方法有个优点是搜索引擎蜘蛛在设计的时候比较容易。
☞ <wbr>不懂搜索引擎原理就是在裸奔
　　广度抓取有助于获取到更多的信息，深度抓取有助于得到更全面的信息。搜索引擎蜘蛛在抓取数据时，通常会两种方式都采用，但是想比较来说，广度抓取要多于深度抓取。
 
　　当然这是搜索引擎抓取数据的二大策略，当然其中还夹杂着一些加入了人工智能的策略，比如：
 
　　a、热点优先策略：对于爆发式的热点关键词进行优先抓取，而且不需要经过严格的去重和过滤，因为会有新的链接来覆盖以及用户的主动选择。
 
　　b、权威优先策略：搜索引擎会给每个网站分配一个权威度，通过网站历史、网站更新等来确定网站的权威度，优先抓取权威度高的网站链接。
 
　　c、用户点击策略：当大部分搜索一个行业词库内的关键词时，频繁的点击同一个网站的搜索结果，那么搜索引擎会更频繁的抓取这个网站。
 
　　d、历史参考策略：对于保持频繁更新的网站，搜索引擎会对网站建立更新历史，根据更新历史来预估未来的更新量以及确定抓取频率。
 
　　3、地址库
 
　　为了避免重复爬行和抓取网址，搜索引擎会建立一个地址库，记录已经被发现还没有抓取的页面，以及已经被抓取的页面。地址库中的 URL 有几个来源。
 
　　1. 一是人工录入的种子网站。
 
　　2. 二是蜘蛛抓取页面后，从 HTML 中解析出新的链接 URL，与地址库中的数据对比，如果是地址库中没有的网址，就存入待访问地址库。
 
　　3. 三是站长通过搜索引擎网页提交表格提交进来的网址。
 
　　蜘蛛按重要性从待访问地址库中提取 URL，访问并抓取页面，然后把这个 URL 从待访问地址库中删除，放进已访问地址库中。大部分主流搜索引擎都提供一个表格，让站长提交网址。不过这些提交来的网址都只是存入地址库而已，是否收录还要看页面重要性如何。搜索引擎所收录的绝大部分页面是蜘蛛自己跟踪链接得到的。可以说提交页面基本上是毫无用处的，搜索引擎更喜欢自己沿着链接发现新页面。
 
　　4、文件存储
 
　　链接跟踪完毕，需要将跟踪到的信息进行存储。存储的对象，第一是url，第二是页面内容(文件大小、最后一次更新时间、http状态码、页面源代码等等)。
————————————————————————————————————————
 
　　预处理【索引】
 
　　数据抓取完毕，就需要进行预处理了，一般也叫索引。主要会从提取文字、中文分词、去停止词、消噪、去重、正向索引、倒排索引、链接分析、特殊文件处理等几个方面来进行。
☞ <wbr>不懂搜索引擎原理就是在裸奔

 
　　1、提取文字
 
　　很好理解的一部，将源代码中的文字提取出来。当然需要注意的是，这里面会包括meta信息以及一些替代文字，除了用户可见的文字信息外，还有代码中的文字信息(例如alt标签)。目前搜索引擎都是以文字为基础。蜘蛛抓取的HTML代码中除了用户在浏览器看到的文字外还有大量HTML格式标签、DIV+CSS标签、JavaScript程序等无法用于排名的内容。所以搜索引擎第一步就是要去除从HTML代码中抓取的标签、程序等，提取可以用于排名处理的页面文字内容。除了可见文字，搜索引擎也会提取一些特殊的包含文字信息的代码，如Meta标签中的文字、alt标签、FLASH文件代替的文字、链接的锚文本等等。
 
　　2、分词
 
　　中文分词 (Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂的多、困难的多。分词方法主要包括：基于理解的分词方法、基于字符串匹配的分词方法、基于统计的分词方法。这里就不多说了，分词是个难啃的骨头，如果感兴趣可以看一下《百度分词》。
 
百度分词
 
　　3、去停止词
 
　　无论英文还是中文，页面内容中都会有一些出现频率很高，却对内容没有任何影响的词，如“的”、“地”、“得”之类的助词，“啊”、“哈”、“呀”之类的感叹词，“从而”、“以”、“却”之类的介词，这些词被称为停止词，因为它们对页面主要意思没有什么影响。英文中常见的停止词如the，a，an，to，of等。搜索引擎在索引页面之前会去掉这些停止词，使索引数据主题更为突出，减少无谓的计算量。
 
　　4、消噪
 
　　对搜索引擎来说，并不是网页上的所有部分它都需要抓取，有一些部分对排名计算是没有意义的，比如导航条、版权文字说明、广告等等区块。考虑到搜索引擎需要处理的网页数量非常庞大，这部分无意义内容的绝对量也是非常大的，为了节省计算资源，提升排名计算的速度，搜索引擎在预处理时会将这些内容识别后剔除出去。这个过程就称为消噪。
 
　　现在搜索引擎应用的消噪技术可分为三类：基于网页结构的方法，基于模版的方法和基于可视化信息的方法。
 
　　A、基于可视化信息的方法。是指利用页面中元素的布局信息，从而能够利用布局信息对页面进行划分，保留页面中间区域，而其它区域则认为是噪音。
 
　　B、基于网页结构的方法。即根据html标签对页面来分区，分出一些页头、导航、正文、广告等等的区块，只抓取正文等重要的部分。
 
　　C、基本模版的方法。指的是从一组网页中提取出相同的模板，而后利用这些模版从网页中抽取有用的信息。
 
　　如何人工减噪？
 
　　A、搜索引擎会基于可视化信息识别噪音，因此SEO人员在建设网页时应尽量遵循通用的原则，将正文内容安排在页面中间区域，而不要弄一些非常个性化的页面，增加搜索引擎识别噪音的难度。
 
　　B、搜索引擎会基于网页结构识别噪音，因此SEO人员在处理网页结构时建议引入JS代码，将页头、广告、版权声明等内容通过JS调用来实现。当然是一些你不想被抓取的版块，因为这些区块在站内很可能都是重复出现的，特别是广告、版权、评论这些。一旦被收录，很容易造成重复内容堆积，影响整站的内容质量评分。
 
　　C、搜索引擎会基于网页模版识别噪音，因此SEO人员在建设网页时应尽量采用同一套模版，尤其是在改版的时候不要轻易动模版，以帮助搜索引擎识别噪音区块。
 
　　5、去重
 
　　经过去停顿，去噪之后剩下的词组，已经可以很好的表达出页面的主体意思了。为了便于使得内容不被搜索引擎重复收录，搜索引擎需要一个算法来进行去重处理。比如比较知名且常用的为MD5算法，搜索引擎根据特征关键词计算指纹区分。《搜索引擎判断原创的指纹算法》
 
　　6、正向索引
 
　　正向索引简称为索引。经过前五步之后，接下来搜索引擎将提取文中关键词，按分词程序划分好的词，同时记录每个词在页面中出现的频率、出现的次数、格式(如加粗、倾斜、黑体、H标签、加颜色、锚文字等)、位置(如页面第一段文字或者最后一段等)。然后把这些词语记录为串关键词集合，那么这些词的相关信息如格式、权重等也会记录在案。实际在搜索引擎中每个关键词也被转换为ID形式记录，然后每个文件ID对应一串关键词ID。这种每个文件ID对应一个串关键词ID这样的数据结构被称之为正向索引。比如文章A对应1、2、3这三个关键词，文章B对应2、4、5这三个关键词。

☞ <wbr>不懂搜索引擎原理就是在裸奔
 
　　7、倒排索引
 
　　正向索引还不能直接运用到关键词排名，假设用户搜索关键词2，那么搜索引擎讲扫描索引库中所有文件，这样时间太长无法满足用户返回结果的速度，所以这里运用到了倒排索引，把关键词ID映射到文章ID，比如关键词2对应文章A、文章B，如此一来大大缩短搜索引擎扫描索引库中的文件，缩短扫描时间。
 
　　8、链接算法
 
　　在此阶段，各个页面之间的链接关系也会被搜集。页面中有哪些导入链接，这些链接都指向哪里，哪些链接又指向这个页面，链接用的是URL还是锚文字，这些复杂的链接关系网就形成了页面的链接权重，此时锚文本将被作为重要排名依据，当量广泛的锚文本将被列入计算关键词排名的步骤中。
 
　　9、特殊文件的处理
 
　　除了HTML 文件外，搜索引擎通常还能抓取和索引以文字为基础的多种文件类型，如 PDF、Word、WPS、XLS、PPT、TXT 文件等。我们在搜索结果中也经常会看到这些文件类型。但搜索引擎还不能处理图片、视频、Flash 这类非文字内容，也不能执行脚本和程序。
————————————————————————————————————————
 
　　排名　
 
　　索引文件建立完毕之后，就来排名了。排名也从几个方面进行的：
 
　　1、搜索词的处理。
 
       这一步和前面的预处理一样也要中文分词、去停止词。还要进行指令处理，拼写错误矫正，整合搜索触发等。这个上面基本是一样的。
 
　　2、文件匹配。
 
　　从上面我们看那到搜索引擎的蜘蛛是无时无刻的都在爬行和抓取，另外不断对抓取的数据进行整理归纳以及存储。这些过程并不是用户在搜索的时候进行的，而是在搜索之前就预处理好的，真正当用户搜索某个关键词时，搜索引擎只需要在自己的数据库中进行查找，而不是实时的对互联网上所有的网站进行查找。搜索引擎就会在和该关键词对应的所有文件中进行简单的计算和匹配，找到匹配页面。
 
　　3、初始子集选择。
 
　　为了更加快速的满足用户的需要，搜索引擎需要从所有的相关页面中进行选择，只计算权重稍高的页面返回给用户，这个过程就是常说的初始子集的筛选。大家可以试想，当我们搜索某个关键词时，往往包含这个关键词的页面数量是巨大的，甚至几十万、上百万。如果搜索引擎从这么大的数据中进行匹配的话时间显然更长，为了更好的满足用户的需求，实际中搜索引擎只会选择哪些权重高的页面去匹配(1000个左右)。
 
　　4、相关性计算。
 
　　(1)关键词常用程度。经过分词后的多个关键词，对整个搜索字符串的意义贡献并不相同。越常用的词对搜索词的意义贡献越小，越不常用的词对搜索词的意义贡献越大。举个例子，假设用户输入的搜索词是“我们冥王星”。“我们”这个词常用程度非常高，在很多页面上会出现。它对“我们冥王星”这个搜索词的辨识程度和意义相关度贡献就很小。
 
　　找出那些包含“我们”这个词的页面，对搜索排名相关性几乎没有什么影响，有太多页面包含“我们”这个词。而“冥王星”这个词常用程度就比较低，对“我们冥王星”这个搜索词的意义贡献要大得多。那些包含“冥王星”这个词的页面，对“我们冥王星”这个搜索词会更为相关。
 
　　常用词的极致就是停止词，对页面意义完全没有影响。所以搜索引擎对搜索词串中的关键词并不是一视同仁地处理，而是根据常用程度进行加权。不常用的词加权系数高，常用词加权系数低，排名算法对不常用的词给予更多关注。我们假设A、B两个页面都各出现“我们”及“冥王星”两个词。但是“我们”这个词在A页面出现于普通文字中，“冥王星”这个词在A页面出现于标题标签中。B页面正相反，“我们”出现在标题标签中，而“冥王星”出现在普通文字中。那么针对“我们冥王星”这个搜索词，A页面将更相关。
 
　　(2)词频及密度。一般认为在没有关键词堆积的情况下，搜索词在页面中出现的次数多，密度越高，说明页面与搜索词越相关。当然这只是一个大致规律，实际情况未必如此，所以相关性计算还有其他因素。出现频率及密度只是因素的一部分，而且重要程度越来越低。
 
　　(3)关键词位置及形式。就像在索引部分中提到的，页面关键词出现的格式和位置都被记录在索引库中。关键词出现在比较重要的位置，如标题标签、黑体、H1等，说明页面与关键词越相关。这一部分就是页面seo所要解决的。
 
　　(4)关键词距离。切分后的关键词完整匹配地出现，说明与搜索词最相关。比如搜索“呼叫中心”时，页面上连续完整出现“呼叫中心”四个字是最相关的。如果“呼叫”和“中心”两个词没有连续匹配出现，出现的距离近一些，也被搜索引擎认为相关性稍微大一些。
 
　　(5)链接分析及页面权重。除了页面本身的因素，页面之间的链接和权重关系也影响关键词的相关性。其中最重要的是锚文字。页面有越多以拽索词为锚文字的导入链接，说明页面的相关性越强。链接分析还包括了链接源页面本身的主题、锚文字周围的文字等。
 
　　5、排名过滤及调整，过滤一些作弊等。
 
　　6、排名显示。
 
　　7、搜索缓存。
 
　　搜索引擎的缓存也即cache，是计算机领域非常常用的一种技术，我们最熟悉的，恐怕就是浏览器的缓存。搜索引擎的缓存可以这样简单描述：在高速内存硬件设备开辟一块数据存储区，用来存储搜索用户的查询、索引数据、搜索的中间结果或者最终的搜索结果。缓存的大小是有限度的，不可能无限存储数据。因此搜索引擎会采取缓存更新策略和缓存淘汰策略管理维护缓存区存储的数据。搜索引擎缓存的价值搜索引擎缓存具有两个价值：一、加快响应搜索用户查询的速度，提高搜索用户体验;二、减少搜索引擎后台的计算量，节省计算资源。
 
　　8、查询及点击日志。
 
　　对搜索用户的搜索做统计，并根据该用户搜索习惯给出相应结果。
————————————————————————————————————————
　　根据下面一张图，再细细回顾一下：
 
☞ <wbr>不懂搜索引擎原理就是在裸奔
 
　　木木博客（http://blog.sina.com.cn/mumuhouzi），
关注互联网营销，注重网络推广策略、营销引流技巧及思路！如果你觉得这篇文章有价值，请分享给你的朋友！如果你有不同的看法也可以和我交流。
 
　　公众号：mumuseo，有更多网络营销干货，网络推广策略，引流技巧，成功案例故事等诸多优质内容，提升自己的专业能力！如果你想和我扯扯，欢迎关注。公众号回复“SEO核心技术”可免费获取《这就是搜索引擎 SEO核心技术详解》完整版！　　
** DONE [[http://blog.sina.com.cn/s/blog_c206a2c30101e7nk.html][图文并茂带你走进电商转化率]]
     CLOSED: [2015-11-22 Sun 18:28]
     - State "DONE"       from ""           [2015-11-22 Sun 18:28]
*** 电商行业转换率公式
　　电商领域，只要追求利润，那么都可以用一些公式去进行分解。
[[file:./tomsinsight-hack/转化率公式.png][转化率公式]]
　　针对这个公式，我们坚持列出来源和各个转换率，然后去判断每一个步骤的转化和数据是否在正常范围，这样就很容易找到病根。然后针对有问题的转化率去着手。
*** 转化率是追求的重点
　　上面我们看到，无论是流量引导还是在购买，都存在各种转化率。每个转化率高，利润很明显就会高。
　　所以这些都是一条链上的信息。有一环出问题都会不正常，比如点击率很高的时候，那必然导致到达页面的转化率降低。但是你要注意，不能单独通过一个转化率低说明什么，比如上面说的点击率很高，到达页面转化率却从5%降到1%。但是点击却很高即流量引导做得很好，从500次访问做到5000.那么转化率低的那个还是占优势，所以不能从一个点去看整体。只能去做好每一个转化率环节，这样才能做得更好。各个环节转化更高，才有真正的意义。通过一些手段获得暂时的大流量或其他展现都是短暂性的，只有稳定的转化率才是发展之道，这就像竞价与seo的关系。
*** 转化率必须分清谁转化到谁
[[file:./tomsinsight-hack/淘宝的典型转化路径.png][淘宝的典型转化路径.png]]
　　上图是淘宝典型的集中转化率，每天到淘宝有几千万人，其中购买了几百万单，所以全站的购买转化率在5%-10%吧。同时呢，淘宝运营看的是从各自搜索和类目页、活动页面进入之后产生的购买，“购买UV / 进入类目和活动的UV”就是类目和活动的购买转化率。
　　所以，一定要分清是什么转化率，不是同样路径的转化率，对比没有意义。　　
*** 对转化率的分解，决定运营方向
[[file:./tomsinsight-hack/蘑菇街的转化路径.png][蘑菇街的转化路径.png]]
　　用户从各种渠道进入首页或者推广页，进入图墙，这是第一步转化，基本是100%都会进瀑布流。
　　然后用户看到很多分享的商品，翻着翻着，看到自己喜欢的点进去，进入详情页面，这是第二步转化。
　　进入详情页面，判断信息觉得确实不错，点击“购买”，跳入淘宝，这就是第三步转化。
　　到淘宝之后，购买，这有第四步转化，到淘宝后的购买转化率。
　　所以，整站的购买转化率就很容易算，四个转化率相乘就行了。
　　现在，我们把“整站转化率”的任务分解掉，去想办法提高所有环节的转化率。下面是图例：
[[file:./tomsinsight-hack/蘑菇街转化率分解任务.jpg][蘑菇街转化率分解任务.jpg]]
   分解转化率，很容易找到努力的方向。每一个转化率一目了然，这样各个击破就是该做的运营。
*** 佣金的计算和分解
[[file:./tomsinsight-hack/佣金收入的计算方法.jpg][佣金收入的计算方法.jpg]]
　　佣金收入的公式拆分到“到站UV、整站转化率、支持分成的比例、客单价、平均佣金比例”这5个数字时，我们发现，每个数字都可以计算。如果要追求佣金更多，那运营和营销方向分解就变得很容易。
　　到站UV必须变大。这是整个公式里弹性最大的部分，其他的变化范围都有限。换句话说，UV提高一倍，收入就翻番。这个相信大家都是很清楚的。
　　整站转化率是运营核心。上面就大篇幅详述过，这里不说了。
　　支持分成的比例和定位有关。如果蘑菇街是一个纯淘宝客网站，那完全可以做成100%，但我们不是，我们解决的是“用户买什么”的问题，所以我们必须保持“不功利”，那这个比例不大会变。
　　客单价可以提高。提升的办法，比如提高品质感，比如想办法扩展人群和品类……

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE [[http://blog.sina.com.cn/s/blog_c206a2c30101dmpx.html][网站标题，走起！]]
     CLOSED: [2015-11-22 Sun 18:29]
     - State "DONE"       from ""           [2015-11-22 Sun 18:29]
　　[[my-anchor-baidu-search-engine][搜索引擎]]会通过各种链接渠道来抓取最新更新的网页,最先开始读取的就是网页的标题,此时,搜索引擎会根据这个网页标题来判断网页的大概内容以及将这个网页的标题进行拆分,给予相关的分类。然后,搜索引擎就会对网页的内容进行读取,根据内容与标题的匹配程度来判断网页内容是否具有一定的质量。最后,搜索引擎会根据网站的整体权重以及这个网页的外部引用情况,再把Title中的标题进行相关的拆分之后,给予相应的排名。

　　Title在搜索引擎中的真正意义:

　　不论是百度搜索引擎,还是谷歌搜索引擎,在所有影响网站排名的因素中,Title都是至关重要的,而且对排名的影响成分占所有因素一般都会有10%到20%以上。

*** 一、网站标题涵有关键词

　　标题中涵有关键词,并不一定是要把所有的关键词都放在上面,这样不仅对网站优化有影响,还影响用户体验。要选择和企业业务相关的关键词,放在标题的前面,让用户在搜索信息的时候,就能找到网站,增加网站的曝光率。网站标题是搜索引擎最先收录的,所以说网站标题对合肥网站优化有着重要意义，标题中关键词越是靠前那么搜索引擎赋予的权重也就会越高一些，所以对一个标题组合的时候，把重要的关键词能够往前面靠。

*** 二、网站标题涵盖网页内容

　　标题是最先被搜索引擎看到的,它很重视网站标题,这一点写好的话,对于网站优化来说,意义深远。标题不仅要含有关键词,还要用简短的语言概括网页的内容,让用户从几个简单的字就能看出网站主要做什么。标题要控制长度,太长的标题不容易被搜索引擎收录,既要把网站的意思说明白,也要适合搜索引擎优化原则。

　　网页标题和一本书的书名一样,是整本书所讲内容的高度概括。我们在读者在看一本书的时候最先判断其所讲内容也是从标题入手。同样的道理，搜索引擎了解一个网页内容是关于什么，也是从标题入手。

　　那么，搜索引擎没有“眼睛”，他怎么判断这些内容呢?

　　搜索引擎是一个特殊的访客，他是通过机器人来抓取网页的代码，并通过相关的程序过滤网页代码，来识别网站的实际内容。　搜索引擎读到一个网页的第一部分内容就是标题，只要网站站长是老实的，那基本已经可以通过网页标题确定一个网页的内容了。

*** 三、网站标题需要考虑目标群体

　　做优化最终目的是为了什么?网站最终是要给谁看?明确了这两点,才算是一名合格的优化人员。优化的最终目的是为企业创造价值。网站最终是给用户看。得出用户是第一位的。网站的标题一定要简练、有吸引力,让用户看到标题就对网站感兴趣。搜索引擎优化以用户为中心,所以,网站的标题也要以用户为中心。

　　标题优化

　　1、独特不重复：尽量使网站标题与别人和自身网站内其他页面相同，过多的重复导致搜索引擎不会收录。

　　2、准确相关：每个标题都应该准确描述网站页面的内容，让用户一看就能知道该网站大致是做什么的，搜索引擎也能迅速判断页面的相关性。

　　3、字数限制：按技术角度来书Title标签可以写任意长度，但搜索结果中标题显示是有一定的字数限制。(百度最多显示30个中文字符，谷歌显示65个英文字符，转换成中文大概在30-33个字符。)所以要合理的控制标题字数。

　　4、简洁通顺,不堆砌：堆积关键词是初学者很容易犯的错误，为了提高相关性而在标题中不自然的多次出现关键词。

　　5、关键词出现在最前面：经验和一些统计关表明，关键词在标题中出现的位置与排名有比较大的相关性，位置越靠前排名就越好。

　　6、吸引点击：标题能够吸引用户磨光，让用户欲罢不能，非要点击看个究竟才能达到最好的SEO效果。

　　7、组合两三个关键词：一般来说，一个页面最多针对三四个关键词进行优化，不宜太多。如何合理的在标题中添加组合关键词也是一种技巧。

　　标题长度是否对SEO有影响，肯定有的。根据TF-IDF算法和HillTop算法，标题要短才对SEO有利;但从长尾角度思量流量的话，标题则必要笼罩一些常见的用户搜刮词。所以在做标题时要用好[[my-anchor-baidu-cut-words][百度分词技术]]，可以大大提高标题的作用。

　　网页标题目前还是被公认为影响排名的最重要因素之一，那么，标题是影响网页排名的什么呢?

　　网页标题告诉访客，包括搜索引擎这个访客，这个网页是关于什么的。这是关于“是与不是”的问题，也就是从0变1的概念是一样的。那它的作用就是，让搜索引擎将该网页编入某关键词的结果。还是以上面的网页作为例子：标题包含了“茶与艺术”，那当别人搜索“茶与艺术”的时候，该网页就有可能被编入在搜索引擎的搜索结果里面。
 
[[file:./tomsinsight-hack/茶与艺术.jpg][茶与艺术.jpg]]

　　标题在搜刮引擎排名中一个很紧张的因素

　　标题于检索词的相干度直接影响网页展示次数，从而影响流量

　　标题的优劣，对CTR(点击率)的崎岖有非常大的影响

　　总结：标题诠释一个网页“是什么”，“关于什么”。帮助搜索引判断一个网页内容的第一因素，也是重要因素之一。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE [[http://blog.sina.com.cn/s/blog_c206a2c30101elwj.html][网站用户搜索行为：用户自然搜索流程]]
     CLOSED: [2015-11-22 Sun 18:29]
     - State "DONE"       from ""           [2015-11-22 Sun 18:29]
大家都知道，网站优化的目的就是获得流量，取得好的转化率。而网站想获得大量流量，并取得大量有效客户离不开用户体验，了解用户我们需要了解网站用户搜索行为。只有了解了用户的搜索流程才能更好的优化好网站，做好用户体验。但是我们经常使用一样的搜索，时间长了就习惯了现在搜索的流程，即： 
　　搜索——筛选(缩小范围)——找到满意的商品——点击进入详情页，如果没有找到满意的商品就换词继续搜索。
　　习惯了之后，关于用户自然搜索的流程的一些基本问题就不那么容易发现了。所以，有时候要往回退一步，从本质的需求出发重新来审视一下搜索的产品设计，这样才能发现那些隐藏在设计背后的问题。让我们先来看看目前的淘宝搜索标准使用流程：
*** 淘宝搜索的标准用户流程：
[[file:./tomsinsight-hack/淘宝搜索的标准用户流程.png][淘宝搜索的标准用户流程.png]]
*** 要点：
　　用户的每一次搜索都是为了寻找宝贝而搜索。
　　在搜索的过程中不断缩小查找的范围，最终找到自己想要的宝贝。
　　用户实际的搜索流程真是这样的吗?
*** 用户自然搜索流程
　　标准搜索流程中有一个基础假设，这个假设就是用户的搜索意图是静态的，即他的搜索意图不会变，而搜索的过程就是不断尝试修改查询词，并使用各种筛选条件缩小搜索结果范围，直到最终找到符合自己需求的商品。但是，从用户调研结果同时结合自身的搜索体验来看，在用户多次搜索的过程中，受之前搜索结果的影响，用户的搜索需求会改变。就是说搜索的这个过程可能会改变用户最初的意图，比如你准备是买一个耐克的鞋，结果搜着搜着最后确买了个阿迪的鞋甚至没有买鞋反而买了衣服，相信大家都有这样的感受，这就是自然的用户搜索行为。这样的话，用户在搜索的过程中想找到的就不仅仅是商品了，也有可能是一个可以用来改进下一次搜索体验的建议，比如推荐一个新的相关的查询(不是简单的查询词)。而且用户在搜索的过程中也会发现，慢慢地自己搜索的范围有点偏小了，应该要扩大下搜索的范围或加一些特定词，而不是通常意义上的不断缩小查找的范围。所以用户自然的搜索应该是这样的：
[[file:./tomsinsight-hack/淘宝搜索的自然搜索流程.png][淘宝搜索的自然搜索流程.png]]
*** 要点：
　　用户在搜索的过程中会不断学习探索，会根据自己的查询词以及搜索结果，不断加深对自己想要的搜索结果的理解，在这个过程中用户的搜索意图也会不断的清晰确定起来。
 
　　在意图不那么明确的时候，用户想要的可能并不是商品，而是希望可以得到一些建议来帮助自己搞清楚自己的意图。所以大多数用户在开始搜索时，他的意图并不是很明确的。所以才会出现很多搜这家买那家的情况。
 
　　用户搜索的过程是一个发散的过程，初始的目标会激发出新的目标，从而就有不同的搜索方向。所以有很多时候前面的搜索仅仅是后面的推荐和建议，所以网站的内容和创意就显得很重要了，留住用户的心就是成功。
　　搜索的过程并不总是从模糊到清晰，从大范围到小范围的搜索过程，中间也会出现从小范围找不到而需要扩大范围的情况。还是说说买衣鞋，开始搜索男士平板鞋没找到好的，很可能又直接搜男鞋。
 
　　当用户明确并确定了搜索意图之后，接下来就是使用标准搜索流程，利用排序、筛选缩小结果范围，最终找到满意的商品。
 
　　上面都是理论上的分析，让我们来看看现在好的网站实际的产品是怎么做的。在亚马逊的“所有类目”下搜索“手机”，结果截图如下：
[[file:./tomsinsight-hack/在亚马逊的“所有类目”下搜索“手机”.png][在亚马逊的“所有类目”下搜索“手机”.png]] 
　　对于手机这种意图比较宽泛的查询词，亚马逊在搜索结果区的重要位置给出了更加明确的查询推荐：相关搜索和类目推荐，这些推荐可以让用户探索的过程更加容易，从而更快速的在亚马逊上找到自己想要的商品。当用户选择一个具体的类目之后，关键词区域就会出现一个面包屑，从上面对于用户自然搜索流程的分析来看，这个面包屑就是为扩大搜索范围而准备的，鼠标一点就可以快速跳到上面的任意类目级别，而且还可以清除掉查询词的约束，变成纯类目的浏览。当用户确定了类目之后，就可以更加高效的利用左侧区域的筛选功能来缩小商品的范围，找到自己想要的商品了。这就很好的利用了自然用户搜索行为。
[[file:./tomsinsight-hack/自动创建的面包屑，扩大搜索泛微时特别方便.png][自动创建的面包屑，扩大搜索泛微时特别方便.png]]　　
　　不仅仅是亚马逊，通用搜索领域的 Google 也有一些例子，比如新版的搜索结果页上，我发现有些站点搜索结果上面有面包屑，这些绿色的面包屑都是可以点击的，用户可以直接进入相应的分类。
[[file:./tomsinsight-hack/google搜索结果页中绿色的面包屑.png][google搜索结果页中绿色的面包屑.png]]

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503

** DONE [[http://blog.sina.com.cn/s/blog_c206a2c30101efo0.html][淘宝搜索十大作弊行为]]
     CLOSED: [2015-11-22 Sun 18:42]
     - State "DONE"       from "TODO"       [2015-11-22 Sun 18:42]
标签： 淘宝搜索 淘宝作弊 淘宝搜索作弊	分类： 淘宝SEO优化
　　淘宝搜索十大作弊行为
*** 搜索作弊一：换宝贝
 
　　定义：指卖家为了累积销量或人气，修改原有的商品的标题、价格、图片、详情等变成另外一种商品继续出售。这是种严重炒作销量的行为，有这种行为的商品会被淘宝搜索判定为换宝贝立即降权。降权时间根据作弊的不同严重程度而不同，一般为30天左右，严重的可永久降权或屏蔽。
 
　　处理建议：删除该商品 。
 
*** 搜索作弊二：虚假交易，包括炒作信用和炒作销量。
 
　　定义：虚假交易，包括炒作信用和炒作销量。以增加“会员积累信用”为目的或通过炒作商品销量提高商品人气而发布的商品，会被判定为虚假交易商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同，一般为30天左右。店铺虚假交易行为过于严重的，全店铺商品都将被降权。
 
　　处理建议：删除虚假交易的商品 。
 
*** 搜索作弊三：标题、图片、价格、描述等不一致
 
　　定义：所发布的商品标题、图片、价格、描述等信息缺乏或者多种信息相互不一致的情况，包括商品标题、图片、描述等重要信息缺失，淘宝搜索判断为标题、图片、价格、描述等不一致商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,标题、图片、价格、描述等不一致的商品修改正确后最早可在5天内结束降权。
 
　　处理建议：将商品修改正确，使其标题、图片、价格、描述等一致。
 
　　特殊类商品
 
*** 搜索作弊四：标题滥用关键词
 
　　定义：卖家为使发布的商品引人注目，或使买家能更多的搜索到所发布的商品，而在商品名称中滥用品牌名称或和本商品无关的字眼，使消费者无法准确地找到需要的商品。有这种行为的商品会被淘宝搜索判定为滥用关键词商品立即降权。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,标题滥用的商品修改正确后最早可在5天内结束降权。不过可以合理利用标题。
 
　　处理建议：将商品标题修改正确。
 
*** 搜索作弊五：重复铺货
 
　　重复铺货定义：完全相同以及商品的重要属性完全相同的商品，只允许使用一种出售方式(从一口价，拍卖中选择一个)，发布一次。违反以上规则，即可判定为重复发布,并在搜索结果里靠后展现或不予与展现;对于不同的商品，必须在商品的标题、描述、图片等方面体现商品的不同，否则将被判定为重复铺货。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同，重复的商品删除后最早可在5天内结束降权。
 
　　处理建议：删除重复的商品。
 
*** 搜索作弊六：广告商品
 
　　定义：商品描述不详、无实际商品、仅提供发布者联系方式以及非商品信息的商品(住宅类除外)，淘宝搜索判定为广告商品。系统识别后立即降权或屏蔽，降权时间根据作弊的不同严重程度而不同，广告商品修改正确后最早可在5天内结束降权。
 
　　处理建议：删除该广告商品，或将其修改成正确的商品。
 
*** 搜索作弊七：错放类目和属性
 
　　定义：商品属性与发布商品所选择的属性或类目不一致，或将商品错误放置在淘宝网推荐各类目下，淘宝搜索判定为放错类目商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,错放类目和属性的商品调整正确后最早可在5天内结束降权。
 
　　处理建议：将商品放到正确的类目和属性中。
 
*** 搜索作弊八：邮费不符
 
　　定义：发布商品的一口价很低，邮费不符合市场规律或所属行业标准的(包含但不仅限于如下情况：“雪纺吊带衫”，一口价1元，平邮100元)淘宝搜索判定其相关商品为邮费不符商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,邮费、价格严重不符的商品调整正确后最早可在5天内结束降权。
 
　　处理建议：按照市场规律和所属行业标准，将商品邮费、价格调整正确。
 
*** 搜索作弊九：价格不符
 
　　定义：发布商品的定价不符合市场规律或所属行业标准，滥用网络搜索方式实现其发布的商品排名靠前，影响淘宝网正常运营秩序的，淘宝搜索判定其相关商品为价格不符商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,价格严重不符的商品调整正确后最早可在5天内结束降权。
 
　　处理建议：按照市场规律和所属行业标准，将价格调整正确。
 
*** 搜索作弊十：SKU作弊
 
　　定义： SKU作弊指滥用商品属性(如套餐)设置过低或者不真实的一口价，从而使商品排序靠前(如价格排序)，淘宝搜索将这种商品判定为SKU作弊商品。系统识别后立即降权，降权时间根据作弊的不同严重程度而不同,SKU作弊的商品修改正确后最早可在5天内结束降权。
 
　　处理建议：将SKU商品修改正确

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE #<<my-anchor-baidu-cut-words>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dmb0.html][浅谈不可不知的百度分词！]]
     CLOSED: [2015-11-22 Sun 18:29]
     - State "DONE"       from ""           [2015-11-22 Sun 18:29]
　中文分词 (Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。我们知道，在英文的行文中，单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂的多、困难的多。
*** 一、中文分词原理的解说
　　1、基于理解的分词方法
 
　　这种分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。它通常包括三个部分：分词子系统、句法语义子系统、总控部分。在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。这种分词方法需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此目前基于理解的分词系统还处在试验阶段。
浅谈不可不知的百度分词！
[[file:./tomsinsight-hack/百度中文分词系统.jpg][百度中文分词系统.jpg]]
　　2、基于字符串匹配的分词方法
 
　　基于字符串匹配分词是与词库进行对比按照不同的扫描方式进行分词，扫描方式分为四种:
 
　　1)正向最大匹配法(由左到右的方向)
 
　　正向最大匹配算法：从左到右将待分词文本中的几个连续字符与词表匹配，如果匹配上，则切分出一个词。但这里有一个问题：要做到最大匹配，并不是第一次匹配到就可以切分的。我们来举个例子：
　　待分词文本： content[]={"中"，"华"，"民"，"族"，"从"，"此"，"站"，"起"，"来"，"了"，"。"}
　　词表： dict[]={"中华"， "中华民族" ， "从此"，"站起来"}
　　(1) 从content[1]开始，当扫描到content[2]的时候，发现"中华"已经在词表dict[]中了。但还不能切分出来，因为我们不知道后面的词语能不能组成更长的词(最大匹配)。
 
　　(2) 继续扫描content[3]，发现"中华民"并不是dict[]中的词。但是我们还不能确定是否前面找到的"中华"已经是最大的词了。因为"中华民"是dict[2]的前缀。
 
　　(3) 扫描content[4]，发现"中华民族"是dict[]中的词。继续扫描下去：
 
　　(4) 当扫描content[5]的时候，发现"中华民族从"并不是词表中的词，也不是词的前缀。因此可以切分出前面最大的词——"中华民族"。
 
　　由此可见，最大匹配出的词必须保证下一个扫描不是词表中的词或词的前缀才可以结束。
 
　　2)逆向最大匹配法(由右到左的方向)
 
　　逆向最大匹配法原理和正向一样，只不过是从右到左
 
    逆向最大匹配法通常简称为ＲＭＭ法。ＲＭＭ法的基本原理与ＭＭ法相同 ,不同的是分词切分的方向与MM法相反，而且使用的分词辞典也不同。逆向最大匹配法从被处理文档的末端开始匹配扫描，每次取最末端的2i个字符（i字字串）作为匹配字段，若匹配失败，则去掉匹配字段最前面的一个字，继续匹配。相应地，它使用的分词词典是逆序词典，其中的每个词条都将按逆序方式存放。在实际处理时，先将文档进行倒排处理，生成逆序文档。然后，根据逆序词典，对逆序文档用正向最大匹配法处理即可。反向最大匹配方式，最大长度为5。

 
　　3)最少切分(使每一句中切出的词数最小)
 
　　4)双向最大匹配法(进行由左到右、由右到左两次扫描)
 
　　正向最大匹配法和逆向最大匹配法，都有其局限性，我举得例子是正向最大匹配法局限性的例子，逆向也同样存在(如：长春药店，逆向切分为“长/春药店”)，因此有人又提出了双向最大匹配法，双向最大匹配法。即，两种算法都切一遍，然后根据大颗粒度词越多越好，非词典词、单字词和总词数越少越好的原则，选取其中一种分词结果输出。
 
　　非字典词：正向(1)>逆向(0)(越少越好)
　　单字字典词：正向(2)=逆向(2)(越少越好)
　　总词数：正向(6)>逆向(4)(越少越好)
　　因此最终输出为逆向结果。
 
　　5）为了提高分词精确度，又出现了标志和特征扫描。标志分词以标志作为为断点，可将原字符串分为较小的串再来进机械分词;特征分词将分词和词类标注结合起来，利用丰富的词类信息对分词决策提供帮助，并且在标注过程中又反过来对分词结果进行检验、调整，从而极大地提高切分的准确率。
 
　　3、基于统计的分词方法
 
　　从形式上看，词是稳定的字的组合，因此在上下文中，相邻的字同时出现的次数越多，就越有可能构成一个词。因此字与字相邻共现的频率或概率能够较好的反映成词的可信度。可以对语料中相邻共现的各个字的组合的频度进行统计，计算它们的互现信息。定义两个字的互现信息，计算两个汉字X、Y的相邻共现概率。互现信息体现了汉字之间结合关系的紧密程度。当紧密程度高于某一个阈值时，便可认为此字组可能构成了一个词。这种方法只需对语料中的字组频度进行统计，不需要切分词典，因而又叫做无词典分词法或统计取词方法。但这种方法也有一定的局限性，会经常抽出一些共现频度高、但并不是词的常用字组，例如“这一”、“之一”、“有的”、“我的”、“许多的”等，并且对常用词的识别精度差，时空开销大。实际应用的统计分词系统都要使用一部基本的分词词典(常用词词典)进行串匹配分词，同时使用统计方法识别一些新的词，即将串频统计和串匹配结合起来，既发挥匹配分词切分速度快、效率高的特点，又利用了无词典分词结合上下文识别生词、自动消除歧义的优点。
 
　　机械学习统计分词：在有大量已经分词的文本前提下，利用统计机器学习模型学习词语切分的规律，实现对未知文本的切分，也可以成为训练统计分词。
*** 二、百度分词的难点：
　　1、歧义词语的识别
 
　　歧义是指同样的一句话，可能有两种或者更多的切分方法。主要的歧义有两种：交集型歧义和组合型歧义，例如：表面的，因为“表面”和“面的”都是词，那么这个短语就可以分成“表面的”和“表面的”。这种称为交集型歧义(交叉歧义)。像这种交集型歧义十分常见，前面举的“和服”的例子，其实就是因为交集型歧义引起的错误。“化妆和服装”可以分成“化妆和服装”或者“化妆和服装”。由于没有人的知识去理解，计算机很难知道到底哪个方案正确。
 
　　2、新词识别
 
　　命名实体(人名、地名)、新词，专业术语称为未登录词。也就是那些在分词词典中没有收录，但又确实能称为词的那些词。最典型的是人名，人可以很容易理解。句子“王军虎去广州了”中，“王军虎”是个词，因为是一个人的名字，但要是让计算机去识别就困难了。如果把“王军虎”做为一个词收录到字典中去，全世界有那么多名字，而且每时每刻都有新增的人名，收录这些人名本身就是一项既不划算又巨大的工程。即使这项工作可以完成，还是会存在问题，例如：在句子“王军虎头虎脑的”中，“王军虎”还能不能算词?
*** 三、针对百度搜索引擎分词的注意事项。
[[file:./tomsinsight-hack/针对百度搜索引擎分词的注意事项.jpg][针对百度搜索引擎分词的注意事项.jpg]]
　　1、在title标签中要注意下划线的使用。虽然在搜索词的匹配程度上要远远大于谷歌，但是由于百度分词是基于词典匹配和统计匹配的综合使用，不用分隔词，这样会造成很杂乱的分词。标题分隔符详见：http://blog.sina.com.cn/s/blog_c206a2c30101dm9t.html　　
 
　　2、在关键词没有完全匹配的情况下，如果有分词，比如说：“浏览器下载”这个关键词，有一个网页里第一次出现的关键词是“浏览器”，并且有较高的关键词密度，但是这个网页中却没有“下载”这个关键词而另一个网页里第一次出现的关键词是下载，那么这个网页的关键词就会被拆分成“浏览器”与“下载”两个词，虽然第二个网页里包含有“浏览器”、“下载” 但是第一个网页还是会排在第二个网页的前面，这说明关键词的前面部分是最重要的，因为前面一个关键词权重要高于后面的关键词。所以在关键词排序时要注意顺序，因为关键词从左向右权重分会依次递减。比如在content="SEO,SEO培训,SEO技术,SEM,SEM营销"中从左向右权重依次递减，所以即使只把前面两道三个关键词做起来了，后面的关键词排名也会自动上升。
 
　　3、百度搜索引擎在分词时也存在一个正向匹配和逆向匹配原则。比如单机游戏下载基地。百度进行分词时会形成单机，单机游戏，单机下载，游戏下载，下载基地等选择合适的关键词从做到右依次排列，重点做前面几个词。
 
　　4、尽量去掉一些停止词，比如“的”，“啊”之类的，对内容没有任何影响，但出现频率很高，减少计算量。
 
　　5、通过一些方式消除一些对页面主题没有什么贡献的内容，比如广告，固定目标的导航条，版权声明文字等。
 
　　6、考虑到用户体验和搜索引擎的搜索习惯，要进行一些去重处理，不要让同一篇文章链接到同一网站的不同界面或者链接到其他网站界面。
*** 四、查看百度分词特征基本分为两种方法：
　　第一种方法：利用[[my-anchor-baidu-shot][百度快照]]。
 
　　现在在百度里面搜索“大学生活动策划书”，然后多选择几个页面，不要直接点进去，而是点击相应的“百度快照”。里面会有不同颜色为底色标的关键词。这些就是百度正对该页面的一个分词情况。多看几个页面，把所有这些关键词都整理出来。
 
　　像“大学生活动策划书”大体可以分为：大学生、大学生活动、活动策划书、大学生活动策划书等。
 
　　第二种方法：利用百度搜索结果
 
　　用百度搜索某个关键词或者关键句子的时候，会列出很多待选结果出来。同时在这些结果列表中会以红色字体显示用户搜索词中出现的文字。
 
　　把这些红色字体的词语总结起来。最好能看前十页的搜索结果列表。然后再归纳一些这些词语。就不难看出百度是怎么对你搜索的词或句是怎么分词的了。
*** 五、利用百度分词设置标题
　　1.关键词不是文章的标题，学会利用百度分词1.多渠道寻找关键词，对比找出质量高的关键词。
 
　　2.学会熟练的使用工具，可以让你事半功倍。
 
　　3.关键词分级优化，长短合理搭配。关键词的长短不同，难易程度不同，这就需要我们分级优化，核心词给予高权重，长尾词在网页中出现，具体的关键词分级优化，大家可以参考我的另一篇关于如何对关键词分级优化的博文，在这里就不细说了。
 
　　4.关键词不是文章的标题，学会利用百度分词。很多编辑写文章的时候，喜欢把关键词直接拿来当标题，一方面省心，另一方面觉得是绝对匹配，会有很好的排名。其实这是不正确的，确实完全匹配关键词的标题会给排名带来一定的好处，但是百度不可能让你完全一样的标题文章排名都在首页，这就需要我们合理的利用分词技术以及同义词重复，使标题不但完全匹配关键词，更能吸引用户点击。毕竟，如果只有排名而没有用户点击的话，也是没有用处的。
 
　　5.最好数据统计，善于分析数据。
*** 六、给大家看一个利用分词作标题的实力
　　关键词选好了这个词也想做那个词也想做，在首页投放的关键词超过5个怎么办？比如笔者的网站要做的关键词为：无缝钢管，钢管，无缝钢管价格，大口径无缝钢管，小口径无缝钢管，厚壁钢管，厚壁无缝钢管，无缝钢管厂家。如果把这些关键词罗列起来远远超过百度标题显示的63个字符，百度显示的63字符以后的关键词权重减少很难优化！这里就可以利用百度的分词技术，把这些关键词融合到一起，将百度首页的关键词写成：小口径无缝钢管价格|厚壁钢管|厚壁无缝钢管|大口径无缝钢管厂家。

　　第一个关键词小口径无缝钢管价格就可以利用百度分词技术就可以分为小口径无缝钢管，无缝钢管，无缝钢管价格三个词。
 
　　把所有的词都分开的话：

　　小口径无缝钢管价格 小口径无缝钢管无缝钢管 钢管 无缝钢管价格
　　厚壁钢管：厚壁钢管
　　厚壁无缝钢管：厚壁无缝钢管 无缝钢管 钢管 厚壁钢管
　　大口径无缝钢管厂家：大口径无缝钢管 无缝钢管 无缝钢管厂家 钢管

　　关于关键词的排序：越排在靠前的关键词越容易获得比较好的排名。有人曾做过一个试验：第一次首页标题写法为：大口径无缝钢管价格|厚壁无缝钢管|厚壁钢管|小口径无缝钢管厂家结果大口径无缝钢管排名首页，小口径无缝钢管排名第二页。修改标题后为：小口径无缝钢管价格|厚壁钢管|厚壁无缝钢管|大口径无缝钢管厂家。结果小口径无缝钢管排名首页而大口径无缝钢管的排名掉到第三页。其他的词语变化基本不大。可见关键词的排序也需要注意。建议 seoer将转化率比较高的关键词排在第一位。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE #<<my-anchor-baidu-shot>> [[http://blog.sina.com.cn/s/blog_c206a2c30101dk2w.html][谈点百度快照]]
     CLOSED: [2015-11-22 Sun 18:29]
     - State "DONE"       from ""           [2015-11-22 Sun 18:29]
谈点百度快照 (2013-06-18 22:58:25)转载▼
标签： 百度快照 快照 百度快照更新 快照更新	分类： SEO策略技巧
*** 一、那些被我们误解的百度快照
　　a.百度快照影响权重。这个结论有些荒诞，网站快照的更新频率与权重并不存在任何直接的关系。
　　b.百度快照不影响排名，排名也不作用百度快照。就跟PR一样，只是用来换友情链接的嚼头而已。
　　c.百度快照与友情链接。更没关系了，但是百度快照是交换友情链接时要看的重要指标。
*** 二、百度快照为什么会更新?
　　所谓的百度快照更新，其实就是网页缓存的更新。每个新抓取的网页，百度都会根据其重要程度和时效性以不同的频率去建立索引，一些经常有重要内容更新的网页，蜘蛛会以更快的速度创建索引并放出这个索引缓存。如果一个网站只是一般的文字变更或者内容没有时效性价值的内容，并不一定会被搜索引擎认为是有更新的页面而建立新的索引。
*** 三、快照为什么不更新
　　a.网站遭到惩罚，降权，导致百度蜘蛛不来爬行。笔者的站点l曾经被惩罚，快照一直不是最新的一天，当改进了一些做法后，现在的快照都是当天的。可以证明快照确实是反映网站健康状况的指标。
 
　　b.网站长时间不更新，或者更新无规律性，百度蜘蛛来爬行的频率变少。
 
　　c.网站内容雷同率过高，采用采集的内容，蜘蛛觉得网站内容垃圾。
 
　　d.网站改版，导致网站回归百度考核期。
 
　　e.服务器不稳定，访问困难。
　　.........................
*** 四、百度快照为什么会倒退
　　一个重要的网页，往往会在搜索引擎中保留多份网页快照，而且这些快照的索引时间也不尽相同，有时搜索引擎可能会选择一个他觉得比较重要的快照来进行展示，所以就有可能出现网页快照倒退的情况出现。这与网站本身是没有关系的，更不是因为搜索引擎对网站进行了降权处理。当然也有快照倒退是因为网站被降权K站，还有的时候搜索引擎的更新或误判也会导致快照倒退。
*** 五、怎样让快照更新
　　如果你的站点已经被百度收录，那么也就是说已经被百度定位了网站的类型，这之后百度蜘蛛会频繁的爬行网站，如果此时不坚持更新网站内容，很有可能导致百度放弃此站点，所以一旦开始，就不要放弃。
 
　　1.网站要经常更新内容，而且最好是具有一定的规律性，结合自身的情况，丰富网站内容。对于网站内容，要将原创摆在第一位，至少原创度要提高，这很重要。切记不可今天1篇，明天10篇，采集的内容更是下下策。
 
　　2.外链。推荐写软文，发表在A5和站长之家。这两个平台如果文章能够通过，外链基本就可以完成了。这样的网站权重很高，百度蜘蛛爬行频率快，有效的方法付出的是时间。
 
　　3.选择高质量的友情链接。不用太多的关注pr指，但是一定要有相关性，权重要越高越好，快照要最近的就可以，经常的检查友链情况很重要。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503
** DONE #<<my-anchor-baidu-search-engine>> [[http://blog.sina.com.cn/s/blog_c206a2c30101ddkj.html][简单谈谈搜索引擎爬行和抓取]]
     CLOSED: [2015-11-22 Sun 18:29]
     - State "DONE"       from ""           [2015-11-22 Sun 18:29]
　　今天简单的说说搜索引擎的工作过程，大体分为三个阶段：
 
　　1.爬行和抓取：搜索引擎蜘蛛通过跟踪链接访问网页，获得html代码并存入数据库。
 
　　2.预处理：索引程序对抓取来的页面数据进行文字提取、中文分词、去热词、去噪、索引等处理，以备排名程序调用，详细可以参考seo实战密码。
 
　　3.排名：用户输入关键词后，排名程序调用索引数据库数据，计算相关性，然后按照一定的格式生成搜索结果页面。
 
*** 1.蜘蛛爬行
 
　　蜘蛛(spider)是搜索引擎用来爬行和访问页面的程序，也称为机器人。
　　蜘蛛访问任何一个网站，都会访问网站根目录下的robots.txt文件。
　　例如：如果你不希望你的网站被蜘蛛抓取，那么可以修改robots.txt文件来实现。
 
*** 2.跟踪链接
　　为了抓取网上尽量多的页面，搜索引擎蜘蛛会跟踪页面上的链接，从一个页面爬到另一个页面，就好像蜘蛛在蜘蛛网上爬行一样，这也就是搜索引擎蜘蛛的由来。
　　为了让蜘蛛更好的爬取我们的网站，我们要让我们的网站结构简单有规律一些，以利于蜘蛛的爬行。
 
*** 3.吸引蜘蛛
　　(1)网站和页面的权重。质量高、资格老的网站权重自然也高，这种网站上的页面被爬行的深度也会比较高，所以会有更多内页被收录。
　　(2)页面的更新频率。这点我想大家都懂，蜘蛛对活动的东西非常敏感，所以你要定期更新你的网站。更新的越频繁，质量越高，蜘蛛自然越喜欢。
　　(3)导入链接。高质量的导入链接能更好的吸引蜘蛛。
　　(4)与首页点击距离。一般来说网站权重最高的是首页。所以离首页越近，页面权重越高，被蜘蛛爬行的机会也就越大。
　　(5)页面的结构，头部和尾部比较好。
 
*** 4.爬行时的复制内容检测。
　　检测并删除复制内容通常是在预处理过程中进行，但是现在的蜘蛛会在爬行和抓取时就进行检测。如果你的网站权重很低，而且有大量转载、抄袭或伪原创的内容，蜘蛛认为你是低质量的转载网站，可能不在继续爬行。

　　文章来自：木木seo博客http://blog.sina.com.cn/mumuhouzi  QQ：809472503

* SEO的reference
** [[https://en.wikipedia.org/wiki/Search_engine_optimization][Search engine optimization]]
** [[https://en.wikipedia.org/wiki/Spamdexing][Spamdexing]]
** [[http://26836659.blogcn.com/articles/tag/%25E7%2599%25BE%25E5%25BA%25A6%25E9%25BB%2591%25E5%25B8%25BDseo][混世魔王的技术博客]]
** [[http://tx.liberal.ntu.edu.tw/silverjay/google%2520analytics-seo_malicious.htm][電子商務 個體策略=行為科技+網路科技/數位分析]]
** [[http://reed077.blog.techweb.com.cn/archives/726.html][独家揭秘：暴利的黑帽SEO行业]]
** [[http://blog.seo-tw.org/][搜尋引擎優化 | 台湾SEO學院 Taiwan SEO College]]